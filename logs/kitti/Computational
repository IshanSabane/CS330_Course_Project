digraph {
	graph [size="765.9,765.9"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140594681347984 [label="
 (6, 100, 92)" fillcolor=darkolivegreen1]
	140594704309024 [label="ViewBackward0
---------------------
self_sizes: (600, 92)"]
	140594704307296 -> 140594704309024
	140594704307296 -> 140594682121488 [dir=none]
	140594682121488 [label="mat1
 (600, 256)" fillcolor=orange]
	140594704307296 -> 140594682121328 [dir=none]
	140594682121328 [label="mat2
 (256, 92)" fillcolor=orange]
	140594704307296 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :      (256, 92)
mat2_strides:       (1, 256)"]
	140594704306912 -> 140594704307296
	140594519815168 [label="class_labels_classifier.bias
 (92)" fillcolor=lightblue]
	140594519815168 -> 140594704306912
	140594704306912 [label=AccumulateGrad]
	140594704307728 -> 140594704307296
	140594704307728 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594704306288 -> 140594704307728
	140594704306288 -> 140594519815008 [dir=none]
	140594519815008 [label="bias
 (256)" fillcolor=orange]
	140594704306288 -> 140594682157312 [dir=none]
	140594682157312 [label="input
 (6, 100, 256)" fillcolor=orange]
	140594704306288 -> 140594682121728 [dir=none]
	140594682121728 [label="result1
 (6, 100, 1)" fillcolor=orange]
	140594704306288 -> 140594682121408 [dir=none]
	140594682121408 [label="result2
 (6, 100, 1)" fillcolor=orange]
	140594704306288 -> 140594519814928 [dir=none]
	140594519814928 [label="weight
 (256)" fillcolor=orange]
	140594704306288 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140594704308352 -> 140594704306288
	140594704308352 -> 140594519814848 [dir=none]
	140594519814848 [label="bias
 (256)" fillcolor=orange]
	140594704308352 -> 140594682155792 [dir=none]
	140594682155792 [label="input
 (6, 100, 256)" fillcolor=orange]
	140594704308352 -> 140594682121888 [dir=none]
	140594682121888 [label="result1
 (6, 100, 1)" fillcolor=orange]
	140594704308352 -> 140594682121648 [dir=none]
	140594682121648 [label="result2
 (6, 100, 1)" fillcolor=orange]
	140594704308352 -> 140594519814768 [dir=none]
	140594519814768 [label="weight
 (256)" fillcolor=orange]
	140594704308352 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140594704309936 -> 140594704308352
	140594704309936 [label="AddBackward0
------------
alpha: 1"]
	140594704309456 -> 140594704309936
	140594704309456 -> 140594519814368 [dir=none]
	140594519814368 [label="bias
 (256)" fillcolor=orange]
	140594704309456 -> 140594682157232 [dir=none]
	140594682157232 [label="input
 (6, 100, 256)" fillcolor=orange]
	140594704309456 -> 140594682122048 [dir=none]
	140594682122048 [label="result1
 (6, 100, 1)" fillcolor=orange]
	140594704309456 -> 140594682121808 [dir=none]
	140594682121808 [label="result2
 (6, 100, 1)" fillcolor=orange]
	140594704309456 -> 140594519814288 [dir=none]
	140594519814288 [label="weight
 (256)" fillcolor=orange]
	140594704309456 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140594704309744 -> 140594704309456
	140594704309744 [label="AddBackward0
------------
alpha: 1"]
	140594704335200 -> 140594704309744
	140594704335200 -> 140594519694688 [dir=none]
	140594519694688 [label="bias
 (256)" fillcolor=orange]
	140594704335200 -> 140594682156272 [dir=none]
	140594682156272 [label="input
 (6, 100, 256)" fillcolor=orange]
	140594704335200 -> 140594682121568 [dir=none]
	140594682121568 [label="result1
 (6, 100, 1)" fillcolor=orange]
	140594704335200 -> 140594682121968 [dir=none]
	140594682121968 [label="result2
 (6, 100, 1)" fillcolor=orange]
	140594704335200 -> 140594519694608 [dir=none]
	140594519694608 [label="weight
 (256)" fillcolor=orange]
	140594704335200 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140594704338464 -> 140594704335200
	140594704338464 [label="AddBackward0
------------
alpha: 1"]
	140594704336976 -> 140594704338464
	140594704336976 -> 140594519693888 [dir=none]
	140594519693888 [label="bias
 (256)" fillcolor=orange]
	140594704336976 -> 140594682178272 [dir=none]
	140594682178272 [label="input
 (6, 100, 256)" fillcolor=orange]
	140594704336976 -> 140594682122128 [dir=none]
	140594682122128 [label="result1
 (6, 100, 1)" fillcolor=orange]
	140594704336976 -> 140594682200208 [dir=none]
	140594682200208 [label="result2
 (6, 100, 1)" fillcolor=orange]
	140594704336976 -> 140594519693808 [dir=none]
	140594519693808 [label="weight
 (256)" fillcolor=orange]
	140594704336976 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140594704335248 -> 140594704336976
	140594704335248 [label="AddBackward0
------------
alpha: 1"]
	140594704335632 -> 140594704335248
	140594704335632 -> 140594519693408 [dir=none]
	140594519693408 [label="bias
 (256)" fillcolor=orange]
	140594704335632 -> 140594682179472 [dir=none]
	140594682179472 [label="input
 (6, 100, 256)" fillcolor=orange]
	140594704335632 -> 140594682200368 [dir=none]
	140594682200368 [label="result1
 (6, 100, 1)" fillcolor=orange]
	140594704335632 -> 140594682200128 [dir=none]
	140594682200128 [label="result2
 (6, 100, 1)" fillcolor=orange]
	140594704335632 -> 140594519693328 [dir=none]
	140594519693328 [label="weight
 (256)" fillcolor=orange]
	140594704335632 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140594704335824 -> 140594704335632
	140594704335824 [label="AddBackward0
------------
alpha: 1"]
	140594704335920 -> 140594704335824
	140594704335920 -> 140594519692608 [dir=none]
	140594519692608 [label="bias
 (256)" fillcolor=orange]
	140594704335920 -> 140594682178752 [dir=none]
	140594682178752 [label="input
 (6, 100, 256)" fillcolor=orange]
	140594704335920 -> 140594682200528 [dir=none]
	140594682200528 [label="result1
 (6, 100, 1)" fillcolor=orange]
	140594704335920 -> 140594682200288 [dir=none]
	140594682200288 [label="result2
 (6, 100, 1)" fillcolor=orange]
	140594704335920 -> 140594519692528 [dir=none]
	140594519692528 [label="weight
 (256)" fillcolor=orange]
	140594704335920 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140594704336640 -> 140594704335920
	140594704336640 [label="AddBackward0
------------
alpha: 1"]
	140594704336688 -> 140594704336640
	140594704336688 -> 140594519691808 [dir=none]
	140594519691808 [label="bias
 (256)" fillcolor=orange]
	140594704336688 -> 140594682176272 [dir=none]
	140594682176272 [label="input
 (6, 100, 256)" fillcolor=orange]
	140594704336688 -> 140594682200688 [dir=none]
	140594682200688 [label="result1
 (6, 100, 1)" fillcolor=orange]
	140594704336688 -> 140594682200448 [dir=none]
	140594682200448 [label="result2
 (6, 100, 1)" fillcolor=orange]
	140594704336688 -> 140594519691728 [dir=none]
	140594519691728 [label="weight
 (256)" fillcolor=orange]
	140594704336688 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140594704337360 -> 140594704336688
	140594704337360 [label="AddBackward0
------------
alpha: 1"]
	140594704338704 -> 140594704337360
	140594704338704 -> 140594519691328 [dir=none]
	140594519691328 [label="bias
 (256)" fillcolor=orange]
	140594704338704 -> 140594682177712 [dir=none]
	140594682177712 [label="input
 (6, 100, 256)" fillcolor=orange]
	140594704338704 -> 140594682200848 [dir=none]
	140594682200848 [label="result1
 (6, 100, 1)" fillcolor=orange]
	140594704338704 -> 140594682200608 [dir=none]
	140594682200608 [label="result2
 (6, 100, 1)" fillcolor=orange]
	140594704338704 -> 140594520100752 [dir=none]
	140594520100752 [label="weight
 (256)" fillcolor=orange]
	140594704338704 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140594704338896 -> 140594704338704
	140594704338896 [label="AddBackward0
------------
alpha: 1"]
	140594704338848 -> 140594704338896
	140594704338848 -> 140594520100032 [dir=none]
	140594520100032 [label="bias
 (256)" fillcolor=orange]
	140594704338848 -> 140594682176752 [dir=none]
	140594682176752 [label="input
 (6, 100, 256)" fillcolor=orange]
	140594704338848 -> 140594682201008 [dir=none]
	140594682201008 [label="result1
 (6, 100, 1)" fillcolor=orange]
	140594704338848 -> 140594682200768 [dir=none]
	140594682200768 [label="result2
 (6, 100, 1)" fillcolor=orange]
	140594704338848 -> 140594520099952 [dir=none]
	140594520099952 [label="weight
 (256)" fillcolor=orange]
	140594704338848 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140594704360064 -> 140594704338848
	140594704360064 [label="AddBackward0
------------
alpha: 1"]
	140594704361984 -> 140594704360064
	140594704361984 -> 140594520099232 [dir=none]
	140594520099232 [label="bias
 (256)" fillcolor=orange]
	140594704361984 -> 140594682079968 [dir=none]
	140594682079968 [label="input
 (6, 100, 256)" fillcolor=orange]
	140594704361984 -> 140594682201168 [dir=none]
	140594682201168 [label="result1
 (6, 100, 1)" fillcolor=orange]
	140594704361984 -> 140594682200928 [dir=none]
	140594682200928 [label="result2
 (6, 100, 1)" fillcolor=orange]
	140594704361984 -> 140594520099152 [dir=none]
	140594520099152 [label="weight
 (256)" fillcolor=orange]
	140594704361984 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140594704359584 -> 140594704361984
	140594704359584 [label="AddBackward0
------------
alpha: 1"]
	140594704360448 -> 140594704359584
	140594704360448 -> 140594520098752 [dir=none]
	140594520098752 [label="bias
 (256)" fillcolor=orange]
	140594704360448 -> 140594682081168 [dir=none]
	140594682081168 [label="input
 (6, 100, 256)" fillcolor=orange]
	140594704360448 -> 140594682201328 [dir=none]
	140594682201328 [label="result1
 (6, 100, 1)" fillcolor=orange]
	140594704360448 -> 140594682201088 [dir=none]
	140594682201088 [label="result2
 (6, 100, 1)" fillcolor=orange]
	140594704360448 -> 140594520098672 [dir=none]
	140594520098672 [label="weight
 (256)" fillcolor=orange]
	140594704360448 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140594704361312 -> 140594704360448
	140594704361312 [label="AddBackward0
------------
alpha: 1"]
	140594704361552 -> 140594704361312
	140594704361552 -> 140594520097952 [dir=none]
	140594520097952 [label="bias
 (256)" fillcolor=orange]
	140594704361552 -> 140594682080448 [dir=none]
	140594682080448 [label="input
 (6, 100, 256)" fillcolor=orange]
	140594704361552 -> 140594682201488 [dir=none]
	140594682201488 [label="result1
 (6, 100, 1)" fillcolor=orange]
	140594704361552 -> 140594682201248 [dir=none]
	140594682201248 [label="result2
 (6, 100, 1)" fillcolor=orange]
	140594704361552 -> 140594520097872 [dir=none]
	140594520097872 [label="weight
 (256)" fillcolor=orange]
	140594704361552 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140594704363232 -> 140594704361552
	140594704363232 [label="AddBackward0
------------
alpha: 1"]
	140594704362176 -> 140594704363232
	140594704362176 -> 140594520097152 [dir=none]
	140594520097152 [label="bias
 (256)" fillcolor=orange]
	140594704362176 -> 140594682077968 [dir=none]
	140594682077968 [label="input
 (6, 100, 256)" fillcolor=orange]
	140594704362176 -> 140594682201648 [dir=none]
	140594682201648 [label="result1
 (6, 100, 1)" fillcolor=orange]
	140594704362176 -> 140594682201408 [dir=none]
	140594682201408 [label="result2
 (6, 100, 1)" fillcolor=orange]
	140594704362176 -> 140594520097072 [dir=none]
	140594520097072 [label="weight
 (256)" fillcolor=orange]
	140594704362176 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140594704361840 -> 140594704362176
	140594704361840 [label="AddBackward0
------------
alpha: 1"]
	140594704362464 -> 140594704361840
	140594704362464 -> 140594704602032 [dir=none]
	140594704602032 [label="bias
 (256)" fillcolor=orange]
	140594704362464 -> 140594682079408 [dir=none]
	140594682079408 [label="input
 (6, 100, 256)" fillcolor=orange]
	140594704362464 -> 140594682201808 [dir=none]
	140594682201808 [label="result1
 (6, 100, 1)" fillcolor=orange]
	140594704362464 -> 140594682201568 [dir=none]
	140594682201568 [label="result2
 (6, 100, 1)" fillcolor=orange]
	140594704362464 -> 140594704602192 [dir=none]
	140594704602192 [label="weight
 (256)" fillcolor=orange]
	140594704362464 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140594704362704 -> 140594704362464
	140594704362704 [label="AddBackward0
------------
alpha: 1"]
	140594704363088 -> 140594704362704
	140594704363088 -> 140594680939280 [dir=none]
	140594680939280 [label="bias
 (256)" fillcolor=orange]
	140594704363088 -> 140594682078448 [dir=none]
	140594682078448 [label="input
 (6, 100, 256)" fillcolor=orange]
	140594704363088 -> 140594682201968 [dir=none]
	140594682201968 [label="result1
 (6, 100, 1)" fillcolor=orange]
	140594704363088 -> 140594682201728 [dir=none]
	140594682201728 [label="result2
 (6, 100, 1)" fillcolor=orange]
	140594704363088 -> 140594680939120 [dir=none]
	140594680939120 [label="weight
 (256)" fillcolor=orange]
	140594704363088 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140594704388208 -> 140594704363088
	140594704388208 [label="AddBackward0
------------
alpha: 1"]
	140594704388400 -> 140594704388208
	140594704388400 -> 140594680940480 [dir=none]
	140594680940480 [label="bias
 (256)" fillcolor=orange]
	140594704388400 -> 140594704304864 [dir=none]
	140594704304864 [label="input
 (6, 100, 256)" fillcolor=orange]
	140594704388400 -> 140594682202128 [dir=none]
	140594682202128 [label="result1
 (6, 100, 1)" fillcolor=orange]
	140594704388400 -> 140594682201888 [dir=none]
	140594682201888 [label="result2
 (6, 100, 1)" fillcolor=orange]
	140594704388400 -> 140594680940560 [dir=none]
	140594680940560 [label="weight
 (256)" fillcolor=orange]
	140594704388400 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140594704391088 -> 140594704388400
	140594704391088 [label="AddBackward0
------------
alpha: 1"]
	140594704388736 -> 140594704391088
	140594704388736 -> 140594680940960 [dir=none]
	140594680940960 [label="bias
 (256)" fillcolor=orange]
	140594704388736 -> 140594704306064 [dir=none]
	140594704306064 [label="input
 (6, 100, 256)" fillcolor=orange]
	140594704388736 -> 140594682202288 [dir=none]
	140594682202288 [label="result1
 (6, 100, 1)" fillcolor=orange]
	140594704388736 -> 140594682202048 [dir=none]
	140594682202048 [label="result2
 (6, 100, 1)" fillcolor=orange]
	140594704388736 -> 140594680941040 [dir=none]
	140594680941040 [label="weight
 (256)" fillcolor=orange]
	140594704388736 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140594704390176 -> 140594704388736
	140594704390176 [label="AddBackward0
------------
alpha: 1"]
	140594704389360 -> 140594704390176
	140594704389360 -> 140594680941760 [dir=none]
	140594680941760 [label="bias
 (256)" fillcolor=orange]
	140594704389360 -> 140594704305344 [dir=none]
	140594704305344 [label="input
 (6, 100, 256)" fillcolor=orange]
	140594704389360 -> 140594682202448 [dir=none]
	140594682202448 [label="result1
 (6, 100, 1)" fillcolor=orange]
	140594704389360 -> 140594682202208 [dir=none]
	140594682202208 [label="result2
 (6, 100, 1)" fillcolor=orange]
	140594704389360 -> 140594680941840 [dir=none]
	140594680941840 [label="weight
 (256)" fillcolor=orange]
	140594704389360 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140594704389696 -> 140594704389360
	140594704389696 [label="AddBackward0
------------
alpha: 1"]
	140594704390368 -> 140594704389696
	140594704390368 -> 140594682202608 [dir=none]
	140594682202608 [label="other
 (6, 100, 256)" fillcolor=orange]
	140594704390368 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704391568 -> 140594704390368
	140594704391568 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594704390416 -> 140594704391568
	140594704390416 -> 140594682202768 [dir=none]
	140594682202768 [label="mat1
 (600, 256)" fillcolor=orange]
	140594704390416 -> 140594682202528 [dir=none]
	140594682202528 [label="mat2
 (256, 256)" fillcolor=orange]
	140594704390416 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594704390560 -> 140594704390416
	140594680941920 [label="model.decoder.layers.0.self_attn.out_proj.bias
 (256)" fillcolor=lightblue]
	140594680941920 -> 140594704390560
	140594704390560 [label=AccumulateGrad]
	140594704390656 -> 140594704390416
	140594704390656 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594704390848 -> 140594704390656
	140594704390848 [label="UnsafeViewBackward0
---------------------------
self_sizes: (6, 100, 8, 32)"]
	140594704391472 -> 140594704390848
	140594704391472 [label=CloneBackward0]
	140594704391760 -> 140594704391472
	140594704391760 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594704392096 -> 140594704391760
	140594704392096 [label="ViewBackward0
-------------------------
self_sizes: (48, 100, 32)"]
	140594704417792 -> 140594704392096
	140594704417792 -> 140594704305024 [dir=none]
	140594704305024 [label="mat2
 (48, 100, 32)" fillcolor=orange]
	140594704417792 -> 140594704305184 [dir=none]
	140594704305184 [label="self
 (48, 100, 100)" fillcolor=orange]
	140594704417792 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594704418272 -> 140594704417792
	140594704418272 -> 140594519875648 [dir=none]
	140594519875648 [label="result
 (48, 100, 100)" fillcolor=orange]
	140594704418272 [label="SoftmaxBackward0
----------------------------
dim   : 18446744073709551615
result:       [saved tensor]"]
	140594704418464 -> 140594704418272
	140594704418464 -> 140594704304624 [dir=none]
	140594704304624 [label="mat2
 (48, 32, 100)" fillcolor=orange]
	140594704418464 -> 140594704304944 [dir=none]
	140594704304944 [label="self
 (48, 100, 32)" fillcolor=orange]
	140594704418464 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594704417840 -> 140594704418464
	140594704417840 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 100, 32)"]
	140594704417216 -> 140594704417840
	140594704417216 [label=CloneBackward0]
	140594704418080 -> 140594704417216
	140594704418080 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594704417648 -> 140594704418080
	140594704417648 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594704448336 -> 140594704417648
	140594704448336 -> 140594682202928 [dir=none]
	140594682202928 [label="other
 ()" fillcolor=orange]
	140594704448336 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704448720 -> 140594704448336
	140594704448720 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594704448096 -> 140594704448720
	140594704448096 -> 140594682203168 [dir=none]
	140594682203168 [label="mat1
 (600, 256)" fillcolor=orange]
	140594704448096 -> 140594682202688 [dir=none]
	140594682202688 [label="mat2
 (256, 256)" fillcolor=orange]
	140594704448096 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594704449344 -> 140594704448096
	140594680942080 [label="model.decoder.layers.0.self_attn.q_proj.bias
 (256)" fillcolor=lightblue]
	140594680942080 -> 140594704449344
	140594704449344 [label=AccumulateGrad]
	140594704448288 -> 140594704448096
	140594704448288 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594704447568 -> 140594704448288
	140594704447568 [label="AddBackward0
------------
alpha: 1"]
	140594713911600 -> 140594704447568
	140594713911600 [label="RepeatBackward0
-------------------------
repeats   :     (6, 1, 1)
self_sizes: (1, 100, 256)"]
	140594681996480 -> 140594713911600
	140594681996480 [label="UnsqueezeBackward0
------------------
dim: 0"]
	140594704474992 -> 140594681996480
	140594681347344 [label="model.query_position_embeddings.weight
 (100, 256)" fillcolor=lightblue]
	140594681347344 -> 140594704474992
	140594704474992 [label=AccumulateGrad]
	140594704449104 -> 140594704448096
	140594704449104 [label=TBackward0]
	140594713913136 -> 140594704449104
	140594680942160 [label="model.decoder.layers.0.self_attn.q_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594680942160 -> 140594713913136
	140594713913136 [label=AccumulateGrad]
	140594704417072 -> 140594704418464
	140594704417072 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594713911552 -> 140594704417072
	140594713911552 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 100, 32)"]
	140594704417264 -> 140594713911552
	140594704417264 [label=CloneBackward0]
	140594704448144 -> 140594704417264
	140594704448144 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594704446176 -> 140594704448144
	140594704446176 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594704449392 -> 140594704446176
	140594704449392 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594704474176 -> 140594704449392
	140594704474176 -> 140595115423040 [dir=none]
	140595115423040 [label="mat1
 (600, 256)" fillcolor=orange]
	140594704474176 -> 140594682203328 [dir=none]
	140594682203328 [label="mat2
 (256, 256)" fillcolor=orange]
	140594704474176 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594704476096 -> 140594704474176
	140594680942400 [label="model.decoder.layers.0.self_attn.k_proj.bias
 (256)" fillcolor=lightblue]
	140594680942400 -> 140594704476096
	140594704476096 [label=AccumulateGrad]
	140594704474704 -> 140594704474176
	140594704474704 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594704447568 -> 140594704474704
	140594704474656 -> 140594704474176
	140594704474656 [label=TBackward0]
	140594704475424 -> 140594704474656
	140594680942480 [label="model.decoder.layers.0.self_attn.k_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594680942480 -> 140594704475424
	140594704475424 [label=AccumulateGrad]
	140594704416976 -> 140594704417792
	140594704416976 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 100, 32)"]
	140594704418128 -> 140594704416976
	140594704418128 [label=CloneBackward0]
	140594704417600 -> 140594704418128
	140594704417600 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594704448480 -> 140594704417600
	140594704448480 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594704474848 -> 140594704448480
	140594704474848 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594704474944 -> 140594704474848
	140594704474944 -> 140594682203008 [dir=none]
	140594682203008 [label="mat1
 (600, 256)" fillcolor=orange]
	140594704474944 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:             ()
mat2        :           None
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594704285408 -> 140594704474944
	140594680942240 [label="model.decoder.layers.0.self_attn.v_proj.bias
 (256)" fillcolor=lightblue]
	140594680942240 -> 140594704285408
	140594704285408 [label=AccumulateGrad]
	140594704285216 -> 140594704474944
	140594704285216 [label=TBackward0]
	140594704285456 -> 140594704285216
	140594680942320 [label="model.decoder.layers.0.self_attn.v_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594680942320 -> 140594704285456
	140594704285456 [label=AccumulateGrad]
	140594704390896 -> 140594704390416
	140594704390896 [label=TBackward0]
	140594704391712 -> 140594704390896
	140594680942000 [label="model.decoder.layers.0.self_attn.out_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594680942000 -> 140594704391712
	140594704391712 [label=AccumulateGrad]
	140594704389792 -> 140594704389360
	140594680941840 [label="model.decoder.layers.0.self_attn_layer_norm.weight
 (256)" fillcolor=lightblue]
	140594680941840 -> 140594704389792
	140594704389792 [label=AccumulateGrad]
	140594704389552 -> 140594704389360
	140594680941760 [label="model.decoder.layers.0.self_attn_layer_norm.bias
 (256)" fillcolor=lightblue]
	140594680941760 -> 140594704389552
	140594704389552 [label=AccumulateGrad]
	140594704389312 -> 140594704390176
	140594704389312 -> 140594682202848 [dir=none]
	140594682202848 [label="other
 (6, 100, 256)" fillcolor=orange]
	140594704389312 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704390032 -> 140594704389312
	140594704390032 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594704390608 -> 140594704390032
	140594704390608 -> 140594682203648 [dir=none]
	140594682203648 [label="mat1
 (600, 256)" fillcolor=orange]
	140594704390608 -> 140594682203408 [dir=none]
	140594682203408 [label="mat2
 (256, 256)" fillcolor=orange]
	140594704390608 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594704391232 -> 140594704390608
	140594680941120 [label="model.decoder.layers.0.encoder_attn.out_proj.bias
 (256)" fillcolor=lightblue]
	140594680941120 -> 140594704391232
	140594704391232 [label=AccumulateGrad]
	140594704391280 -> 140594704390608
	140594704391280 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594704417456 -> 140594704391280
	140594704417456 [label="UnsafeViewBackward0
---------------------------
self_sizes: (6, 100, 8, 32)"]
	140594704448960 -> 140594704417456
	140594704448960 [label=CloneBackward0]
	140594704474224 -> 140594704448960
	140594704474224 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594704285504 -> 140594704474224
	140594704285504 [label="ViewBackward0
-------------------------
self_sizes: (48, 100, 32)"]
	140594704284832 -> 140594704285504
	140594704284832 -> 140594704305984 [dir=none]
	140594704305984 [label="mat2
 (48, 782, 32)" fillcolor=orange]
	140594704284832 -> 140594682077248 [dir=none]
	140594682077248 [label="self
 (48, 100, 782)" fillcolor=orange]
	140594704284832 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594704285024 -> 140594704284832
	140594704285024 -> 140594682203488 [dir=none]
	140594682203488 [label="result
 (48, 100, 782)" fillcolor=orange]
	140594704285024 [label="SoftmaxBackward0
----------------------------
dim   : 18446744073709551615
result:       [saved tensor]"]
	140594704284544 -> 140594704285024
	140594704284544 [label="ViewBackward0
----------------------------
self_sizes: (6, 8, 100, 782)"]
	140594704284352 -> 140594704284544
	140594704284352 [label="AddBackward0
------------
alpha: 1"]
	140594704284160 -> 140594704284352
	140594704284160 [label="ViewBackward0
--------------------------
self_sizes: (48, 100, 782)"]
	140594704283968 -> 140594704284160
	140594704283968 -> 140594704305584 [dir=none]
	140594704305584 [label="mat2
 (48, 32, 782)" fillcolor=orange]
	140594704283968 -> 140594704305904 [dir=none]
	140594704305904 [label="self
 (48, 100, 32)" fillcolor=orange]
	140594704283968 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594704283776 -> 140594704283968
	140594704283776 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 100, 32)"]
	140594704283536 -> 140594704283776
	140594704283536 [label=CloneBackward0]
	140594704283344 -> 140594704283536
	140594704283344 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594704283152 -> 140594704283344
	140594704283152 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594704282960 -> 140594704283152
	140594704282960 -> 140594682203808 [dir=none]
	140594682203808 [label="other
 ()" fillcolor=orange]
	140594704282960 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704282864 -> 140594704282960
	140594704282864 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594704282672 -> 140594704282864
	140594704282672 -> 140594682203888 [dir=none]
	140594682203888 [label="mat1
 (600, 256)" fillcolor=orange]
	140594704282672 -> 140594682203728 [dir=none]
	140594682203728 [label="mat2
 (256, 256)" fillcolor=orange]
	140594704282672 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594704282480 -> 140594704282672
	140594680941280 [label="model.decoder.layers.0.encoder_attn.q_proj.bias
 (256)" fillcolor=lightblue]
	140594680941280 -> 140594704282480
	140594704282480 [label=AccumulateGrad]
	140594704282624 -> 140594704282672
	140594704282624 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594704282288 -> 140594704282624
	140594704282288 [label="AddBackward0
------------
alpha: 1"]
	140594704389360 -> 140594704282288
	140594713911600 -> 140594704282288
	140594704283728 -> 140594704282672
	140594704283728 [label=TBackward0]
	140594704282048 -> 140594704283728
	140594680941360 [label="model.decoder.layers.0.encoder_attn.q_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594680941360 -> 140594704282048
	140594704282048 [label=AccumulateGrad]
	140594704283824 -> 140594704283968
	140594704283824 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594704283296 -> 140594704283824
	140594704283296 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 782, 32)"]
	140594704282912 -> 140594704283296
	140594704282912 [label=CloneBackward0]
	140594704282432 -> 140594704282912
	140594704282432 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594704281952 -> 140594704282432
	140594704281952 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594704282240 -> 140594704281952
	140594704282240 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594704281856 -> 140594704282240
	140594704281856 -> 140594682202368 [dir=none]
	140594682202368 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594704281856 -> 140594682203088 [dir=none]
	140594682203088 [label="mat2
 (256, 256)" fillcolor=orange]
	140594704281856 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594704281712 -> 140594704281856
	140594680941600 [label="model.decoder.layers.0.encoder_attn.k_proj.bias
 (256)" fillcolor=lightblue]
	140594680941600 -> 140594704281712
	140594704281712 [label=AccumulateGrad]
	140594704281664 -> 140594704281856
	140594704281664 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594704777024 -> 140594704281664
	140594704777024 [label="AddBackward0
------------
alpha: 1"]
	140594704776640 -> 140594704777024
	140594704776640 -> 140594681069712 [dir=none]
	140594681069712 [label="bias
 (256)" fillcolor=orange]
	140594704776640 -> 140594704303584 [dir=none]
	140594704303584 [label="input
 (6, 782, 256)" fillcolor=orange]
	140594704776640 -> 140594682203968 [dir=none]
	140594682203968 [label="result1
 (6, 782, 1)" fillcolor=orange]
	140594704776640 -> 140594682203568 [dir=none]
	140594682203568 [label="result2
 (6, 782, 1)" fillcolor=orange]
	140594704776640 -> 140594681069632 [dir=none]
	140594681069632 [label="weight
 (256)" fillcolor=orange]
	140594704776640 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140594704776544 -> 140594704776640
	140594704776544 [label="AddBackward0
------------
alpha: 1"]
	140594704776160 -> 140594704776544
	140594704776160 -> 140594681070192 [dir=none]
	140594681070192 [label="bias
 (256)" fillcolor=orange]
	140594704776160 -> 140594704303824 [dir=none]
	140594704303824 [label="input
 (6, 782, 256)" fillcolor=orange]
	140594704776160 -> 140594682204048 [dir=none]
	140594682204048 [label="result1
 (6, 782, 1)" fillcolor=orange]
	140594704776160 -> 140594682203248 [dir=none]
	140594682203248 [label="result2
 (6, 782, 1)" fillcolor=orange]
	140594704776160 -> 140594681070112 [dir=none]
	140594681070112 [label="weight
 (256)" fillcolor=orange]
	140594704776160 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140594704775824 -> 140594704776160
	140594704775824 [label="AddBackward0
------------
alpha: 1"]
	140594704775536 -> 140594704775824
	140594704775536 -> 140594681070992 [dir=none]
	140594681070992 [label="bias
 (256)" fillcolor=orange]
	140594704775536 -> 140594704302464 [dir=none]
	140594704302464 [label="input
 (6, 782, 256)" fillcolor=orange]
	140594704775536 -> 140594681999424 [dir=none]
	140594681999424 [label="result1
 (6, 782, 1)" fillcolor=orange]
	140594704775536 -> 140594681999584 [dir=none]
	140594681999584 [label="result2
 (6, 782, 1)" fillcolor=orange]
	140594704775536 -> 140594681070912 [dir=none]
	140594681070912 [label="weight
 (256)" fillcolor=orange]
	140594704775536 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140594704775296 -> 140594704775536
	140594704775296 [label="AddBackward0
------------
alpha: 1"]
	140594704774912 -> 140594704775296
	140594704774912 -> 140594681071472 [dir=none]
	140594681071472 [label="bias
 (256)" fillcolor=orange]
	140594704774912 -> 140594704302704 [dir=none]
	140594704302704 [label="input
 (6, 782, 256)" fillcolor=orange]
	140594704774912 -> 140594681999744 [dir=none]
	140594681999744 [label="result1
 (6, 782, 1)" fillcolor=orange]
	140594704774912 -> 140594681999504 [dir=none]
	140594681999504 [label="result2
 (6, 782, 1)" fillcolor=orange]
	140594704774912 -> 140594681071392 [dir=none]
	140594681071392 [label="weight
 (256)" fillcolor=orange]
	140594704774912 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140594704774672 -> 140594704774912
	140594704774672 [label="AddBackward0
------------
alpha: 1"]
	140594704774288 -> 140594704774672
	140594704774288 -> 140594704424768 [dir=none]
	140594704424768 [label="bias
 (256)" fillcolor=orange]
	140594704774288 -> 140594704325824 [dir=none]
	140594704325824 [label="input
 (6, 782, 256)" fillcolor=orange]
	140594704774288 -> 140594681999904 [dir=none]
	140594681999904 [label="result1
 (6, 782, 1)" fillcolor=orange]
	140594704774288 -> 140594681999664 [dir=none]
	140594681999664 [label="result2
 (6, 782, 1)" fillcolor=orange]
	140594704774288 -> 140594704424848 [dir=none]
	140594704424848 [label="weight
 (256)" fillcolor=orange]
	140594704774288 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140594704774048 -> 140594704774288
	140594704774048 [label="AddBackward0
------------
alpha: 1"]
	140594704773760 -> 140594704774048
	140594704773760 -> 140594704423888 [dir=none]
	140594704423888 [label="bias
 (256)" fillcolor=orange]
	140594704773760 -> 140594704326064 [dir=none]
	140594704326064 [label="input
 (6, 782, 256)" fillcolor=orange]
	140594704773760 -> 140594682000064 [dir=none]
	140594682000064 [label="result1
 (6, 782, 1)" fillcolor=orange]
	140594704773760 -> 140594681999824 [dir=none]
	140594681999824 [label="result2
 (6, 782, 1)" fillcolor=orange]
	140594704773760 -> 140594681814688 [dir=none]
	140594681814688 [label="weight
 (256)" fillcolor=orange]
	140594704773760 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140594704773424 -> 140594704773760
	140594704773424 [label="AddBackward0
------------
alpha: 1"]
	140594704773232 -> 140594704773424
	140594704773232 -> 140594681907456 [dir=none]
	140594681907456 [label="bias
 (256)" fillcolor=orange]
	140594704773232 -> 140594704324704 [dir=none]
	140594704324704 [label="input
 (6, 782, 256)" fillcolor=orange]
	140594704773232 -> 140594682000224 [dir=none]
	140594682000224 [label="result1
 (6, 782, 1)" fillcolor=orange]
	140594704773232 -> 140594681999984 [dir=none]
	140594681999984 [label="result2
 (6, 782, 1)" fillcolor=orange]
	140594704773232 -> 140594681909136 [dir=none]
	140594681909136 [label="weight
 (256)" fillcolor=orange]
	140594704773232 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140594704756448 -> 140594704773232
	140594704756448 [label="AddBackward0
------------
alpha: 1"]
	140594704756064 -> 140594704756448
	140594704756064 -> 140594681491184 [dir=none]
	140594681491184 [label="bias
 (256)" fillcolor=orange]
	140594704756064 -> 140594704324944 [dir=none]
	140594704324944 [label="input
 (6, 782, 256)" fillcolor=orange]
	140594704756064 -> 140594682000384 [dir=none]
	140594682000384 [label="result1
 (6, 782, 1)" fillcolor=orange]
	140594704756064 -> 140594682000144 [dir=none]
	140594682000144 [label="result2
 (6, 782, 1)" fillcolor=orange]
	140594704756064 -> 140594681491104 [dir=none]
	140594681491104 [label="weight
 (256)" fillcolor=orange]
	140594704756064 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140594704755824 -> 140594704756064
	140594704755824 [label="AddBackward0
------------
alpha: 1"]
	140594704755440 -> 140594704755824
	140594704755440 -> 140594681579456 [dir=none]
	140594681579456 [label="bias
 (256)" fillcolor=orange]
	140594704755440 -> 140594704323584 [dir=none]
	140594704323584 [label="input
 (6, 782, 256)" fillcolor=orange]
	140594704755440 -> 140594682000544 [dir=none]
	140594682000544 [label="result1
 (6, 782, 1)" fillcolor=orange]
	140594704755440 -> 140594682000304 [dir=none]
	140594682000304 [label="result2
 (6, 782, 1)" fillcolor=orange]
	140594704755440 -> 140594681581456 [dir=none]
	140594681581456 [label="weight
 (256)" fillcolor=orange]
	140594704755440 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140594704755200 -> 140594704755440
	140594704755200 [label="AddBackward0
------------
alpha: 1"]
	140594704754912 -> 140594704755200
	140594704754912 -> 140594681685872 [dir=none]
	140594681685872 [label="bias
 (256)" fillcolor=orange]
	140594704754912 -> 140594704323824 [dir=none]
	140594704323824 [label="input
 (6, 782, 256)" fillcolor=orange]
	140594704754912 -> 140594682000704 [dir=none]
	140594682000704 [label="result1
 (6, 782, 1)" fillcolor=orange]
	140594704754912 -> 140594682000464 [dir=none]
	140594682000464 [label="result2
 (6, 782, 1)" fillcolor=orange]
	140594704754912 -> 140594681247360 [dir=none]
	140594681247360 [label="weight
 (256)" fillcolor=orange]
	140594704754912 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140594704754576 -> 140594704754912
	140594704754576 [label="AddBackward0
------------
alpha: 1"]
	140594704754192 -> 140594704754576
	140594704754192 -> 140594681344064 [dir=none]
	140594681344064 [label="bias
 (256)" fillcolor=orange]
	140594704754192 -> 140594704359072 [dir=none]
	140594704359072 [label="input
 (6, 782, 256)" fillcolor=orange]
	140594704754192 -> 140594682000864 [dir=none]
	140594682000864 [label="result1
 (6, 782, 1)" fillcolor=orange]
	140594704754192 -> 140594682000624 [dir=none]
	140594682000624 [label="result2
 (6, 782, 1)" fillcolor=orange]
	140594704754192 -> 140594681346064 [dir=none]
	140594681346064 [label="weight
 (256)" fillcolor=orange]
	140594704754192 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140594704754048 -> 140594704754192
	140594704754048 [label="AddBackward0
------------
alpha: 1"]
	140594704753664 -> 140594704754048
	140594704753664 -> 140594681347584 [dir=none]
	140594681347584 [label="bias
 (256)" fillcolor=orange]
	140594704753664 -> 140594704359312 [dir=none]
	140594704359312 [label="input
 (6, 782, 256)" fillcolor=orange]
	140594704753664 -> 140594682001024 [dir=none]
	140594682001024 [label="result1
 (6, 782, 1)" fillcolor=orange]
	140594704753664 -> 140594682000784 [dir=none]
	140594682000784 [label="result2
 (6, 782, 1)" fillcolor=orange]
	140594704753664 -> 140594681347904 [dir=none]
	140594681347904 [label="weight
 (256)" fillcolor=orange]
	140594704753664 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140594704753328 -> 140594704753664
	140594704753328 [label="AddBackward0
------------
alpha: 1"]
	140594704753040 -> 140594704753328
	140594704753040 -> 140594682001184 [dir=none]
	140594682001184 [label="other
 (6, 782, 256)" fillcolor=orange]
	140594704753040 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704752800 -> 140594704753040
	140594704752800 [label="PermuteBackward0
----------------
dims: (0, 2, 1)"]
	140594704752992 -> 140594704752800
	140594704752992 [label="ReshapeAliasBackward0
----------------------------
self_sizes: (6, 256, 23, 34)"]
	140594704731872 -> 140594704752992
	140594704731872 -> 140594704357232 [dir=none]
	140594704357232 [label="input
 (6, 2048, 23, 34)" fillcolor=orange]
	140594704731872 -> 140594681346944 [dir=none]
	140594681346944 [label="weight
 (256, 2048, 1, 1)" fillcolor=orange]
	140594704731872 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:         (256,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594704731776 -> 140594704731872
	140594704731776 -> 140594682001344 [dir=none]
	140594682001344 [label="result
 (6, 2048, 23, 34)" fillcolor=orange]
	140594704731776 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594704731392 -> 140594704731776
	140594704731392 [label="AddBackward0
------------
alpha: 1"]
	140594704731200 -> 140594704731392
	140594704731200 [label="AddBackward0
------------
alpha: 1"]
	140594704730960 -> 140594704731200
	140594704730960 -> 140594704357152 [dir=none]
	140594704357152 [label="other
 (1, 2048, 1, 1)" fillcolor=orange]
	140594704730960 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704730768 -> 140594704730960
	140594704730768 -> 140594704357072 [dir=none]
	140594704357072 [label="input
 (6, 512, 23, 34)" fillcolor=orange]
	140594704730768 -> 140594681347664 [dir=none]
	140594681347664 [label="weight
 (2048, 512, 1, 1)" fillcolor=orange]
	140594704730768 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594704730576 -> 140594704730768
	140594704730576 -> 140594682001424 [dir=none]
	140594682001424 [label="result
 (6, 512, 23, 34)" fillcolor=orange]
	140594704730576 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594704730336 -> 140594704730576
	140594704730336 [label="AddBackward0
------------
alpha: 1"]
	140594704730144 -> 140594704730336
	140594704730144 -> 140594704356992 [dir=none]
	140594704356992 [label="other
 (1, 512, 1, 1)" fillcolor=orange]
	140594704730144 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704730048 -> 140594704730144
	140594704730048 -> 140594704356912 [dir=none]
	140594704356912 [label="input
 (6, 512, 23, 34)" fillcolor=orange]
	140594704730048 -> 140594681347184 [dir=none]
	140594681347184 [label="weight
 (512, 512, 3, 3)" fillcolor=orange]
	140594704730048 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594704729856 -> 140594704730048
	140594704729856 -> 140594682001264 [dir=none]
	140594682001264 [label="result
 (6, 512, 23, 34)" fillcolor=orange]
	140594704729856 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594704729520 -> 140594704729856
	140594704729520 [label="AddBackward0
------------
alpha: 1"]
	140594704729328 -> 140594704729520
	140594704729328 -> 140594704356832 [dir=none]
	140594704356832 [label="other
 (1, 512, 1, 1)" fillcolor=orange]
	140594704729328 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704729232 -> 140594704729328
	140594704729232 -> 140594704356752 [dir=none]
	140594704356752 [label="input
 (6, 2048, 23, 34)" fillcolor=orange]
	140594704729232 -> 140594681346544 [dir=none]
	140594681346544 [label="weight
 (512, 2048, 1, 1)" fillcolor=orange]
	140594704729232 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594704731248 -> 140594704729232
	140594704731248 -> 140594682001584 [dir=none]
	140594682001584 [label="result
 (6, 2048, 23, 34)" fillcolor=orange]
	140594704731248 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594704728944 -> 140594704731248
	140594704728944 [label="AddBackward0
------------
alpha: 1"]
	140594704728752 -> 140594704728944
	140594704728752 [label="AddBackward0
------------
alpha: 1"]
	140594704728512 -> 140594704728752
	140594704728512 -> 140594704356672 [dir=none]
	140594704356672 [label="other
 (1, 2048, 1, 1)" fillcolor=orange]
	140594704728512 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704728320 -> 140594704728512
	140594704728320 -> 140594704356592 [dir=none]
	140594704356592 [label="input
 (6, 512, 23, 34)" fillcolor=orange]
	140594704728320 -> 140594681345984 [dir=none]
	140594681345984 [label="weight
 (2048, 512, 1, 1)" fillcolor=orange]
	140594704728320 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594704728224 -> 140594704728320
	140594704728224 -> 140594682001824 [dir=none]
	140594682001824 [label="result
 (6, 512, 23, 34)" fillcolor=orange]
	140594704728224 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594704703248 -> 140594704728224
	140594704703248 [label="AddBackward0
------------
alpha: 1"]
	140594704703056 -> 140594704703248
	140594704703056 -> 140594704356512 [dir=none]
	140594704356512 [label="other
 (1, 512, 1, 1)" fillcolor=orange]
	140594704703056 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704702864 -> 140594704703056
	140594704702864 -> 140594704356272 [dir=none]
	140594704356272 [label="input
 (6, 512, 23, 34)" fillcolor=orange]
	140594704702864 -> 140594681345504 [dir=none]
	140594681345504 [label="weight
 (512, 512, 3, 3)" fillcolor=orange]
	140594704702864 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594704702768 -> 140594704702864
	140594704702768 -> 140594682001904 [dir=none]
	140594682001904 [label="result
 (6, 512, 23, 34)" fillcolor=orange]
	140594704702768 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594704702528 -> 140594704702768
	140594704702528 [label="AddBackward0
------------
alpha: 1"]
	140594704702336 -> 140594704702528
	140594704702336 -> 140594704356432 [dir=none]
	140594704356432 [label="other
 (1, 512, 1, 1)" fillcolor=orange]
	140594704702336 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704702144 -> 140594704702336
	140594704702144 -> 140594704356192 [dir=none]
	140594704356192 [label="input
 (6, 2048, 23, 34)" fillcolor=orange]
	140594704702144 -> 140594681344864 [dir=none]
	140594681344864 [label="weight
 (512, 2048, 1, 1)" fillcolor=orange]
	140594704702144 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594704728896 -> 140594704702144
	140594704728896 -> 140594682001104 [dir=none]
	140594682001104 [label="result
 (6, 2048, 23, 34)" fillcolor=orange]
	140594704728896 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594704701856 -> 140594704728896
	140594704701856 [label="AddBackward0
------------
alpha: 1"]
	140594704701664 -> 140594704701856
	140594704701664 [label="AddBackward0
------------
alpha: 1"]
	140594704701328 -> 140594704701664
	140594704701328 -> 140594704356112 [dir=none]
	140594704356112 [label="other
 (1, 2048, 1, 1)" fillcolor=orange]
	140594704701328 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704701136 -> 140594704701328
	140594704701136 -> 140594704356032 [dir=none]
	140594704356032 [label="input
 (6, 512, 23, 34)" fillcolor=orange]
	140594704701136 -> 140594681344304 [dir=none]
	140594681344304 [label="weight
 (2048, 512, 1, 1)" fillcolor=orange]
	140594704701136 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594704701040 -> 140594704701136
	140594704701040 -> 140594682002144 [dir=none]
	140594682002144 [label="result
 (6, 512, 23, 34)" fillcolor=orange]
	140594704701040 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594704700800 -> 140594704701040
	140594704700800 [label="AddBackward0
------------
alpha: 1"]
	140594704700608 -> 140594704700800
	140594704700608 -> 140594704355952 [dir=none]
	140594704355952 [label="other
 (1, 512, 1, 1)" fillcolor=orange]
	140594704700608 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704700416 -> 140594704700608
	140594704700416 -> 140594704355872 [dir=none]
	140594704355872 [label="input
 (6, 512, 45, 68)" fillcolor=orange]
	140594704700416 -> 140594681249520 [dir=none]
	140594681249520 [label="weight
 (512, 512, 3, 3)" fillcolor=orange]
	140594704700416 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (2, 2)
transposed    :          False
weight        : [saved tensor]"]
	140594704700224 -> 140594704700416
	140594704700224 -> 140594682001664 [dir=none]
	140594682001664 [label="result
 (6, 512, 45, 68)" fillcolor=orange]
	140594704700224 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594704699984 -> 140594704700224
	140594704699984 [label="AddBackward0
------------
alpha: 1"]
	140594704699792 -> 140594704699984
	140594704699792 -> 140594704355792 [dir=none]
	140594704355792 [label="other
 (1, 512, 1, 1)" fillcolor=orange]
	140594704699792 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704699600 -> 140594704699792
	140594704699600 -> 140594704355712 [dir=none]
	140594704355712 [label="input
 (6, 1024, 45, 68)" fillcolor=orange]
	140594704699600 -> 140594681248880 [dir=none]
	140594681248880 [label="weight
 (512, 1024, 1, 1)" fillcolor=orange]
	140594704699600 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594704699552 -> 140594704699600
	140594704699552 -> 140594682001744 [dir=none]
	140594682001744 [label="result
 (6, 1024, 45, 68)" fillcolor=orange]
	140594704699552 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594704678720 -> 140594704699552
	140594704678720 [label="AddBackward0
------------
alpha: 1"]
	140594704678528 -> 140594704678720
	140594704678528 [label="AddBackward0
------------
alpha: 1"]
	140594704678192 -> 140594704678528
	140594704678192 -> 140594704355632 [dir=none]
	140594704355632 [label="other
 (1, 1024, 1, 1)" fillcolor=orange]
	140594704678192 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704678000 -> 140594704678192
	140594704678000 -> 140594704355552 [dir=none]
	140594704355552 [label="input
 (6, 256, 45, 68)" fillcolor=orange]
	140594704678000 -> 140594681247760 [dir=none]
	140594681247760 [label="weight
 (1024, 256, 1, 1)" fillcolor=orange]
	140594704678000 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594704677904 -> 140594704678000
	140594704677904 -> 140594682002384 [dir=none]
	140594682002384 [label="result
 (6, 256, 45, 68)" fillcolor=orange]
	140594704677904 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594704677664 -> 140594704677904
	140594704677664 [label="AddBackward0
------------
alpha: 1"]
	140594704677472 -> 140594704677664
	140594704677472 -> 140594704355472 [dir=none]
	140594704355472 [label="other
 (1, 256, 1, 1)" fillcolor=orange]
	140594704677472 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704677280 -> 140594704677472
	140594704677280 -> 140594704355392 [dir=none]
	140594704355392 [label="input
 (6, 256, 45, 68)" fillcolor=orange]
	140594704677280 -> 140594681247280 [dir=none]
	140594681247280 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	140594704677280 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594704677088 -> 140594704677280
	140594704677088 -> 140594682002064 [dir=none]
	140594682002064 [label="result
 (6, 256, 45, 68)" fillcolor=orange]
	140594704677088 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594704676848 -> 140594704677088
	140594704676848 [label="AddBackward0
------------
alpha: 1"]
	140594704676656 -> 140594704676848
	140594704676656 -> 140594704430720 [dir=none]
	140594704430720 [label="other
 (1, 256, 1, 1)" fillcolor=orange]
	140594704676656 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704676464 -> 140594704676656
	140594704676464 -> 140594704383808 [dir=none]
	140594704383808 [label="input
 (6, 1024, 45, 68)" fillcolor=orange]
	140594704676464 -> 140594681246640 [dir=none]
	140594681246640 [label="weight
 (256, 1024, 1, 1)" fillcolor=orange]
	140594704676464 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594704678576 -> 140594704676464
	140594704678576 -> 140594682001504 [dir=none]
	140594682001504 [label="result
 (6, 1024, 45, 68)" fillcolor=orange]
	140594704678576 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594704676128 -> 140594704678576
	140594704676128 [label="AddBackward0
------------
alpha: 1"]
	140594704675552 -> 140594704676128
	140594704675552 [label="AddBackward0
------------
alpha: 1"]
	140594704675024 -> 140594704675552
	140594704675024 -> 140594704383728 [dir=none]
	140594704383728 [label="other
 (1, 1024, 1, 1)" fillcolor=orange]
	140594704675024 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704675600 -> 140594704675024
	140594704675600 -> 140594704383648 [dir=none]
	140594704383648 [label="input
 (6, 256, 45, 68)" fillcolor=orange]
	140594704675600 -> 140594681246080 [dir=none]
	140594681246080 [label="weight
 (1024, 256, 1, 1)" fillcolor=orange]
	140594704675600 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594704669952 -> 140594704675600
	140594704669952 -> 140594682002624 [dir=none]
	140594682002624 [label="result
 (6, 256, 45, 68)" fillcolor=orange]
	140594704669952 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594704668992 -> 140594704669952
	140594704668992 [label="AddBackward0
------------
alpha: 1"]
	140594704668560 -> 140594704668992
	140594704668560 -> 140594704383568 [dir=none]
	140594704383568 [label="other
 (1, 256, 1, 1)" fillcolor=orange]
	140594704668560 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704668080 -> 140594704668560
	140594704668080 -> 140594704383488 [dir=none]
	140594704383488 [label="input
 (6, 256, 45, 68)" fillcolor=orange]
	140594704668080 -> 140594681687872 [dir=none]
	140594681687872 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	140594704668080 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594704667888 -> 140594704668080
	140594704667888 -> 140594682002304 [dir=none]
	140594682002304 [label="result
 (6, 256, 45, 68)" fillcolor=orange]
	140594704667888 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594704667792 -> 140594704667888
	140594704667792 [label="AddBackward0
------------
alpha: 1"]
	140594704667696 -> 140594704667792
	140594704667696 -> 140594704383408 [dir=none]
	140594704383408 [label="other
 (1, 256, 1, 1)" fillcolor=orange]
	140594704667696 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704667648 -> 140594704667696
	140594704667648 -> 140594704383328 [dir=none]
	140594704383328 [label="input
 (6, 1024, 45, 68)" fillcolor=orange]
	140594704667648 -> 140594681687232 [dir=none]
	140594681687232 [label="weight
 (256, 1024, 1, 1)" fillcolor=orange]
	140594704667648 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594704676176 -> 140594704667648
	140594704676176 -> 140594682001984 [dir=none]
	140594682001984 [label="result
 (6, 1024, 45, 68)" fillcolor=orange]
	140594704676176 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594704667024 -> 140594704676176
	140594704667024 [label="AddBackward0
------------
alpha: 1"]
	140594704666928 -> 140594704667024
	140594704666928 [label="AddBackward0
------------
alpha: 1"]
	140594704666688 -> 140594704666928
	140594704666688 -> 140594704383248 [dir=none]
	140594704383248 [label="other
 (1, 1024, 1, 1)" fillcolor=orange]
	140594704666688 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594713322448 -> 140594704666688
	140594713322448 -> 140594704383168 [dir=none]
	140594704383168 [label="input
 (6, 256, 45, 68)" fillcolor=orange]
	140594713322448 -> 140594681686672 [dir=none]
	140594681686672 [label="weight
 (1024, 256, 1, 1)" fillcolor=orange]
	140594713322448 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594713321728 -> 140594713322448
	140594713321728 -> 140594682002864 [dir=none]
	140594682002864 [label="result
 (6, 256, 45, 68)" fillcolor=orange]
	140594713321728 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594713322544 -> 140594713321728
	140594713322544 [label="AddBackward0
------------
alpha: 1"]
	140594713321776 -> 140594713322544
	140594713321776 -> 140594704383088 [dir=none]
	140594704383088 [label="other
 (1, 256, 1, 1)" fillcolor=orange]
	140594713321776 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594713321680 -> 140594713321776
	140594713321680 -> 140594704383008 [dir=none]
	140594704383008 [label="input
 (6, 256, 45, 68)" fillcolor=orange]
	140594713321680 -> 140594681686192 [dir=none]
	140594681686192 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	140594713321680 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594713325424 -> 140594713321680
	140594713325424 -> 140594682002544 [dir=none]
	140594682002544 [label="result
 (6, 256, 45, 68)" fillcolor=orange]
	140594713325424 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594713325280 -> 140594713325424
	140594713325280 [label="AddBackward0
------------
alpha: 1"]
	140594713325232 -> 140594713325280
	140594713325232 -> 140594704382928 [dir=none]
	140594704382928 [label="other
 (1, 256, 1, 1)" fillcolor=orange]
	140594713325232 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594713324944 -> 140594713325232
	140594713324944 -> 140594704382848 [dir=none]
	140594704382848 [label="input
 (6, 1024, 45, 68)" fillcolor=orange]
	140594713324944 -> 140594681685552 [dir=none]
	140594681685552 [label="weight
 (256, 1024, 1, 1)" fillcolor=orange]
	140594713324944 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594704666832 -> 140594713324944
	140594704666832 -> 140594682002224 [dir=none]
	140594682002224 [label="result
 (6, 1024, 45, 68)" fillcolor=orange]
	140594704666832 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594713323600 -> 140594704666832
	140594713323600 [label="AddBackward0
------------
alpha: 1"]
	140594713321872 -> 140594713323600
	140594713321872 [label="AddBackward0
------------
alpha: 1"]
	140594713877616 -> 140594713321872
	140594713877616 -> 140594704382768 [dir=none]
	140594704382768 [label="other
 (1, 1024, 1, 1)" fillcolor=orange]
	140594713877616 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594713874832 -> 140594713877616
	140594713874832 -> 140594704382688 [dir=none]
	140594704382688 [label="input
 (6, 256, 45, 68)" fillcolor=orange]
	140594713874832 -> 140594681684992 [dir=none]
	140594681684992 [label="weight
 (1024, 256, 1, 1)" fillcolor=orange]
	140594713874832 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594713874736 -> 140594713874832
	140594713874736 -> 140594682003104 [dir=none]
	140594682003104 [label="result
 (6, 256, 45, 68)" fillcolor=orange]
	140594713874736 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594713209968 -> 140594713874736
	140594713209968 [label="AddBackward0
------------
alpha: 1"]
	140594713206896 -> 140594713209968
	140594713206896 -> 140594704382608 [dir=none]
	140594704382608 [label="other
 (1, 256, 1, 1)" fillcolor=orange]
	140594713206896 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594713209632 -> 140594713206896
	140594713209632 -> 140594704382528 [dir=none]
	140594704382528 [label="input
 (6, 256, 45, 68)" fillcolor=orange]
	140594713209632 -> 140594681684512 [dir=none]
	140594681684512 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	140594713209632 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594704682048 -> 140594713209632
	140594704682048 -> 140594682002784 [dir=none]
	140594682002784 [label="result
 (6, 256, 45, 68)" fillcolor=orange]
	140594704682048 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594704681616 -> 140594704682048
	140594704681616 [label="AddBackward0
------------
alpha: 1"]
	140594704681232 -> 140594704681616
	140594704681232 -> 140594704382448 [dir=none]
	140594704382448 [label="other
 (1, 256, 1, 1)" fillcolor=orange]
	140594704681232 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704680608 -> 140594704681232
	140594704680608 -> 140594704382368 [dir=none]
	140594704382368 [label="input
 (6, 1024, 45, 68)" fillcolor=orange]
	140594704680608 -> 140594681581376 [dir=none]
	140594681581376 [label="weight
 (256, 1024, 1, 1)" fillcolor=orange]
	140594704680608 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594713325376 -> 140594704680608
	140594713325376 -> 140594682002464 [dir=none]
	140594682002464 [label="result
 (6, 1024, 45, 68)" fillcolor=orange]
	140594713325376 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594704679648 -> 140594713325376
	140594704679648 [label="AddBackward0
------------
alpha: 1"]
	140594704679168 -> 140594704679648
	140594704679168 [label="AddBackward0
------------
alpha: 1"]
	140594704681040 -> 140594704679168
	140594704681040 -> 140594704382288 [dir=none]
	140594704382288 [label="other
 (1, 1024, 1, 1)" fillcolor=orange]
	140594704681040 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594682141040 -> 140594704681040
	140594682141040 -> 140594704382208 [dir=none]
	140594704382208 [label="input
 (6, 256, 45, 68)" fillcolor=orange]
	140594682141040 -> 140594681580816 [dir=none]
	140594681580816 [label="weight
 (1024, 256, 1, 1)" fillcolor=orange]
	140594682141040 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594682140848 -> 140594682141040
	140594682140848 -> 140594682003344 [dir=none]
	140594682003344 [label="result
 (6, 256, 45, 68)" fillcolor=orange]
	140594682140848 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594682140704 -> 140594682140848
	140594682140704 [label="AddBackward0
------------
alpha: 1"]
	140594682140512 -> 140594682140704
	140594682140512 -> 140594704382128 [dir=none]
	140594704382128 [label="other
 (1, 256, 1, 1)" fillcolor=orange]
	140594682140512 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594682140416 -> 140594682140512
	140594682140416 -> 140594704381888 [dir=none]
	140594704381888 [label="input
 (6, 256, 45, 68)" fillcolor=orange]
	140594682140416 -> 140594681580336 [dir=none]
	140594681580336 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	140594682140416 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594682140224 -> 140594682140416
	140594682140224 -> 140594682003024 [dir=none]
	140594682003024 [label="result
 (6, 256, 45, 68)" fillcolor=orange]
	140594682140224 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594682139984 -> 140594682140224
	140594682139984 [label="AddBackward0
------------
alpha: 1"]
	140594682139792 -> 140594682139984
	140594682139792 -> 140594704382048 [dir=none]
	140594704382048 [label="other
 (1, 256, 1, 1)" fillcolor=orange]
	140594682139792 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594682139600 -> 140594682139792
	140594682139600 -> 140594704381808 [dir=none]
	140594704381808 [label="input
 (6, 1024, 45, 68)" fillcolor=orange]
	140594682139600 -> 140594681579696 [dir=none]
	140594681579696 [label="weight
 (256, 1024, 1, 1)" fillcolor=orange]
	140594682139600 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594704679120 -> 140594682139600
	140594704679120 -> 140594682003184 [dir=none]
	140594682003184 [label="result
 (6, 1024, 45, 68)" fillcolor=orange]
	140594704679120 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594682139216 -> 140594704679120
	140594682139216 [label="AddBackward0
------------
alpha: 1"]
	140594682139120 -> 140594682139216
	140594682139120 [label="AddBackward0
------------
alpha: 1"]
	140594682138880 -> 140594682139120
	140594682138880 -> 140594704381728 [dir=none]
	140594704381728 [label="other
 (1, 1024, 1, 1)" fillcolor=orange]
	140594682138880 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594682138784 -> 140594682138880
	140594682138784 -> 140594704381648 [dir=none]
	140594704381648 [label="input
 (6, 256, 45, 68)" fillcolor=orange]
	140594682138784 -> 140594681579136 [dir=none]
	140594681579136 [label="weight
 (1024, 256, 1, 1)" fillcolor=orange]
	140594682138784 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594682141280 -> 140594682138784
	140594682141280 -> 140594682002704 [dir=none]
	140594682002704 [label="result
 (6, 256, 45, 68)" fillcolor=orange]
	140594682141280 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594682141472 -> 140594682141280
	140594682141472 [label="AddBackward0
------------
alpha: 1"]
	140594682141568 -> 140594682141472
	140594682141568 -> 140594704381568 [dir=none]
	140594704381568 [label="other
 (1, 256, 1, 1)" fillcolor=orange]
	140594682141568 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594682141664 -> 140594682141568
	140594682141664 -> 140594704381488 [dir=none]
	140594704381488 [label="input
 (6, 256, 90, 135)" fillcolor=orange]
	140594682141664 -> 140594681578656 [dir=none]
	140594681578656 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	140594682141664 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (2, 2)
transposed    :          False
weight        : [saved tensor]"]
	140594682141760 -> 140594682141664
	140594682141760 -> 140594682000944 [dir=none]
	140594682000944 [label="result
 (6, 256, 90, 135)" fillcolor=orange]
	140594682141760 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594682141904 -> 140594682141760
	140594682141904 [label="AddBackward0
------------
alpha: 1"]
	140594682142000 -> 140594682141904
	140594682142000 -> 140594704381408 [dir=none]
	140594704381408 [label="other
 (1, 256, 1, 1)" fillcolor=orange]
	140594682142000 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594682142096 -> 140594682142000
	140594682142096 -> 140594704381328 [dir=none]
	140594704381328 [label="input
 (6, 512, 90, 135)" fillcolor=orange]
	140594682142096 -> 140594681578016 [dir=none]
	140594681578016 [label="weight
 (256, 512, 1, 1)" fillcolor=orange]
	140594682142096 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594682142192 -> 140594682142096
	140594682142192 -> 140594682002944 [dir=none]
	140594682002944 [label="result
 (6, 512, 90, 135)" fillcolor=orange]
	140594682142192 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594682142336 -> 140594682142192
	140594682142336 [label="AddBackward0
------------
alpha: 1"]
	140594682142432 -> 140594682142336
	140594682142432 [label="AddBackward0
------------
alpha: 1"]
	140594682142576 -> 140594682142432
	140594682142576 -> 140594704381248 [dir=none]
	140594704381248 [label="other
 (1, 512, 1, 1)" fillcolor=orange]
	140594682142576 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594682142672 -> 140594682142576
	140594682142672 -> 140594704381168 [dir=none]
	140594704381168 [label="input
 (6, 128, 90, 135)" fillcolor=orange]
	140594682142672 -> 140594681490784 [dir=none]
	140594681490784 [label="weight
 (512, 128, 1, 1)" fillcolor=orange]
	140594682142672 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594682142480 -> 140594682142672
	140594682142480 -> 140594682003264 [dir=none]
	140594682003264 [label="result
 (6, 128, 90, 135)" fillcolor=orange]
	140594682142480 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594519032064 -> 140594682142480
	140594519032064 [label="AddBackward0
------------
alpha: 1"]
	140594519032160 -> 140594519032064
	140594519032160 -> 140594704381088 [dir=none]
	140594704381088 [label="other
 (1, 128, 1, 1)" fillcolor=orange]
	140594519032160 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519032256 -> 140594519032160
	140594519032256 -> 140594704381008 [dir=none]
	140594704381008 [label="input
 (6, 128, 90, 135)" fillcolor=orange]
	140594519032256 -> 140594681490304 [dir=none]
	140594681490304 [label="weight
 (128, 128, 3, 3)" fillcolor=orange]
	140594519032256 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594519032352 -> 140594519032256
	140594519032352 -> 140594519093472 [dir=none]
	140594519093472 [label="result
 (6, 128, 90, 135)" fillcolor=orange]
	140594519032352 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594519032496 -> 140594519032352
	140594519032496 [label="AddBackward0
------------
alpha: 1"]
	140594519032592 -> 140594519032496
	140594519032592 -> 140594704380928 [dir=none]
	140594704380928 [label="other
 (1, 128, 1, 1)" fillcolor=orange]
	140594519032592 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519032688 -> 140594519032592
	140594519032688 -> 140594704380848 [dir=none]
	140594704380848 [label="input
 (6, 512, 90, 135)" fillcolor=orange]
	140594519032688 -> 140594681489824 [dir=none]
	140594681489824 [label="weight
 (128, 512, 1, 1)" fillcolor=orange]
	140594519032688 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594682142384 -> 140594519032688
	140594682142384 -> 140594519093312 [dir=none]
	140594519093312 [label="result
 (6, 512, 90, 135)" fillcolor=orange]
	140594682142384 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594519032880 -> 140594682142384
	140594519032880 [label="AddBackward0
------------
alpha: 1"]
	140594519032976 -> 140594519032880
	140594519032976 [label="AddBackward0
------------
alpha: 1"]
	140594519033120 -> 140594519032976
	140594519033120 -> 140594704380768 [dir=none]
	140594704380768 [label="other
 (1, 512, 1, 1)" fillcolor=orange]
	140594519033120 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519033216 -> 140594519033120
	140594519033216 -> 140594704380688 [dir=none]
	140594704380688 [label="input
 (6, 128, 90, 135)" fillcolor=orange]
	140594519033216 -> 140594681489264 [dir=none]
	140594681489264 [label="weight
 (512, 128, 1, 1)" fillcolor=orange]
	140594519033216 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594519033312 -> 140594519033216
	140594519033312 -> 140594519093712 [dir=none]
	140594519093712 [label="result
 (6, 128, 90, 135)" fillcolor=orange]
	140594519033312 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594519033456 -> 140594519033312
	140594519033456 [label="AddBackward0
------------
alpha: 1"]
	140594519033552 -> 140594519033456
	140594519033552 -> 140594704380608 [dir=none]
	140594704380608 [label="other
 (1, 128, 1, 1)" fillcolor=orange]
	140594519033552 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519033648 -> 140594519033552
	140594519033648 -> 140594704380528 [dir=none]
	140594704380528 [label="input
 (6, 128, 90, 135)" fillcolor=orange]
	140594519033648 -> 140594681488784 [dir=none]
	140594681488784 [label="weight
 (128, 128, 3, 3)" fillcolor=orange]
	140594519033648 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594519033744 -> 140594519033648
	140594519033744 -> 140594519093872 [dir=none]
	140594519093872 [label="result
 (6, 128, 90, 135)" fillcolor=orange]
	140594519033744 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594519033888 -> 140594519033744
	140594519033888 [label="AddBackward0
------------
alpha: 1"]
	140594519033984 -> 140594519033888
	140594519033984 -> 140594704380448 [dir=none]
	140594704380448 [label="other
 (1, 128, 1, 1)" fillcolor=orange]
	140594519033984 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519034080 -> 140594519033984
	140594519034080 -> 140594704380368 [dir=none]
	140594704380368 [label="input
 (6, 512, 90, 135)" fillcolor=orange]
	140594519034080 -> 140594681488144 [dir=none]
	140594681488144 [label="weight
 (128, 512, 1, 1)" fillcolor=orange]
	140594519034080 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594519032928 -> 140594519034080
	140594519032928 -> 140594519094032 [dir=none]
	140594519094032 [label="result
 (6, 512, 90, 135)" fillcolor=orange]
	140594519032928 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594519034272 -> 140594519032928
	140594519034272 [label="AddBackward0
------------
alpha: 1"]
	140594519034368 -> 140594519034272
	140594519034368 [label="AddBackward0
------------
alpha: 1"]
	140594519034512 -> 140594519034368
	140594519034512 -> 140594704380288 [dir=none]
	140594704380288 [label="other
 (1, 512, 1, 1)" fillcolor=orange]
	140594519034512 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519034608 -> 140594519034512
	140594519034608 -> 140594704380208 [dir=none]
	140594704380208 [label="input
 (6, 128, 90, 135)" fillcolor=orange]
	140594519034608 -> 140594681487584 [dir=none]
	140594681487584 [label="weight
 (512, 128, 1, 1)" fillcolor=orange]
	140594519034608 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594519034704 -> 140594519034608
	140594519034704 -> 140594519094192 [dir=none]
	140594519094192 [label="result
 (6, 128, 90, 135)" fillcolor=orange]
	140594519034704 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594519034848 -> 140594519034704
	140594519034848 [label="AddBackward0
------------
alpha: 1"]
	140594519034944 -> 140594519034848
	140594519034944 -> 140594704380128 [dir=none]
	140594704380128 [label="other
 (1, 128, 1, 1)" fillcolor=orange]
	140594519034944 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519035040 -> 140594519034944
	140594519035040 -> 140594704380048 [dir=none]
	140594704380048 [label="input
 (6, 128, 90, 135)" fillcolor=orange]
	140594519035040 -> 140594681908896 [dir=none]
	140594681908896 [label="weight
 (128, 128, 3, 3)" fillcolor=orange]
	140594519035040 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594519035136 -> 140594519035040
	140594519035136 -> 140594519094272 [dir=none]
	140594519094272 [label="result
 (6, 128, 90, 135)" fillcolor=orange]
	140594519035136 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594519035280 -> 140594519035136
	140594519035280 [label="AddBackward0
------------
alpha: 1"]
	140594519035376 -> 140594519035280
	140594519035376 -> 140594704433040 [dir=none]
	140594704433040 [label="other
 (1, 128, 1, 1)" fillcolor=orange]
	140594519035376 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519035472 -> 140594519035376
	140594519035472 -> 140594704432960 [dir=none]
	140594704432960 [label="input
 (6, 512, 90, 135)" fillcolor=orange]
	140594519035472 -> 140594681908256 [dir=none]
	140594681908256 [label="weight
 (128, 512, 1, 1)" fillcolor=orange]
	140594519035472 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594519034320 -> 140594519035472
	140594519034320 -> 140594519094352 [dir=none]
	140594519094352 [label="result
 (6, 512, 90, 135)" fillcolor=orange]
	140594519034320 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594519035664 -> 140594519034320
	140594519035664 [label="AddBackward0
------------
alpha: 1"]
	140594519035760 -> 140594519035664
	140594519035760 [label="AddBackward0
------------
alpha: 1"]
	140594519035856 -> 140594519035760
	140594519035856 -> 140594704432560 [dir=none]
	140594704432560 [label="other
 (1, 512, 1, 1)" fillcolor=orange]
	140594519035856 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519019680 -> 140594519035856
	140594519019680 -> 140594704432800 [dir=none]
	140594704432800 [label="input
 (6, 128, 90, 135)" fillcolor=orange]
	140594519019680 -> 140594681907696 [dir=none]
	140594681907696 [label="weight
 (512, 128, 1, 1)" fillcolor=orange]
	140594519019680 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594519019776 -> 140594519019680
	140594519019776 -> 140594519094432 [dir=none]
	140594519094432 [label="result
 (6, 128, 90, 135)" fillcolor=orange]
	140594519019776 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594519019920 -> 140594519019776
	140594519019920 [label="AddBackward0
------------
alpha: 1"]
	140594519020016 -> 140594519019920
	140594519020016 -> 140594704432400 [dir=none]
	140594704432400 [label="other
 (1, 128, 1, 1)" fillcolor=orange]
	140594519020016 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519020112 -> 140594519020016
	140594519020112 -> 140594704432640 [dir=none]
	140594704432640 [label="input
 (6, 128, 180, 270)" fillcolor=orange]
	140594519020112 -> 140594681907216 [dir=none]
	140594681907216 [label="weight
 (128, 128, 3, 3)" fillcolor=orange]
	140594519020112 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (2, 2)
transposed    :          False
weight        : [saved tensor]"]
	140594519020208 -> 140594519020112
	140594519020208 -> 140594519094592 [dir=none]
	140594519094592 [label="result
 (6, 128, 180, 270)" fillcolor=orange]
	140594519020208 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594519020352 -> 140594519020208
	140594519020352 [label="AddBackward0
------------
alpha: 1"]
	140594519020448 -> 140594519020352
	140594519020448 -> 140594704432240 [dir=none]
	140594704432240 [label="other
 (1, 128, 1, 1)" fillcolor=orange]
	140594519020448 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519020544 -> 140594519020448
	140594519020544 -> 140594704432480 [dir=none]
	140594704432480 [label="input
 (6, 256, 180, 270)" fillcolor=orange]
	140594519020544 -> 140594681906576 [dir=none]
	140594681906576 [label="weight
 (128, 256, 1, 1)" fillcolor=orange]
	140594519020544 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594519020640 -> 140594519020544
	140594519020640 -> 140594519094672 [dir=none]
	140594519094672 [label="result
 (6, 256, 180, 270)" fillcolor=orange]
	140594519020640 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594519020784 -> 140594519020640
	140594519020784 [label="AddBackward0
------------
alpha: 1"]
	140594519020880 -> 140594519020784
	140594519020880 [label="AddBackward0
------------
alpha: 1"]
	140594519021024 -> 140594519020880
	140594519021024 -> 140594704432080 [dir=none]
	140594704432080 [label="other
 (1, 256, 1, 1)" fillcolor=orange]
	140594519021024 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519021120 -> 140594519021024
	140594519021120 -> 140594704432320 [dir=none]
	140594704432320 [label="input
 (6, 64, 180, 270)" fillcolor=orange]
	140594519021120 -> 140594681905456 [dir=none]
	140594681905456 [label="weight
 (256, 64, 1, 1)" fillcolor=orange]
	140594519021120 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594519021216 -> 140594519021120
	140594519021216 -> 140594519093632 [dir=none]
	140594519093632 [label="result
 (6, 64, 180, 270)" fillcolor=orange]
	140594519021216 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594519021360 -> 140594519021216
	140594519021360 [label="AddBackward0
------------
alpha: 1"]
	140594519021456 -> 140594519021360
	140594519021456 -> 140594704431920 [dir=none]
	140594704431920 [label="other
 (1, 64, 1, 1)" fillcolor=orange]
	140594519021456 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519021552 -> 140594519021456
	140594519021552 -> 140594704432160 [dir=none]
	140594704432160 [label="input
 (6, 64, 180, 270)" fillcolor=orange]
	140594519021552 -> 140594681814768 [dir=none]
	140594681814768 [label="weight
 (64, 64, 3, 3)" fillcolor=orange]
	140594519021552 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594519021648 -> 140594519021552
	140594519021648 -> 140594519093792 [dir=none]
	140594519093792 [label="result
 (6, 64, 180, 270)" fillcolor=orange]
	140594519021648 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594519021792 -> 140594519021648
	140594519021792 [label="AddBackward0
------------
alpha: 1"]
	140594519021888 -> 140594519021792
	140594519021888 -> 140594704431520 [dir=none]
	140594704431520 [label="other
 (1, 64, 1, 1)" fillcolor=orange]
	140594519021888 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519021984 -> 140594519021888
	140594519021984 -> 140594704432000 [dir=none]
	140594704432000 [label="input
 (6, 256, 180, 270)" fillcolor=orange]
	140594519021984 -> 140594681814128 [dir=none]
	140594681814128 [label="weight
 (64, 256, 1, 1)" fillcolor=orange]
	140594519021984 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594519020832 -> 140594519021984
	140594519020832 -> 140594519093952 [dir=none]
	140594519093952 [label="result
 (6, 256, 180, 270)" fillcolor=orange]
	140594519020832 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594519022176 -> 140594519020832
	140594519022176 [label="AddBackward0
------------
alpha: 1"]
	140594519022272 -> 140594519022176
	140594519022272 [label="AddBackward0
------------
alpha: 1"]
	140594519022416 -> 140594519022272
	140594519022416 -> 140594704431200 [dir=none]
	140594704431200 [label="other
 (1, 256, 1, 1)" fillcolor=orange]
	140594519022416 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519022512 -> 140594519022416
	140594519022512 -> 140594704431840 [dir=none]
	140594704431840 [label="input
 (6, 64, 180, 270)" fillcolor=orange]
	140594519022512 -> 140594681813568 [dir=none]
	140594681813568 [label="weight
 (256, 64, 1, 1)" fillcolor=orange]
	140594519022512 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594519022608 -> 140594519022512
	140594519022608 -> 140594519094112 [dir=none]
	140594519094112 [label="result
 (6, 64, 180, 270)" fillcolor=orange]
	140594519022608 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594519022752 -> 140594519022608
	140594519022752 [label="AddBackward0
------------
alpha: 1"]
	140594519022848 -> 140594519022752
	140594519022848 -> 140594704430320 [dir=none]
	140594704430320 [label="other
 (1, 64, 1, 1)" fillcolor=orange]
	140594519022848 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519022944 -> 140594519022848
	140594519022944 -> 140594704431360 [dir=none]
	140594704431360 [label="input
 (6, 64, 180, 270)" fillcolor=orange]
	140594519022944 -> 140594681813088 [dir=none]
	140594681813088 [label="weight
 (64, 64, 3, 3)" fillcolor=orange]
	140594519022944 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594519023040 -> 140594519022944
	140594519023040 -> 140594519093552 [dir=none]
	140594519093552 [label="result
 (6, 64, 180, 270)" fillcolor=orange]
	140594519023040 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594519023184 -> 140594519023040
	140594519023184 [label="AddBackward0
------------
alpha: 1"]
	140594519023280 -> 140594519023184
	140594519023280 -> 140594704431760 [dir=none]
	140594704431760 [label="other
 (1, 64, 1, 1)" fillcolor=orange]
	140594519023280 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519023376 -> 140594519023280
	140594519023376 -> 140594704431440 [dir=none]
	140594704431440 [label="input
 (6, 256, 180, 270)" fillcolor=orange]
	140594519023376 -> 140594681812448 [dir=none]
	140594681812448 [label="weight
 (64, 256, 1, 1)" fillcolor=orange]
	140594519023376 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594519022224 -> 140594519023376
	140594519022224 -> 140594519094752 [dir=none]
	140594519094752 [label="result
 (6, 256, 180, 270)" fillcolor=orange]
	140594519022224 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594519023568 -> 140594519022224
	140594519023568 [label="AddBackward0
------------
alpha: 1"]
	140594519023088 -> 140594519023568
	140594519023088 [label="AddBackward0
------------
alpha: 1"]
	140594519073024 -> 140594519023088
	140594519073024 -> 140594704430400 [dir=none]
	140594704430400 [label="other
 (1, 256, 1, 1)" fillcolor=orange]
	140594519073024 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519073120 -> 140594519073024
	140594519073120 -> 140594704431280 [dir=none]
	140594704431280 [label="input
 (6, 64, 180, 270)" fillcolor=orange]
	140594519073120 -> 140594681811888 [dir=none]
	140594681811888 [label="weight
 (256, 64, 1, 1)" fillcolor=orange]
	140594519073120 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594519073216 -> 140594519073120
	140594519073216 -> 140594519094832 [dir=none]
	140594519094832 [label="result
 (6, 64, 180, 270)" fillcolor=orange]
	140594519073216 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594519073360 -> 140594519073216
	140594519073360 [label="AddBackward0
------------
alpha: 1"]
	140594519073456 -> 140594519073360
	140594519073456 -> 140594704430960 [dir=none]
	140594704430960 [label="other
 (1, 64, 1, 1)" fillcolor=orange]
	140594519073456 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519073552 -> 140594519073456
	140594519073552 -> 140594704431120 [dir=none]
	140594704431120 [label="input
 (6, 64, 180, 270)" fillcolor=orange]
	140594519073552 -> 140594681811408 [dir=none]
	140594681811408 [label="weight
 (64, 64, 3, 3)" fillcolor=orange]
	140594519073552 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594519073648 -> 140594519073552
	140594519073648 -> 140594519094512 [dir=none]
	140594519094512 [label="result
 (6, 64, 180, 270)" fillcolor=orange]
	140594519073648 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594519073792 -> 140594519073648
	140594519073792 [label="AddBackward0
------------
alpha: 1"]
	140594519073888 -> 140594519073792
	140594519073888 -> 140594704431040 [dir=none]
	140594704431040 [label="other
 (1, 64, 1, 1)" fillcolor=orange]
	140594519073888 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519073984 -> 140594519073888
	140594519073984 -> 140594704370960 [dir=none]
	140594704370960 [label="input
 (6, 64, 180, 270)" fillcolor=orange]
	140594519073984 -> 140594704424688 [dir=none]
	140594704424688 [label="weight
 (64, 64, 1, 1)" fillcolor=orange]
	140594519073984 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594519074080 -> 140594519073984
	140594519074080 -> 140594519094992 [dir=none]
	140594519094992 [label="result1
 (6, 64, 180, 270)" fillcolor=orange]
	140594519074080 -> 140594704430880 [dir=none]
	140594704430880 [label="self
 (6, 64, 360, 540)" fillcolor=orange]
	140594519074080 [label="MaxPool2DWithIndicesBackward0
-----------------------------
ceil_mode  :          False
dilation   :         (1, 1)
kernel_size:         (3, 3)
padding    :         (1, 1)
result1    : [saved tensor]
self       : [saved tensor]
stride     :         (2, 2)"]
	140594519074224 -> 140594519074080
	140594519074224 -> 140594519095072 [dir=none]
	140594519095072 [label="result
 (6, 64, 360, 540)" fillcolor=orange]
	140594519074224 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594519074320 -> 140594519074224
	140594519074320 [label="AddBackward0
------------
alpha: 1"]
	140594519074416 -> 140594519074320
	140594519074416 -> 140594704430800 [dir=none]
	140594704430800 [label="other
 (1, 64, 1, 1)" fillcolor=orange]
	140594519074416 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519074512 -> 140594519074416
	140594519074512 -> 140594519888576 [dir=none]
	140594519888576 [label="input
 (6, 3, 720, 1080)" fillcolor=orange]
	140594519074512 -> 140594704423488 [dir=none]
	140594704423488 [label="weight
 (64, 3, 7, 7)" fillcolor=orange]
	140594519074512 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (3, 3)
stride        :         (2, 2)
transposed    :          False
weight        : [saved tensor]"]
	140594519074608 -> 140594519074512
	140594704423488 [label="model.backbone.conv_encoder.model.conv1.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	140594704423488 -> 140594519074608
	140594519074608 [label=AccumulateGrad]
	140594519074032 -> 140594519073984
	140594704424688 [label="model.backbone.conv_encoder.model.layer1.0.conv1.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	140594704424688 -> 140594519074032
	140594519074032 [label=AccumulateGrad]
	140594519073600 -> 140594519073552
	140594681811408 [label="model.backbone.conv_encoder.model.layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140594681811408 -> 140594519073600
	140594519073600 [label=AccumulateGrad]
	140594519073168 -> 140594519073120
	140594681811888 [label="model.backbone.conv_encoder.model.layer1.0.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	140594681811888 -> 140594519073168
	140594519073168 [label=AccumulateGrad]
	140594519072880 -> 140594519023568
	140594519072880 [label="AddBackward0
------------
alpha: 1"]
	140594519072928 -> 140594519072880
	140594519072928 -> 140594704431600 [dir=none]
	140594704431600 [label="other
 (1, 256, 1, 1)" fillcolor=orange]
	140594519072928 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519073408 -> 140594519072928
	140594519073408 -> 140594704370960 [dir=none]
	140594704370960 [label="input
 (6, 64, 180, 270)" fillcolor=orange]
	140594519073408 -> 140594704424208 [dir=none]
	140594704424208 [label="weight
 (256, 64, 1, 1)" fillcolor=orange]
	140594519073408 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140594519074080 -> 140594519073408
	140594519073264 -> 140594519073408
	140594704424208 [label="model.backbone.conv_encoder.model.layer1.0.downsample.0.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	140594704424208 -> 140594519073264
	140594519073264 [label=AccumulateGrad]
	140594519023472 -> 140594519023376
	140594681812448 [label="model.backbone.conv_encoder.model.layer1.1.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	140594681812448 -> 140594519023472
	140594519023472 [label=AccumulateGrad]
	140594519022992 -> 140594519022944
	140594681813088 [label="model.backbone.conv_encoder.model.layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140594681813088 -> 140594519022992
	140594519022992 [label=AccumulateGrad]
	140594519022560 -> 140594519022512
	140594681813568 [label="model.backbone.conv_encoder.model.layer1.1.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	140594681813568 -> 140594519022560
	140594519022560 [label=AccumulateGrad]
	140594519022224 -> 140594519022176
	140594519022080 -> 140594519021984
	140594681814128 [label="model.backbone.conv_encoder.model.layer1.2.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	140594681814128 -> 140594519022080
	140594519022080 [label=AccumulateGrad]
	140594519021600 -> 140594519021552
	140594681814768 [label="model.backbone.conv_encoder.model.layer1.2.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140594681814768 -> 140594519021600
	140594519021600 [label=AccumulateGrad]
	140594519021168 -> 140594519021120
	140594681905456 [label="model.backbone.conv_encoder.model.layer1.2.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	140594681905456 -> 140594519021168
	140594519021168 [label=AccumulateGrad]
	140594519020832 -> 140594519020784
	140594519020592 -> 140594519020544
	140594681906576 [label="model.backbone.conv_encoder.model.layer2.0.conv1.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	140594681906576 -> 140594519020592
	140594519020592 [label=AccumulateGrad]
	140594519020160 -> 140594519020112
	140594681907216 [label="model.backbone.conv_encoder.model.layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140594681907216 -> 140594519020160
	140594519020160 [label=AccumulateGrad]
	140594519019728 -> 140594519019680
	140594681907696 [label="model.backbone.conv_encoder.model.layer2.0.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	140594681907696 -> 140594519019728
	140594519019728 [label=AccumulateGrad]
	140594519035712 -> 140594519035664
	140594519035712 [label="AddBackward0
------------
alpha: 1"]
	140594519035808 -> 140594519035712
	140594519035808 -> 140594704379968 [dir=none]
	140594704379968 [label="other
 (1, 512, 1, 1)" fillcolor=orange]
	140594519035808 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519019968 -> 140594519035808
	140594519019968 -> 140594704432480 [dir=none]
	140594704432480 [label="input
 (6, 256, 180, 270)" fillcolor=orange]
	140594519019968 -> 140594681906096 [dir=none]
	140594681906096 [label="weight
 (512, 256, 1, 1)" fillcolor=orange]
	140594519019968 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (2, 2)
transposed    :          False
weight        : [saved tensor]"]
	140594519020640 -> 140594519019968
	140594519019824 -> 140594519019968
	140594681906096 [label="model.backbone.conv_encoder.model.layer2.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	140594681906096 -> 140594519019824
	140594519019824 [label=AccumulateGrad]
	140594519035568 -> 140594519035472
	140594681908256 [label="model.backbone.conv_encoder.model.layer2.1.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	140594681908256 -> 140594519035568
	140594519035568 [label=AccumulateGrad]
	140594519035088 -> 140594519035040
	140594681908896 [label="model.backbone.conv_encoder.model.layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140594681908896 -> 140594519035088
	140594519035088 [label=AccumulateGrad]
	140594519034656 -> 140594519034608
	140594681487584 [label="model.backbone.conv_encoder.model.layer2.1.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	140594681487584 -> 140594519034656
	140594519034656 [label=AccumulateGrad]
	140594519034320 -> 140594519034272
	140594519034176 -> 140594519034080
	140594681488144 [label="model.backbone.conv_encoder.model.layer2.2.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	140594681488144 -> 140594519034176
	140594519034176 [label=AccumulateGrad]
	140594519033696 -> 140594519033648
	140594681488784 [label="model.backbone.conv_encoder.model.layer2.2.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140594681488784 -> 140594519033696
	140594519033696 [label=AccumulateGrad]
	140594519033264 -> 140594519033216
	140594681489264 [label="model.backbone.conv_encoder.model.layer2.2.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	140594681489264 -> 140594519033264
	140594519033264 [label=AccumulateGrad]
	140594519032928 -> 140594519032880
	140594519032784 -> 140594519032688
	140594681489824 [label="model.backbone.conv_encoder.model.layer2.3.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	140594681489824 -> 140594519032784
	140594519032784 [label=AccumulateGrad]
	140594519032304 -> 140594519032256
	140594681490304 [label="model.backbone.conv_encoder.model.layer2.3.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140594681490304 -> 140594519032304
	140594519032304 [label=AccumulateGrad]
	140594519031872 -> 140594682142672
	140594681490784 [label="model.backbone.conv_encoder.model.layer2.3.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	140594681490784 -> 140594519031872
	140594519031872 [label=AccumulateGrad]
	140594682142384 -> 140594682142336
	140594682142144 -> 140594682142096
	140594681578016 [label="model.backbone.conv_encoder.model.layer3.0.conv1.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	140594681578016 -> 140594682142144
	140594682142144 [label=AccumulateGrad]
	140594682141712 -> 140594682141664
	140594681578656 [label="model.backbone.conv_encoder.model.layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140594681578656 -> 140594682141712
	140594682141712 [label=AccumulateGrad]
	140594682141328 -> 140594682138784
	140594681579136 [label="model.backbone.conv_encoder.model.layer3.0.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140594681579136 -> 140594682141328
	140594682141328 [label=AccumulateGrad]
	140594682139168 -> 140594682139216
	140594682139168 [label="AddBackward0
------------
alpha: 1"]
	140594682139072 -> 140594682139168
	140594682139072 -> 140594704381968 [dir=none]
	140594704381968 [label="other
 (1, 1024, 1, 1)" fillcolor=orange]
	140594682139072 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594682141520 -> 140594682139072
	140594682141520 -> 140594704381328 [dir=none]
	140594704381328 [label="input
 (6, 512, 90, 135)" fillcolor=orange]
	140594682141520 -> 140594681577536 [dir=none]
	140594681577536 [label="weight
 (1024, 512, 1, 1)" fillcolor=orange]
	140594682141520 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (2, 2)
transposed    :          False
weight        : [saved tensor]"]
	140594682142192 -> 140594682141520
	140594682141376 -> 140594682141520
	140594681577536 [label="model.backbone.conv_encoder.model.layer3.0.downsample.0.weight
 (1024, 512, 1, 1)" fillcolor=lightblue]
	140594681577536 -> 140594682141376
	140594682141376 [label=AccumulateGrad]
	140594682139408 -> 140594682139600
	140594681579696 [label="model.backbone.conv_encoder.model.layer3.1.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140594681579696 -> 140594682139408
	140594682139408 [label=AccumulateGrad]
	140594682140272 -> 140594682140416
	140594681580336 [label="model.backbone.conv_encoder.model.layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140594681580336 -> 140594682140272
	140594682140272 [label=AccumulateGrad]
	140594682140992 -> 140594682141040
	140594681580816 [label="model.backbone.conv_encoder.model.layer3.1.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140594681580816 -> 140594682140992
	140594682140992 [label=AccumulateGrad]
	140594704679120 -> 140594704679648
	140594704680128 -> 140594704680608
	140594681581376 [label="model.backbone.conv_encoder.model.layer3.2.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140594681581376 -> 140594704680128
	140594704680128 [label=AccumulateGrad]
	140594704682576 -> 140594713209632
	140594681684512 [label="model.backbone.conv_encoder.model.layer3.2.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140594681684512 -> 140594704682576
	140594704682576 [label=AccumulateGrad]
	140594713877760 -> 140594713874832
	140594681684992 [label="model.backbone.conv_encoder.model.layer3.2.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140594681684992 -> 140594713877760
	140594713877760 [label=AccumulateGrad]
	140594713325376 -> 140594713323600
	140594713323936 -> 140594713324944
	140594681685552 [label="model.backbone.conv_encoder.model.layer3.3.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140594681685552 -> 140594713323936
	140594713323936 [label=AccumulateGrad]
	140594713325520 -> 140594713321680
	140594681686192 [label="model.backbone.conv_encoder.model.layer3.3.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140594681686192 -> 140594713325520
	140594713325520 [label=AccumulateGrad]
	140594713321824 -> 140594713322448
	140594681686672 [label="model.backbone.conv_encoder.model.layer3.3.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140594681686672 -> 140594713321824
	140594713321824 [label=AccumulateGrad]
	140594704666832 -> 140594704667024
	140594704667312 -> 140594704667648
	140594681687232 [label="model.backbone.conv_encoder.model.layer3.4.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140594681687232 -> 140594704667312
	140594704667312 [label=AccumulateGrad]
	140594704668176 -> 140594704668080
	140594681687872 [label="model.backbone.conv_encoder.model.layer3.4.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140594681687872 -> 140594704668176
	140594704668176 [label=AccumulateGrad]
	140594704669904 -> 140594704675600
	140594681246080 [label="model.backbone.conv_encoder.model.layer3.4.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140594681246080 -> 140594704669904
	140594704669904 [label=AccumulateGrad]
	140594704676176 -> 140594704676128
	140594704676272 -> 140594704676464
	140594681246640 [label="model.backbone.conv_encoder.model.layer3.5.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140594681246640 -> 140594704676272
	140594704676272 [label=AccumulateGrad]
	140594704677136 -> 140594704677280
	140594681247280 [label="model.backbone.conv_encoder.model.layer3.5.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140594681247280 -> 140594704677136
	140594704677136 [label=AccumulateGrad]
	140594704677952 -> 140594704678000
	140594681247760 [label="model.backbone.conv_encoder.model.layer3.5.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140594681247760 -> 140594704677952
	140594704677952 [label=AccumulateGrad]
	140594704678576 -> 140594704678720
	140594704700176 -> 140594704699600
	140594681248880 [label="model.backbone.conv_encoder.model.layer4.0.conv1.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	140594681248880 -> 140594704700176
	140594704700176 [label=AccumulateGrad]
	140594704700272 -> 140594704700416
	140594681249520 [label="model.backbone.conv_encoder.model.layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140594681249520 -> 140594704700272
	140594704700272 [label=AccumulateGrad]
	140594704701088 -> 140594704701136
	140594681344304 [label="model.backbone.conv_encoder.model.layer4.0.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	140594681344304 -> 140594704701088
	140594704701088 [label=AccumulateGrad]
	140594704701712 -> 140594704701856
	140594704701712 [label="AddBackward0
------------
alpha: 1"]
	140594704701520 -> 140594704701712
	140594704701520 -> 140594704356352 [dir=none]
	140594704356352 [label="other
 (1, 2048, 1, 1)" fillcolor=orange]
	140594704701520 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704700656 -> 140594704701520
	140594704700656 -> 140594704355712 [dir=none]
	140594704355712 [label="input
 (6, 1024, 45, 68)" fillcolor=orange]
	140594704700656 -> 140594681248400 [dir=none]
	140594681248400 [label="weight
 (2048, 1024, 1, 1)" fillcolor=orange]
	140594704700656 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (2, 2)
transposed    :          False
weight        : [saved tensor]"]
	140594704699552 -> 140594704700656
	140594704700992 -> 140594704700656
	140594681248400 [label="model.backbone.conv_encoder.model.layer4.0.downsample.0.weight
 (2048, 1024, 1, 1)" fillcolor=lightblue]
	140594681248400 -> 140594704700992
	140594704700992 [label=AccumulateGrad]
	140594704701952 -> 140594704702144
	140594681344864 [label="model.backbone.conv_encoder.model.layer4.1.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	140594681344864 -> 140594704701952
	140594704701952 [label=AccumulateGrad]
	140594704702816 -> 140594704702864
	140594681345504 [label="model.backbone.conv_encoder.model.layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140594681345504 -> 140594704702816
	140594704702816 [label=AccumulateGrad]
	140594704728272 -> 140594704728320
	140594681345984 [label="model.backbone.conv_encoder.model.layer4.1.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	140594681345984 -> 140594704728272
	140594704728272 [label=AccumulateGrad]
	140594704728896 -> 140594704728944
	140594704729136 -> 140594704729232
	140594681346544 [label="model.backbone.conv_encoder.model.layer4.2.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	140594681346544 -> 140594704729136
	140594704729136 [label=AccumulateGrad]
	140594704729904 -> 140594704730048
	140594681347184 [label="model.backbone.conv_encoder.model.layer4.2.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140594681347184 -> 140594704729904
	140594704729904 [label=AccumulateGrad]
	140594704730720 -> 140594704730768
	140594681347664 [label="model.backbone.conv_encoder.model.layer4.2.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	140594681347664 -> 140594704730720
	140594704730720 [label=AccumulateGrad]
	140594704731248 -> 140594704731392
	140594704731824 -> 140594704731872
	140594681346944 [label="model.input_projection.weight
 (256, 2048, 1, 1)" fillcolor=lightblue]
	140594681346944 -> 140594704731824
	140594704731824 [label=AccumulateGrad]
	140594704732112 -> 140594704731872
	140594681346784 [label="model.input_projection.bias
 (256)" fillcolor=lightblue]
	140594681346784 -> 140594704732112
	140594704732112 [label=AccumulateGrad]
	140594704753184 -> 140594704753328
	140594704753184 -> 140594519094912 [dir=none]
	140594519094912 [label="other
 (6, 782, 256)" fillcolor=orange]
	140594704753184 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704752848 -> 140594704753184
	140594704752848 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594704731440 -> 140594704752848
	140594704731440 -> 140594519095392 [dir=none]
	140594519095392 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594704731440 -> 140594519095232 [dir=none]
	140594519095232 [label="mat2
 (256, 256)" fillcolor=orange]
	140594704731440 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594704731008 -> 140594704731440
	140594681347424 [label="model.encoder.layers.0.self_attn.out_proj.bias
 (256)" fillcolor=lightblue]
	140594681347424 -> 140594704731008
	140594704731008 [label=AccumulateGrad]
	140594704731584 -> 140594704731440
	140594704731584 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594704731056 -> 140594704731584
	140594704731056 [label="UnsafeViewBackward0
---------------------------
self_sizes: (6, 782, 8, 32)"]
	140594704730528 -> 140594704731056
	140594704730528 [label=CloneBackward0]
	140594704729472 -> 140594704730528
	140594704729472 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594704729184 -> 140594704729472
	140594704729184 [label="ViewBackward0
-------------------------
self_sizes: (48, 782, 32)"]
	140594704729712 -> 140594704729184
	140594704729712 -> 140594704359232 [dir=none]
	140594704359232 [label="mat2
 (48, 782, 32)" fillcolor=orange]
	140594704729712 -> 140594704322624 [dir=none]
	140594704322624 [label="self
 (48, 782, 782)" fillcolor=orange]
	140594704729712 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594704728368 -> 140594704729712
	140594704728368 -> 140594519095472 [dir=none]
	140594519095472 [label="result
 (48, 782, 782)" fillcolor=orange]
	140594704728368 [label="SoftmaxBackward0
----------------------------
dim   : 18446744073709551615
result:       [saved tensor]"]
	140594704728704 -> 140594704728368
	140594704728704 [label="ViewBackward0
----------------------------
self_sizes: (6, 8, 782, 782)"]
	140594704703440 -> 140594704728704
	140594704703440 [label="AddBackward0
------------
alpha: 1"]
	140594704702384 -> 140594704703440
	140594704702384 [label="ViewBackward0
--------------------------
self_sizes: (48, 782, 782)"]
	140594704702000 -> 140594704702384
	140594704702000 -> 140594704358832 [dir=none]
	140594704358832 [label="mat2
 (48, 32, 782)" fillcolor=orange]
	140594704702000 -> 140594704359152 [dir=none]
	140594704359152 [label="self
 (48, 782, 32)" fillcolor=orange]
	140594704702000 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594704702720 -> 140594704702000
	140594704702720 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 782, 32)"]
	140594704700848 -> 140594704702720
	140594704700848 [label=CloneBackward0]
	140594704699744 -> 140594704700848
	140594704699744 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594704700128 -> 140594704699744
	140594704700128 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594704701904 -> 140594704700128
	140594704701904 -> 140594519093392 [dir=none]
	140594519093392 [label="other
 ()" fillcolor=orange]
	140594704701904 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704678768 -> 140594704701904
	140594704678768 [label="AddBackward0
------------
alpha: 1"]
	140594704678384 -> 140594704678768
	140594704678384 [label="UnsafeViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594704677712 -> 140594704678384
	140594704677712 -> 140594519095152 [dir=none]
	140594519095152 [label="mat2
 (6, 256, 256)" fillcolor=orange]
	140594704677712 -> 140594519095552 [dir=none]
	140594519095552 [label="self
 (6, 782, 256)" fillcolor=orange]
	140594704677712 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594704676608 -> 140594704677712
	140594704676608 [label="ReshapeAliasBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594704676416 -> 140594704676608
	140594704676416 [label="ExpandBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594704677040 -> 140594704676416
	140594704677040 [label="AddBackward0
------------
alpha: 1"]
	140594704753040 -> 140594704677040
	140594704677856 -> 140594704677712
	140594704677856 [label="ReshapeAliasBackward0
-------------------------
self_sizes: (6, 256, 256)"]
	140594704676224 -> 140594704677856
	140594704676224 [label="ExpandBackward0
----------------------
self_sizes: (256, 256)"]
	140594704676800 -> 140594704676224
	140594704676800 [label=TBackward0]
	140594704668608 -> 140594704676800
	140594681346464 [label="model.encoder.layers.0.self_attn.q_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594681346464 -> 140594704668608
	140594704668608 [label=AccumulateGrad]
	140594704678144 -> 140594704678768
	140594681346704 [label="model.encoder.layers.0.self_attn.q_proj.bias
 (256)" fillcolor=lightblue]
	140594681346704 -> 140594704678144
	140594704678144 [label=AccumulateGrad]
	140594704701280 -> 140594704702000
	140594704701280 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594704701472 -> 140594704701280
	140594704701472 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 782, 32)"]
	140594704700464 -> 140594704701472
	140594704700464 [label=CloneBackward0]
	140594704674976 -> 140594704700464
	140594704674976 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594704677520 -> 140594704674976
	140594704677520 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594704676992 -> 140594704677520
	140594704676992 [label="AddBackward0
------------
alpha: 1"]
	140594704669040 -> 140594704676992
	140594704669040 [label="UnsafeViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594704667552 -> 140594704669040
	140594704667552 -> 140594519095712 [dir=none]
	140594519095712 [label="mat2
 (6, 256, 256)" fillcolor=orange]
	140594704667552 -> 140594519095872 [dir=none]
	140594519095872 [label="self
 (6, 782, 256)" fillcolor=orange]
	140594704667552 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594704667840 -> 140594704667552
	140594704667840 [label="ReshapeAliasBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594704667072 -> 140594704667840
	140594704667072 [label="ExpandBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594704677040 -> 140594704667072
	140594704667744 -> 140594704667552
	140594704667744 [label="ReshapeAliasBackward0
-------------------------
self_sizes: (6, 256, 256)"]
	140594704667360 -> 140594704667744
	140594704667360 [label="ExpandBackward0
----------------------
self_sizes: (256, 256)"]
	140594713321968 -> 140594704667360
	140594713321968 [label=TBackward0]
	140594713322688 -> 140594713321968
	140594681347264 [label="model.encoder.layers.0.self_attn.k_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594681347264 -> 140594713322688
	140594713322688 [label=AccumulateGrad]
	140594704669472 -> 140594704676992
	140594681347104 [label="model.encoder.layers.0.self_attn.k_proj.bias
 (256)" fillcolor=lightblue]
	140594681347104 -> 140594704669472
	140594704669472 [label=AccumulateGrad]
	140594704729088 -> 140594704729712
	140594704729088 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 782, 32)"]
	140594704702192 -> 140594704729088
	140594704702192 [label=CloneBackward0]
	140594704703008 -> 140594704702192
	140594704703008 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594704699936 -> 140594704703008
	140594704699936 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594704677328 -> 140594704699936
	140594704677328 [label="AddBackward0
------------
alpha: 1"]
	140594704678336 -> 140594704677328
	140594704678336 [label="UnsafeViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594704669424 -> 140594704678336
	140594704669424 -> 140594519095952 [dir=none]
	140594519095952 [label="mat2
 (6, 256, 256)" fillcolor=orange]
	140594704669424 -> 140594519095312 [dir=none]
	140594519095312 [label="self
 (6, 782, 256)" fillcolor=orange]
	140594704669424 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594704667984 -> 140594704669424
	140594704667984 [label="ReshapeAliasBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594713322592 -> 140594704667984
	140594713322592 [label="ExpandBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594704753040 -> 140594713322592
	140594713321920 -> 140594704669424
	140594713321920 [label="ReshapeAliasBackward0
-------------------------
self_sizes: (6, 256, 256)"]
	140594713324848 -> 140594713321920
	140594713324848 [label="ExpandBackward0
----------------------
self_sizes: (256, 256)"]
	140594713325328 -> 140594713324848
	140594713325328 [label=TBackward0]
	140594713323984 -> 140594713325328
	140594681346304 [label="model.encoder.layers.0.self_attn.v_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594681346304 -> 140594713323984
	140594713323984 [label=AccumulateGrad]
	140594704678816 -> 140594704677328
	140594681346864 [label="model.encoder.layers.0.self_attn.v_proj.bias
 (256)" fillcolor=lightblue]
	140594681346864 -> 140594704678816
	140594704678816 [label=AccumulateGrad]
	140594704732064 -> 140594704731440
	140594704732064 [label=TBackward0]
	140594704729280 -> 140594704732064
	140594681346624 [label="model.encoder.layers.0.self_attn.out_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594681346624 -> 140594704729280
	140594704729280 [label=AccumulateGrad]
	140594704753472 -> 140594704753664
	140594681347904 [label="model.encoder.layers.0.self_attn_layer_norm.weight
 (256)" fillcolor=lightblue]
	140594681347904 -> 140594704753472
	140594704753472 [label=AccumulateGrad]
	140594704753520 -> 140594704753664
	140594681347584 [label="model.encoder.layers.0.self_attn_layer_norm.bias
 (256)" fillcolor=lightblue]
	140594681347584 -> 140594704753520
	140594704753520 [label=AccumulateGrad]
	140594704753712 -> 140594704754048
	140594704753712 -> 140594519096112 [dir=none]
	140594519096112 [label="other
 (6, 782, 256)" fillcolor=orange]
	140594704753712 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704753232 -> 140594704753712
	140594704753232 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594704730912 -> 140594704753232
	140594704730912 -> 140594519096192 [dir=none]
	140594519096192 [label="mat1
 (4692, 2048)" fillcolor=orange]
	140594704730912 -> 140594519095632 [dir=none]
	140594519095632 [label="mat2
 (2048, 256)" fillcolor=orange]
	140594704730912 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :   (4692, 2048)
mat1_strides:      (2048, 1)
mat2        : [saved tensor]
mat2_sizes  :    (2048, 256)
mat2_strides:      (1, 2048)"]
	140594704728560 -> 140594704730912
	140594681346144 [label="model.encoder.layers.0.fc2.bias
 (256)" fillcolor=lightblue]
	140594681346144 -> 140594704728560
	140594704728560 [label=AccumulateGrad]
	140594704730384 -> 140594704730912
	140594704730384 [label="ViewBackward0
--------------------------
self_sizes: (6, 782, 2048)"]
	140594704730096 -> 140594704730384
	140594704730096 -> 140594519096432 [dir=none]
	140594519096432 [label="result
 (6, 782, 2048)" fillcolor=orange]
	140594704730096 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594704703200 -> 140594704730096
	140594704703200 [label="ViewBackward0
------------------------
self_sizes: (4692, 2048)"]
	140594704678864 -> 140594704703200
	140594704678864 -> 140594519095792 [dir=none]
	140594519095792 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594704678864 -> 140594519096512 [dir=none]
	140594519096512 [label="mat2
 (256, 2048)" fillcolor=orange]
	140594704678864 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :    (256, 2048)
mat2_strides:       (1, 256)"]
	140594704670432 -> 140594704678864
	140594681347744 [label="model.encoder.layers.0.fc1.bias
 (2048)" fillcolor=lightblue]
	140594681347744 -> 140594704670432
	140594704670432 [label=AccumulateGrad]
	140594704670384 -> 140594704678864
	140594704670384 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594704753664 -> 140594704670384
	140594713325136 -> 140594704678864
	140594713325136 [label=TBackward0]
	140594713323648 -> 140594713325136
	140594681347824 [label="model.encoder.layers.0.fc1.weight
 (2048, 256)" fillcolor=lightblue]
	140594681347824 -> 140594713323648
	140594713323648 [label=AccumulateGrad]
	140594704731920 -> 140594704730912
	140594704731920 [label=TBackward0]
	140594704703392 -> 140594704731920
	140594681345184 [label="model.encoder.layers.0.fc2.weight
 (256, 2048)" fillcolor=lightblue]
	140594681345184 -> 140594704703392
	140594704703392 [label=AccumulateGrad]
	140594704754096 -> 140594704754192
	140594681346064 [label="model.encoder.layers.0.final_layer_norm.weight
 (256)" fillcolor=lightblue]
	140594681346064 -> 140594704754096
	140594704754096 [label=AccumulateGrad]
	140594704754144 -> 140594704754192
	140594681344064 [label="model.encoder.layers.0.final_layer_norm.bias
 (256)" fillcolor=lightblue]
	140594681344064 -> 140594704754144
	140594704754144 [label=AccumulateGrad]
	140594704754336 -> 140594704754576
	140594704754336 -> 140594519096672 [dir=none]
	140594519096672 [label="other
 (6, 782, 256)" fillcolor=orange]
	140594704754336 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704753280 -> 140594704754336
	140594704753280 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594704702576 -> 140594704753280
	140594704702576 -> 140594519096832 [dir=none]
	140594519096832 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594704702576 -> 140594519096352 [dir=none]
	140594519096352 [label="mat2
 (256, 256)" fillcolor=orange]
	140594704702576 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594704730192 -> 140594704702576
	140594681248320 [label="model.encoder.layers.1.self_attn.out_proj.bias
 (256)" fillcolor=lightblue]
	140594681248320 -> 140594704730192
	140594704730192 [label=AccumulateGrad]
	140594704729664 -> 140594704702576
	140594704729664 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594713322400 -> 140594704729664
	140594713322400 [label="UnsafeViewBackward0
---------------------------
self_sizes: (6, 782, 8, 32)"]
	140594713874784 -> 140594713322400
	140594713874784 [label=CloneBackward0]
	140594713875312 -> 140594713874784
	140594713875312 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594713209296 -> 140594713875312
	140594713209296 [label="ViewBackward0
-------------------------
self_sizes: (48, 782, 32)"]
	140594713209440 -> 140594713209296
	140594713209440 -> 140594704323504 [dir=none]
	140594704323504 [label="mat2
 (48, 782, 32)" fillcolor=orange]
	140594713209440 -> 140594704323664 [dir=none]
	140594704323664 [label="self
 (48, 782, 782)" fillcolor=orange]
	140594713209440 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594704681568 -> 140594713209440
	140594704681568 -> 140594519096032 [dir=none]
	140594519096032 [label="result
 (48, 782, 782)" fillcolor=orange]
	140594704681568 [label="SoftmaxBackward0
----------------------------
dim   : 18446744073709551615
result:       [saved tensor]"]
	140594704682096 -> 140594704681568
	140594704682096 [label="ViewBackward0
----------------------------
self_sizes: (6, 8, 782, 782)"]
	140594704679600 -> 140594704682096
	140594704679600 [label="AddBackward0
------------
alpha: 1"]
	140594682140464 -> 140594704679600
	140594682140464 [label="ViewBackward0
--------------------------
self_sizes: (48, 782, 782)"]
	140594682140752 -> 140594682140464
	140594682140752 -> 140594704323104 [dir=none]
	140594704323104 [label="mat2
 (48, 32, 782)" fillcolor=orange]
	140594682140752 -> 140594704323424 [dir=none]
	140594704323424 [label="self
 (48, 782, 32)" fillcolor=orange]
	140594682140752 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594682139744 -> 140594682140752
	140594682139744 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 782, 32)"]
	140594682139552 -> 140594682139744
	140594682139552 [label=CloneBackward0]
	140594682140176 -> 140594682139552
	140594682140176 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594682141616 -> 140594682140176
	140594682141616 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594682141952 -> 140594682141616
	140594682141952 -> 140594519097072 [dir=none]
	140594519097072 [label="other
 ()" fillcolor=orange]
	140594682141952 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594682138928 -> 140594682141952
	140594682138928 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594682141808 -> 140594682138928
	140594682141808 -> 140594519097152 [dir=none]
	140594519097152 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594682141808 -> 140594519096912 [dir=none]
	140594519096912 [label="mat2
 (256, 256)" fillcolor=orange]
	140594682141808 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594682142240 -> 140594682141808
	140594681248160 [label="model.encoder.layers.1.self_attn.q_proj.bias
 (256)" fillcolor=lightblue]
	140594681248160 -> 140594682142240
	140594682142240 [label=AccumulateGrad]
	140594682142528 -> 140594682141808
	140594682142528 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594682142624 -> 140594682142528
	140594682142624 [label="AddBackward0
------------
alpha: 1"]
	140594704754192 -> 140594682142624
	140594682139936 -> 140594682141808
	140594682139936 [label=TBackward0]
	140594519032112 -> 140594682139936
	140594681248560 [label="model.encoder.layers.1.self_attn.q_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594681248560 -> 140594519032112
	140594519032112 [label=AccumulateGrad]
	140594682140800 -> 140594682140752
	140594682140800 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594682139360 -> 140594682140800
	140594682139360 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 782, 32)"]
	140594682142048 -> 140594682139360
	140594682142048 [label=CloneBackward0]
	140594682142288 -> 140594682142048
	140594682142288 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594682140128 -> 140594682142288
	140594682140128 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519031920 -> 140594682140128
	140594519031920 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594519032544 -> 140594519031920
	140594519032544 -> 140594519096592 [dir=none]
	140594519096592 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594519032544 -> 140594519096992 [dir=none]
	140594519096992 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519032544 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519032736 -> 140594519032544
	140594681248960 [label="model.encoder.layers.1.self_attn.k_proj.bias
 (256)" fillcolor=lightblue]
	140594681248960 -> 140594519032736
	140594519032736 [label=AccumulateGrad]
	140594519032448 -> 140594519032544
	140594519032448 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594682142624 -> 140594519032448
	140594519032016 -> 140594519032544
	140594519032016 [label=TBackward0]
	140594519033168 -> 140594519032016
	140594681249040 [label="model.encoder.layers.1.self_attn.k_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594681249040 -> 140594519033168
	140594519033168 [label=AccumulateGrad]
	140594704681184 -> 140594713209440
	140594704681184 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 782, 32)"]
	140594704680080 -> 140594704681184
	140594704680080 [label=CloneBackward0]
	140594682141088 -> 140594704680080
	140594682141088 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594682141424 -> 140594682141088
	140594682141424 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594682141856 -> 140594682141424
	140594682141856 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594519032640 -> 140594682141856
	140594519032640 -> 140594519097232 [dir=none]
	140594519097232 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594519032640 -> 140594519096752 [dir=none]
	140594519096752 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519032640 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519032832 -> 140594519032640
	140594681248080 [label="model.encoder.layers.1.self_attn.v_proj.bias
 (256)" fillcolor=lightblue]
	140594681248080 -> 140594519032832
	140594519032832 [label=AccumulateGrad]
	140594519033072 -> 140594519032640
	140594519033072 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594704754192 -> 140594519033072
	140594519031968 -> 140594519032640
	140594519031968 [label=TBackward0]
	140594519033504 -> 140594519031968
	140594681246400 [label="model.encoder.layers.1.self_attn.v_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594681246400 -> 140594519033504
	140594519033504 [label=AccumulateGrad]
	140594704731632 -> 140594704702576
	140594704731632 [label=TBackward0]
	140594713877136 -> 140594704731632
	140594681248480 [label="model.encoder.layers.1.self_attn.out_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594681248480 -> 140594713877136
	140594713877136 [label=AccumulateGrad]
	140594704754720 -> 140594704754912
	140594681247360 [label="model.encoder.layers.1.self_attn_layer_norm.weight
 (256)" fillcolor=lightblue]
	140594681247360 -> 140594704754720
	140594704754720 [label=AccumulateGrad]
	140594704754768 -> 140594704754912
	140594681685872 [label="model.encoder.layers.1.self_attn_layer_norm.bias
 (256)" fillcolor=lightblue]
	140594681685872 -> 140594704754768
	140594704754768 [label=AccumulateGrad]
	140594704754960 -> 140594704755200
	140594704754960 -> 140594519096272 [dir=none]
	140594519096272 [label="other
 (6, 782, 256)" fillcolor=orange]
	140594704754960 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704753856 -> 140594704754960
	140594704753856 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594713876752 -> 140594704753856
	140594713876752 -> 140594519638240 [dir=none]
	140594519638240 [label="mat1
 (4692, 2048)" fillcolor=orange]
	140594713876752 -> 140594519638080 [dir=none]
	140594519638080 [label="mat2
 (2048, 256)" fillcolor=orange]
	140594713876752 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :   (4692, 2048)
mat1_strides:      (2048, 1)
mat2        : [saved tensor]
mat2_sizes  :    (2048, 256)
mat2_strides:      (1, 2048)"]
	140594713207424 -> 140594713876752
	140594681581296 [label="model.encoder.layers.1.fc2.bias
 (256)" fillcolor=lightblue]
	140594681581296 -> 140594713207424
	140594713207424 [label=AccumulateGrad]
	140594704754528 -> 140594713876752
	140594704754528 [label="ViewBackward0
--------------------------
self_sizes: (6, 782, 2048)"]
	140594704680560 -> 140594704754528
	140594704680560 -> 140594519638560 [dir=none]
	140594519638560 [label="result
 (6, 782, 2048)" fillcolor=orange]
	140594704680560 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594704680944 -> 140594704680560
	140594704680944 [label="ViewBackward0
------------------------
self_sizes: (4692, 2048)"]
	140594682141136 -> 140594704680944
	140594682141136 -> 140594519638320 [dir=none]
	140594519638320 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594682141136 -> 140594519638640 [dir=none]
	140594519638640 [label="mat2
 (256, 2048)" fillcolor=orange]
	140594682141136 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :    (256, 2048)
mat2_strides:       (1, 256)"]
	140594519032400 -> 140594682141136
	140594681686752 [label="model.encoder.layers.1.fc1.bias
 (2048)" fillcolor=lightblue]
	140594681686752 -> 140594519032400
	140594519032400 [label=AccumulateGrad]
	140594519033600 -> 140594682141136
	140594519033600 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594704754912 -> 140594519033600
	140594519032208 -> 140594682141136
	140594519032208 [label=TBackward0]
	140594519034032 -> 140594519032208
	140594681686832 [label="model.encoder.layers.1.fc1.weight
 (2048, 256)" fillcolor=lightblue]
	140594681686832 -> 140594519034032
	140594519034032 [label=AccumulateGrad]
	140594713324464 -> 140594713876752
	140594713324464 [label=TBackward0]
	140594682140560 -> 140594713324464
	140594681684752 [label="model.encoder.layers.1.fc2.weight
 (256, 2048)" fillcolor=lightblue]
	140594681684752 -> 140594682140560
	140594682140560 [label=AccumulateGrad]
	140594704755248 -> 140594704755440
	140594681581456 [label="model.encoder.layers.1.final_layer_norm.weight
 (256)" fillcolor=lightblue]
	140594681581456 -> 140594704755248
	140594704755248 [label=AccumulateGrad]
	140594704755392 -> 140594704755440
	140594681579456 [label="model.encoder.layers.1.final_layer_norm.bias
 (256)" fillcolor=lightblue]
	140594681579456 -> 140594704755392
	140594704755392 [label=AccumulateGrad]
	140594704755584 -> 140594704755824
	140594704755584 -> 140594519638800 [dir=none]
	140594519638800 [label="other
 (6, 782, 256)" fillcolor=orange]
	140594704755584 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704754384 -> 140594704755584
	140594704754384 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594713322064 -> 140594704754384
	140594713322064 -> 140594519638960 [dir=none]
	140594519638960 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594713322064 -> 140594519638480 [dir=none]
	140594519638480 [label="mat2
 (256, 256)" fillcolor=orange]
	140594713322064 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594704682528 -> 140594713322064
	140594681490544 [label="model.encoder.layers.2.self_attn.out_proj.bias
 (256)" fillcolor=lightblue]
	140594681490544 -> 140594704682528
	140594704682528 [label=AccumulateGrad]
	140594682138832 -> 140594713322064
	140594682138832 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519033360 -> 140594682138832
	140594519033360 [label="UnsafeViewBackward0
---------------------------
self_sizes: (6, 782, 8, 32)"]
	140594519034128 -> 140594519033360
	140594519034128 [label=CloneBackward0]
	140594519033792 -> 140594519034128
	140594519033792 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519034560 -> 140594519033792
	140594519034560 [label="ViewBackward0
-------------------------
self_sizes: (48, 782, 32)"]
	140594519034992 -> 140594519034560
	140594519034992 -> 140594704324624 [dir=none]
	140594704324624 [label="mat2
 (48, 782, 32)" fillcolor=orange]
	140594519034992 -> 140594704324784 [dir=none]
	140594704324784 [label="self
 (48, 782, 782)" fillcolor=orange]
	140594519034992 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594519034800 -> 140594519034992
	140594519034800 -> 140594519638160 [dir=none]
	140594519638160 [label="result
 (48, 782, 782)" fillcolor=orange]
	140594519034800 [label="SoftmaxBackward0
----------------------------
dim   : 18446744073709551615
result:       [saved tensor]"]
	140594519035328 -> 140594519034800
	140594519035328 [label="ViewBackward0
----------------------------
self_sizes: (6, 8, 782, 782)"]
	140594519035520 -> 140594519035328
	140594519035520 [label="AddBackward0
------------
alpha: 1"]
	140594519035616 -> 140594519035520
	140594519035616 [label="ViewBackward0
--------------------------
self_sizes: (48, 782, 782)"]
	140594519034752 -> 140594519035616
	140594519034752 -> 140594704324224 [dir=none]
	140594704324224 [label="mat2
 (48, 32, 782)" fillcolor=orange]
	140594519034752 -> 140594704324544 [dir=none]
	140594704324544 [label="self
 (48, 782, 32)" fillcolor=orange]
	140594519034752 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594519020400 -> 140594519034752
	140594519020400 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 782, 32)"]
	140594519020304 -> 140594519020400
	140594519020304 [label=CloneBackward0]
	140594519020976 -> 140594519020304
	140594519020976 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519020736 -> 140594519020976
	140594519020736 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519020928 -> 140594519020736
	140594519020928 -> 140594519639200 [dir=none]
	140594519639200 [label="other
 ()" fillcolor=orange]
	140594519020928 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519021408 -> 140594519020928
	140594519021408 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594519021264 -> 140594519021408
	140594519021264 -> 140594519639280 [dir=none]
	140594519639280 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594519021264 -> 140594519639040 [dir=none]
	140594519639040 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519021264 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519021840 -> 140594519021264
	140594681577696 [label="model.encoder.layers.2.self_attn.q_proj.bias
 (256)" fillcolor=lightblue]
	140594681577696 -> 140594519021840
	140594519021840 [label=AccumulateGrad]
	140594519021936 -> 140594519021264
	140594519021936 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519022032 -> 140594519021936
	140594519022032 [label="AddBackward0
------------
alpha: 1"]
	140594704755440 -> 140594519022032
	140594519020496 -> 140594519021264
	140594519020496 [label=TBackward0]
	140594519022128 -> 140594519020496
	140594681578576 [label="model.encoder.layers.2.self_attn.q_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594681578576 -> 140594519022128
	140594519022128 [label=AccumulateGrad]
	140594519019872 -> 140594519034752
	140594519019872 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519020688 -> 140594519019872
	140594519020688 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 782, 32)"]
	140594519021504 -> 140594519020688
	140594519021504 [label=CloneBackward0]
	140594519021744 -> 140594519021504
	140594519021744 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519022320 -> 140594519021744
	140594519022320 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519022368 -> 140594519022320
	140594519022368 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594519022800 -> 140594519022368
	140594519022800 -> 140594519638720 [dir=none]
	140594519638720 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594519022800 -> 140594519639120 [dir=none]
	140594519639120 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519022800 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519022656 -> 140594519022800
	140594681580256 [label="model.encoder.layers.2.self_attn.k_proj.bias
 (256)" fillcolor=lightblue]
	140594681580256 -> 140594519022656
	140594519022656 [label=AccumulateGrad]
	140594519022704 -> 140594519022800
	140594519022704 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519022032 -> 140594519022704
	140594519019632 -> 140594519022800
	140594519019632 [label=TBackward0]
	140594519023424 -> 140594519019632
	140594681580416 [label="model.encoder.layers.2.self_attn.k_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594681580416 -> 140594519023424
	140594519023424 [label=AccumulateGrad]
	140594519034896 -> 140594519034992
	140594519034896 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 782, 32)"]
	140594519035184 -> 140594519034896
	140594519035184 [label=CloneBackward0]
	140594519035424 -> 140594519035184
	140594519035424 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519021072 -> 140594519035424
	140594519021072 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519022464 -> 140594519021072
	140594519022464 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594519022896 -> 140594519022464
	140594519022896 -> 140594519639440 [dir=none]
	140594519639440 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594519022896 -> 140594519639520 [dir=none]
	140594519639520 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519022896 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519023136 -> 140594519022896
	140594681578736 [label="model.encoder.layers.2.self_attn.v_proj.bias
 (256)" fillcolor=lightblue]
	140594681578736 -> 140594519023136
	140594519023136 [label=AccumulateGrad]
	140594519023328 -> 140594519022896
	140594519023328 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594704755440 -> 140594519023328
	140594519020064 -> 140594519022896
	140594519020064 [label=TBackward0]
	140594519023232 -> 140594519020064
	140594681577776 [label="model.encoder.layers.2.self_attn.v_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594681577776 -> 140594519023232
	140594519023232 [label=AccumulateGrad]
	140594704755056 -> 140594713322064
	140594704755056 [label=TBackward0]
	140594519034464 -> 140594704755056
	140594681577616 [label="model.encoder.layers.2.self_attn.out_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594681577616 -> 140594519034464
	140594519034464 [label=AccumulateGrad]
	140594704755872 -> 140594704756064
	140594681491104 [label="model.encoder.layers.2.self_attn_layer_norm.weight
 (256)" fillcolor=lightblue]
	140594681491104 -> 140594704755872
	140594704755872 [label=AccumulateGrad]
	140594704755920 -> 140594704756064
	140594681491184 [label="model.encoder.layers.2.self_attn_layer_norm.bias
 (256)" fillcolor=lightblue]
	140594681491184 -> 140594704755920
	140594704755920 [label=AccumulateGrad]
	140594704756112 -> 140594704756448
	140594704756112 -> 140594519639760 [dir=none]
	140594519639760 [label="other
 (6, 782, 256)" fillcolor=orange]
	140594704756112 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704755008 -> 140594704756112
	140594704755008 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594704753904 -> 140594704755008
	140594704753904 -> 140594519639840 [dir=none]
	140594519639840 [label="mat1
 (4692, 2048)" fillcolor=orange]
	140594704753904 -> 140594519639600 [dir=none]
	140594519639600 [label="mat2
 (2048, 256)" fillcolor=orange]
	140594704753904 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :   (4692, 2048)
mat1_strides:      (2048, 1)
mat2        : [saved tensor]
mat2_sizes  :    (2048, 256)
mat2_strides:      (1, 2048)"]
	140594519034416 -> 140594704753904
	140594681908336 [label="model.encoder.layers.2.fc2.bias
 (256)" fillcolor=lightblue]
	140594681908336 -> 140594519034416
	140594519034416 [label=AccumulateGrad]
	140594519033408 -> 140594704753904
	140594519033408 [label="ViewBackward0
--------------------------
self_sizes: (6, 782, 2048)"]
	140594519033840 -> 140594519033408
	140594519033840 -> 140594519640000 [dir=none]
	140594519640000 [label="result
 (6, 782, 2048)" fillcolor=orange]
	140594519033840 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594519035232 -> 140594519033840
	140594519035232 [label="ViewBackward0
------------------------
self_sizes: (4692, 2048)"]
	140594519021696 -> 140594519035232
	140594519021696 -> 140594519639360 [dir=none]
	140594519639360 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594519021696 -> 140594519640080 [dir=none]
	140594519640080 [label="mat2
 (256, 2048)" fillcolor=orange]
	140594519021696 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :    (256, 2048)
mat2_strides:       (1, 256)"]
	140594519023520 -> 140594519021696
	140594681490224 [label="model.encoder.layers.2.fc1.bias
 (2048)" fillcolor=lightblue]
	140594681490224 -> 140594519023520
	140594519023520 [label=AccumulateGrad]
	140594519019584 -> 140594519021696
	140594519019584 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594704756064 -> 140594519019584
	140594519072832 -> 140594519021696
	140594519072832 [label=TBackward0]
	140594519073840 -> 140594519072832
	140594681491344 [label="model.encoder.layers.2.fc1.weight
 (2048, 256)" fillcolor=lightblue]
	140594681491344 -> 140594519073840
	140594519073840 [label=AccumulateGrad]
	140594519033024 -> 140594704753904
	140594519033024 [label=TBackward0]
	140594519021312 -> 140594519033024
	140594681905216 [label="model.encoder.layers.2.fc2.weight
 (256, 2048)" fillcolor=lightblue]
	140594681905216 -> 140594519021312
	140594519021312 [label=AccumulateGrad]
	140594704756496 -> 140594704773232
	140594681909136 [label="model.encoder.layers.2.final_layer_norm.weight
 (256)" fillcolor=lightblue]
	140594681909136 -> 140594704756496
	140594704756496 [label=AccumulateGrad]
	140594704756640 -> 140594704773232
	140594681907456 [label="model.encoder.layers.2.final_layer_norm.bias
 (256)" fillcolor=lightblue]
	140594681907456 -> 140594704756640
	140594704756640 [label=AccumulateGrad]
	140594704773184 -> 140594704773424
	140594704773184 -> 140594519640160 [dir=none]
	140594519640160 [label="other
 (6, 782, 256)" fillcolor=orange]
	140594704773184 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704755632 -> 140594704773184
	140594704755632 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594519020256 -> 140594704755632
	140594519020256 -> 140594519640320 [dir=none]
	140594519640320 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594519020256 -> 140594519638400 [dir=none]
	140594519638400 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519020256 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519033936 -> 140594519020256
	140594681906016 [label="model.encoder.layers.3.self_attn.out_proj.bias
 (256)" fillcolor=lightblue]
	140594681906016 -> 140594519033936
	140594519033936 [label=AccumulateGrad]
	140594519034224 -> 140594519020256
	140594519034224 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519073312 -> 140594519034224
	140594519073312 [label="UnsafeViewBackward0
---------------------------
self_sizes: (6, 782, 8, 32)"]
	140594519073744 -> 140594519073312
	140594519073744 [label=CloneBackward0]
	140594519074368 -> 140594519073744
	140594519074368 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519074176 -> 140594519074368
	140594519074176 [label="ViewBackward0
-------------------------
self_sizes: (48, 782, 32)"]
	140594519074560 -> 140594519074176
	140594519074560 -> 140594704325744 [dir=none]
	140594704325744 [label="mat2
 (48, 782, 32)" fillcolor=orange]
	140594519074560 -> 140594704325904 [dir=none]
	140594704325904 [label="self
 (48, 782, 782)" fillcolor=orange]
	140594519074560 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594519074656 -> 140594519074560
	140594519074656 -> 140594519638880 [dir=none]
	140594519638880 [label="result
 (48, 782, 782)" fillcolor=orange]
	140594519074656 [label="SoftmaxBackward0
----------------------------
dim   : 18446744073709551615
result:       [saved tensor]"]
	140594519074800 -> 140594519074656
	140594519074800 [label="ViewBackward0
----------------------------
self_sizes: (6, 8, 782, 782)"]
	140594519074896 -> 140594519074800
	140594519074896 [label="AddBackward0
------------
alpha: 1"]
	140594519074992 -> 140594519074896
	140594519074992 [label="ViewBackward0
--------------------------
self_sizes: (48, 782, 782)"]
	140594519075088 -> 140594519074992
	140594519075088 -> 140594704325344 [dir=none]
	140594704325344 [label="mat2
 (48, 32, 782)" fillcolor=orange]
	140594519075088 -> 140594704325664 [dir=none]
	140594704325664 [label="self
 (48, 782, 32)" fillcolor=orange]
	140594519075088 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594519075184 -> 140594519075088
	140594519075184 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 782, 32)"]
	140594519075328 -> 140594519075184
	140594519075328 [label=CloneBackward0]
	140594519075424 -> 140594519075328
	140594519075424 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519075520 -> 140594519075424
	140594519075520 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519075616 -> 140594519075520
	140594519075616 -> 140594519640560 [dir=none]
	140594519640560 [label="other
 ()" fillcolor=orange]
	140594519075616 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519075712 -> 140594519075616
	140594519075712 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594519075808 -> 140594519075712
	140594519075808 -> 140594519640640 [dir=none]
	140594519640640 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594519075808 -> 140594519640400 [dir=none]
	140594519640400 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519075808 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519075904 -> 140594519075808
	140594681905856 [label="model.encoder.layers.3.self_attn.q_proj.bias
 (256)" fillcolor=lightblue]
	140594681905856 -> 140594519075904
	140594519075904 [label=AccumulateGrad]
	140594519075856 -> 140594519075808
	140594519075856 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519076000 -> 140594519075856
	140594519076000 [label="AddBackward0
------------
alpha: 1"]
	140594704773232 -> 140594519076000
	140594519075232 -> 140594519075808
	140594519075232 [label=TBackward0]
	140594519076144 -> 140594519075232
	140594681906256 [label="model.encoder.layers.3.self_attn.q_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594681906256 -> 140594519076144
	140594519076144 [label=AccumulateGrad]
	140594519075136 -> 140594519075088
	140594519075136 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519075472 -> 140594519075136
	140594519075472 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 782, 32)"]
	140594519075664 -> 140594519075472
	140594519075664 [label=CloneBackward0]
	140594519075952 -> 140594519075664
	140594519075952 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519076240 -> 140594519075952
	140594519076240 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519076048 -> 140594519076240
	140594519076048 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594519076336 -> 140594519076048
	140594519076336 -> 140594519639680 [dir=none]
	140594519639680 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594519076336 -> 140594519640480 [dir=none]
	140594519640480 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519076336 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519076432 -> 140594519076336
	140594681906656 [label="model.encoder.layers.3.self_attn.k_proj.bias
 (256)" fillcolor=lightblue]
	140594681906656 -> 140594519076432
	140594519076432 [label=AccumulateGrad]
	140594519076384 -> 140594519076336
	140594519076384 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519076000 -> 140594519076384
	140594519075280 -> 140594519076336
	140594519075280 [label=TBackward0]
	140594519076624 -> 140594519075280
	140594681906736 [label="model.encoder.layers.3.self_attn.k_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594681906736 -> 140594519076624
	140594519076624 [label=AccumulateGrad]
	140594519074704 -> 140594519074560
	140594519074704 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 782, 32)"]
	140594519074944 -> 140594519074704
	140594519074944 [label=CloneBackward0]
	140594519074128 -> 140594519074944
	140594519074128 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519075568 -> 140594519074128
	140594519075568 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519076192 -> 140594519075568
	140594519076192 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594519076288 -> 140594519076192
	140594519076288 -> 140594519640800 [dir=none]
	140594519640800 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594519076288 -> 140594519640880 [dir=none]
	140594519640880 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519076288 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519076576 -> 140594519076288
	140594681905776 [label="model.encoder.layers.3.self_attn.v_proj.bias
 (256)" fillcolor=lightblue]
	140594681905776 -> 140594519076576
	140594519076576 [label=AccumulateGrad]
	140594519076480 -> 140594519076288
	140594519076480 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594704773232 -> 140594519076480
	140594519074752 -> 140594519076288
	140594519074752 [label=TBackward0]
	140594519076768 -> 140594519074752
	140594681905696 [label="model.encoder.layers.3.self_attn.v_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594681905696 -> 140594519076768
	140594519076768 [label=AccumulateGrad]
	140594704756304 -> 140594519020256
	140594704756304 [label=TBackward0]
	140594519073696 -> 140594704756304
	140594681906176 [label="model.encoder.layers.3.self_attn.out_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594681906176 -> 140594519073696
	140594519073696 [label=AccumulateGrad]
	140594704773568 -> 140594704773760
	140594681814688 [label="model.encoder.layers.3.self_attn_layer_norm.weight
 (256)" fillcolor=lightblue]
	140594681814688 -> 140594704773568
	140594704773568 [label=AccumulateGrad]
	140594704773616 -> 140594704773760
	140594704423888 [label="model.encoder.layers.3.self_attn_layer_norm.bias
 (256)" fillcolor=lightblue]
	140594704423888 -> 140594704773616
	140594704773616 [label=AccumulateGrad]
	140594704773808 -> 140594704774048
	140594704773808 -> 140594519641120 [dir=none]
	140594519641120 [label="other
 (6, 782, 256)" fillcolor=orange]
	140594704773808 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704773376 -> 140594704773808
	140594704773376 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594704755776 -> 140594704773376
	140594704755776 -> 140594519641200 [dir=none]
	140594519641200 [label="mat1
 (4692, 2048)" fillcolor=orange]
	140594704755776 -> 140594519640960 [dir=none]
	140594519640960 [label="mat2
 (2048, 256)" fillcolor=orange]
	140594704755776 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :   (4692, 2048)
mat1_strides:      (2048, 1)
mat2        : [saved tensor]
mat2_sizes  :    (2048, 256)
mat2_strides:      (1, 2048)"]
	140594519074464 -> 140594704755776
	140594704423568 [label="model.encoder.layers.3.fc2.bias
 (256)" fillcolor=lightblue]
	140594704423568 -> 140594519074464
	140594519074464 [label=AccumulateGrad]
	140594519073504 -> 140594704755776
	140594519073504 [label="ViewBackward0
--------------------------
self_sizes: (6, 782, 2048)"]
	140594519072976 -> 140594519073504
	140594519072976 -> 140594519641360 [dir=none]
	140594519641360 [label="result
 (6, 782, 2048)" fillcolor=orange]
	140594519072976 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594519075376 -> 140594519072976
	140594519075376 [label="ViewBackward0
------------------------
self_sizes: (4692, 2048)"]
	140594519076096 -> 140594519075376
	140594519076096 -> 140594519640720 [dir=none]
	140594519640720 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594519076096 -> 140594519641440 [dir=none]
	140594519641440 [label="mat2
 (256, 2048)" fillcolor=orange]
	140594519076096 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :    (256, 2048)
mat2_strides:       (1, 256)"]
	140594519076528 -> 140594519076096
	140594704423328 [label="model.encoder.layers.3.fc1.bias
 (2048)" fillcolor=lightblue]
	140594704423328 -> 140594519076528
	140594519076528 [label=AccumulateGrad]
	140594519076720 -> 140594519076096
	140594519076720 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594704773760 -> 140594519076720
	140594519074848 -> 140594519076096
	140594519074848 [label=TBackward0]
	140594519076672 -> 140594519074848
	140594704423728 [label="model.encoder.layers.3.fc1.weight
 (2048, 256)" fillcolor=lightblue]
	140594704423728 -> 140594519076672
	140594519076672 [label=AccumulateGrad]
	140594519073072 -> 140594704755776
	140594519073072 [label=TBackward0]
	140594519075760 -> 140594519073072
	140594704423648 [label="model.encoder.layers.3.fc2.weight
 (256, 2048)" fillcolor=lightblue]
	140594704423648 -> 140594519075760
	140594519075760 [label=AccumulateGrad]
	140594704774096 -> 140594704774288
	140594704424848 [label="model.encoder.layers.3.final_layer_norm.weight
 (256)" fillcolor=lightblue]
	140594704424848 -> 140594704774096
	140594704774096 [label=AccumulateGrad]
	140594704774240 -> 140594704774288
	140594704424768 [label="model.encoder.layers.3.final_layer_norm.bias
 (256)" fillcolor=lightblue]
	140594704424768 -> 140594704774240
	140594704774240 [label=AccumulateGrad]
	140594704774432 -> 140594704774672
	140594704774432 -> 140594519641520 [dir=none]
	140594519641520 [label="other
 (6, 782, 256)" fillcolor=orange]
	140594704774432 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704773952 -> 140594704774432
	140594704773952 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594704756688 -> 140594704773952
	140594704756688 -> 140594519641680 [dir=none]
	140594519641680 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594704756688 -> 140594519639920 [dir=none]
	140594519639920 [label="mat2
 (256, 256)" fillcolor=orange]
	140594704756688 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519076816 -> 140594704756688
	140594681071952 [label="model.encoder.layers.4.self_attn.out_proj.bias
 (256)" fillcolor=lightblue]
	140594681071952 -> 140594519076816
	140594519076816 [label=AccumulateGrad]
	140594519075040 -> 140594704756688
	140594519075040 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519490720 -> 140594519075040
	140594519490720 [label="UnsafeViewBackward0
---------------------------
self_sizes: (6, 782, 8, 32)"]
	140594519490816 -> 140594519490720
	140594519490816 [label=CloneBackward0]
	140594519490912 -> 140594519490816
	140594519490912 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519491008 -> 140594519490912
	140594519491008 [label="ViewBackward0
-------------------------
self_sizes: (48, 782, 32)"]
	140594519491104 -> 140594519491008
	140594519491104 -> 140594704302384 [dir=none]
	140594704302384 [label="mat2
 (48, 782, 32)" fillcolor=orange]
	140594519491104 -> 140594704302544 [dir=none]
	140594704302544 [label="self
 (48, 782, 782)" fillcolor=orange]
	140594519491104 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594519491200 -> 140594519491104
	140594519491200 -> 140594519640240 [dir=none]
	140594519640240 [label="result
 (48, 782, 782)" fillcolor=orange]
	140594519491200 [label="SoftmaxBackward0
----------------------------
dim   : 18446744073709551615
result:       [saved tensor]"]
	140594519491344 -> 140594519491200
	140594519491344 [label="ViewBackward0
----------------------------
self_sizes: (6, 8, 782, 782)"]
	140594519491440 -> 140594519491344
	140594519491440 [label="AddBackward0
------------
alpha: 1"]
	140594519491536 -> 140594519491440
	140594519491536 [label="ViewBackward0
--------------------------
self_sizes: (48, 782, 782)"]
	140594519491632 -> 140594519491536
	140594519491632 -> 140594704326464 [dir=none]
	140594704326464 [label="mat2
 (48, 32, 782)" fillcolor=orange]
	140594519491632 -> 140594704302304 [dir=none]
	140594704302304 [label="self
 (48, 782, 32)" fillcolor=orange]
	140594519491632 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594519491728 -> 140594519491632
	140594519491728 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 782, 32)"]
	140594519491872 -> 140594519491728
	140594519491872 [label=CloneBackward0]
	140594519491968 -> 140594519491872
	140594519491968 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519492064 -> 140594519491968
	140594519492064 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519492160 -> 140594519492064
	140594519492160 -> 140594519641920 [dir=none]
	140594519641920 [label="other
 ()" fillcolor=orange]
	140594519492160 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519492256 -> 140594519492160
	140594519492256 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594519492352 -> 140594519492256
	140594519492352 -> 140594519642000 [dir=none]
	140594519642000 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594519492352 -> 140594519641760 [dir=none]
	140594519641760 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519492352 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519492448 -> 140594519492352
	140594681073072 [label="model.encoder.layers.4.self_attn.q_proj.bias
 (256)" fillcolor=lightblue]
	140594681073072 -> 140594519492448
	140594519492448 [label=AccumulateGrad]
	140594519492400 -> 140594519492352
	140594519492400 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519492544 -> 140594519492400
	140594519492544 [label="AddBackward0
------------
alpha: 1"]
	140594704774288 -> 140594519492544
	140594519491776 -> 140594519492352
	140594519491776 [label=TBackward0]
	140594519492688 -> 140594519491776
	140594704424128 [label="model.encoder.layers.4.self_attn.q_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594704424128 -> 140594519492688
	140594519492688 [label=AccumulateGrad]
	140594519491680 -> 140594519491632
	140594519491680 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519492016 -> 140594519491680
	140594519492016 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 782, 32)"]
	140594519492208 -> 140594519492016
	140594519492208 [label=CloneBackward0]
	140594519492496 -> 140594519492208
	140594519492496 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519492784 -> 140594519492496
	140594519492784 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519492592 -> 140594519492784
	140594519492592 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594519492880 -> 140594519492592
	140594519492880 -> 140594519641040 [dir=none]
	140594519641040 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594519492880 -> 140594519641840 [dir=none]
	140594519641840 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519492880 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519492976 -> 140594519492880
	140594704424368 [label="model.encoder.layers.4.self_attn.k_proj.bias
 (256)" fillcolor=lightblue]
	140594704424368 -> 140594519492976
	140594519492976 [label=AccumulateGrad]
	140594519492928 -> 140594519492880
	140594519492928 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519492544 -> 140594519492928
	140594519491824 -> 140594519492880
	140594519491824 [label=TBackward0]
	140594519493168 -> 140594519491824
	140594704423808 [label="model.encoder.layers.4.self_attn.k_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594704423808 -> 140594519493168
	140594519493168 [label=AccumulateGrad]
	140594519491152 -> 140594519491104
	140594519491152 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 782, 32)"]
	140594519491488 -> 140594519491152
	140594519491488 [label=CloneBackward0]
	140594519491248 -> 140594519491488
	140594519491248 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519492112 -> 140594519491248
	140594519492112 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519492736 -> 140594519492112
	140594519492736 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594519492832 -> 140594519492736
	140594519492832 -> 140594519641600 [dir=none]
	140594519641600 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594519492832 -> 140594519641280 [dir=none]
	140594519641280 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519492832 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519493120 -> 140594519492832
	140594704424288 [label="model.encoder.layers.4.self_attn.v_proj.bias
 (256)" fillcolor=lightblue]
	140594704424288 -> 140594519493120
	140594519493120 [label=AccumulateGrad]
	140594519493024 -> 140594519492832
	140594519493024 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594704774288 -> 140594519493024
	140594519491296 -> 140594519492832
	140594519491296 [label=TBackward0]
	140594519493312 -> 140594519491296
	140594704423968 [label="model.encoder.layers.4.self_attn.v_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594704423968 -> 140594519493312
	140594519493312 [label=AccumulateGrad]
	140594519074272 -> 140594704756688
	140594519074272 [label=TBackward0]
	140594519490864 -> 140594519074272
	140594681072832 [label="model.encoder.layers.4.self_attn.out_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594681072832 -> 140594519490864
	140594519490864 [label=AccumulateGrad]
	140594704774816 -> 140594704774912
	140594681071392 [label="model.encoder.layers.4.self_attn_layer_norm.weight
 (256)" fillcolor=lightblue]
	140594681071392 -> 140594704774816
	140594704774816 [label=AccumulateGrad]
	140594704774864 -> 140594704774912
	140594681071472 [label="model.encoder.layers.4.self_attn_layer_norm.bias
 (256)" fillcolor=lightblue]
	140594681071472 -> 140594704774864
	140594704774864 [label=AccumulateGrad]
	140594704774960 -> 140594704775296
	140594704774960 -> 140594519548208 [dir=none]
	140594519548208 [label="other
 (6, 782, 256)" fillcolor=orange]
	140594704774960 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704774000 -> 140594704774960
	140594704774000 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594519073936 -> 140594704774000
	140594519073936 -> 140594519551248 [dir=none]
	140594519551248 [label="mat1
 (4692, 2048)" fillcolor=orange]
	140594519073936 -> 140594519548528 [dir=none]
	140594519548528 [label="mat2
 (2048, 256)" fillcolor=orange]
	140594519073936 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :   (4692, 2048)
mat1_strides:      (2048, 1)
mat2        : [saved tensor]
mat2_sizes  :    (2048, 256)
mat2_strides:      (1, 2048)"]
	140594704774624 -> 140594519073936
	140594681071152 [label="model.encoder.layers.4.fc2.bias
 (256)" fillcolor=lightblue]
	140594681071152 -> 140594704774624
	140594704774624 [label=AccumulateGrad]
	140594519491056 -> 140594519073936
	140594519491056 [label="ViewBackward0
--------------------------
self_sizes: (6, 782, 2048)"]
	140594519490672 -> 140594519491056
	140594519490672 -> 140594519551728 [dir=none]
	140594519551728 [label="result
 (6, 782, 2048)" fillcolor=orange]
	140594519490672 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594519491920 -> 140594519490672
	140594519491920 [label="ViewBackward0
------------------------
self_sizes: (4692, 2048)"]
	140594519492640 -> 140594519491920
	140594519492640 -> 140594519551008 [dir=none]
	140594519551008 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594519492640 -> 140594519551648 [dir=none]
	140594519551648 [label="mat2
 (256, 2048)" fillcolor=orange]
	140594519492640 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :    (256, 2048)
mat2_strides:       (1, 256)"]
	140594519493072 -> 140594519492640
	140594681071312 [label="model.encoder.layers.4.fc1.bias
 (2048)" fillcolor=lightblue]
	140594681071312 -> 140594519493072
	140594519493072 [label=AccumulateGrad]
	140594519493264 -> 140594519492640
	140594519493264 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594704774912 -> 140594519493264
	140594519491392 -> 140594519492640
	140594519491392 [label=TBackward0]
	140594519493456 -> 140594519491392
	140594681071232 [label="model.encoder.layers.4.fc1.weight
 (2048, 256)" fillcolor=lightblue]
	140594681071232 -> 140594519493456
	140594519493456 [label=AccumulateGrad]
	140594519490768 -> 140594519073936
	140594519490768 [label=TBackward0]
	140594519492304 -> 140594519490768
	140594681071072 [label="model.encoder.layers.4.fc2.weight
 (256, 2048)" fillcolor=lightblue]
	140594681071072 -> 140594519492304
	140594519492304 [label=AccumulateGrad]
	140594704775344 -> 140594704775536
	140594681070912 [label="model.encoder.layers.4.final_layer_norm.weight
 (256)" fillcolor=lightblue]
	140594681070912 -> 140594704775344
	140594704775344 [label=AccumulateGrad]
	140594704775488 -> 140594704775536
	140594681070992 [label="model.encoder.layers.4.final_layer_norm.bias
 (256)" fillcolor=lightblue]
	140594681070992 -> 140594704775488
	140594704775488 [label=AccumulateGrad]
	140594704775680 -> 140594704775824
	140594704775680 -> 140594519551488 [dir=none]
	140594519551488 [label="other
 (6, 782, 256)" fillcolor=orange]
	140594704775680 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704774480 -> 140594704775680
	140594704774480 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594704756256 -> 140594704774480
	140594704756256 -> 140594519551328 [dir=none]
	140594519551328 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594704756256 -> 140594519551808 [dir=none]
	140594519551808 [label="mat2
 (256, 256)" fillcolor=orange]
	140594704756256 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519493216 -> 140594704756256
	140594681070352 [label="model.encoder.layers.5.self_attn.out_proj.bias
 (256)" fillcolor=lightblue]
	140594681070352 -> 140594519493216
	140594519493216 [label=AccumulateGrad]
	140594519491584 -> 140594704756256
	140594519491584 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519490624 -> 140594519491584
	140594519490624 [label="UnsafeViewBackward0
---------------------------
self_sizes: (6, 782, 8, 32)"]
	140594519493600 -> 140594519490624
	140594519493600 [label=CloneBackward0]
	140594519493696 -> 140594519493600
	140594519493696 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519493792 -> 140594519493696
	140594519493792 [label="ViewBackward0
-------------------------
self_sizes: (48, 782, 32)"]
	140594519493888 -> 140594519493792
	140594519493888 -> 140594704303504 [dir=none]
	140594704303504 [label="mat2
 (48, 782, 32)" fillcolor=orange]
	140594519493888 -> 140594704303664 [dir=none]
	140594704303664 [label="self
 (48, 782, 782)" fillcolor=orange]
	140594519493888 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594519493984 -> 140594519493888
	140594519493984 -> 140594519550688 [dir=none]
	140594519550688 [label="result
 (48, 782, 782)" fillcolor=orange]
	140594519493984 [label="SoftmaxBackward0
----------------------------
dim   : 18446744073709551615
result:       [saved tensor]"]
	140594519494128 -> 140594519493984
	140594519494128 [label="ViewBackward0
----------------------------
self_sizes: (6, 8, 782, 782)"]
	140594519494224 -> 140594519494128
	140594519494224 [label="AddBackward0
------------
alpha: 1"]
	140594519494320 -> 140594519494224
	140594519494320 [label="ViewBackward0
--------------------------
self_sizes: (48, 782, 782)"]
	140594519494416 -> 140594519494320
	140594519494416 -> 140594704303104 [dir=none]
	140594704303104 [label="mat2
 (48, 32, 782)" fillcolor=orange]
	140594519494416 -> 140594704303424 [dir=none]
	140594704303424 [label="self
 (48, 782, 32)" fillcolor=orange]
	140594519494416 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594519494512 -> 140594519494416
	140594519494512 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 782, 32)"]
	140594519494608 -> 140594519494512
	140594519494608 [label=CloneBackward0]
	140594519560352 -> 140594519494608
	140594519560352 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519560448 -> 140594519560352
	140594519560448 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519560544 -> 140594519560448
	140594519560544 -> 140594519550928 [dir=none]
	140594519550928 [label="other
 ()" fillcolor=orange]
	140594519560544 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519560640 -> 140594519560544
	140594519560640 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594519560736 -> 140594519560640
	140594519560736 -> 140594519550848 [dir=none]
	140594519550848 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594519560736 -> 140594519551088 [dir=none]
	140594519551088 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519560736 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519560832 -> 140594519560736
	140594681070512 [label="model.encoder.layers.5.self_attn.q_proj.bias
 (256)" fillcolor=lightblue]
	140594681070512 -> 140594519560832
	140594519560832 [label=AccumulateGrad]
	140594519560784 -> 140594519560736
	140594519560784 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519560928 -> 140594519560784
	140594519560928 [label="AddBackward0
------------
alpha: 1"]
	140594704775536 -> 140594519560928
	140594519560256 -> 140594519560736
	140594519560256 [label=TBackward0]
	140594519561072 -> 140594519560256
	140594681070432 [label="model.encoder.layers.5.self_attn.q_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594681070432 -> 140594519561072
	140594519561072 [label=AccumulateGrad]
	140594519494464 -> 140594519494416
	140594519494464 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519494560 -> 140594519494464
	140594519494560 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 782, 32)"]
	140594519560592 -> 140594519494560
	140594519560592 [label=CloneBackward0]
	140594519560880 -> 140594519560592
	140594519560880 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519561168 -> 140594519560880
	140594519561168 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519560976 -> 140594519561168
	140594519560976 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594519561264 -> 140594519560976
	140594519561264 -> 140594519551568 [dir=none]
	140594519551568 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594519561264 -> 140594519550768 [dir=none]
	140594519550768 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519561264 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519561360 -> 140594519561264
	140594681070832 [label="model.encoder.layers.5.self_attn.k_proj.bias
 (256)" fillcolor=lightblue]
	140594681070832 -> 140594519561360
	140594519561360 [label=AccumulateGrad]
	140594519561312 -> 140594519561264
	140594519561312 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519560928 -> 140594519561312
	140594519560304 -> 140594519561264
	140594519560304 [label=TBackward0]
	140594519561552 -> 140594519560304
	140594681070752 [label="model.encoder.layers.5.self_attn.k_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594681070752 -> 140594519561552
	140594519561552 [label=AccumulateGrad]
	140594519493936 -> 140594519493888
	140594519493936 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 782, 32)"]
	140594519494272 -> 140594519493936
	140594519494272 [label=CloneBackward0]
	140594519494032 -> 140594519494272
	140594519494032 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519494080 -> 140594519494032
	140594519494080 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519561120 -> 140594519494080
	140594519561120 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594519561216 -> 140594519561120
	140594519561216 -> 140594519550528 [dir=none]
	140594519550528 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594519561216 -> 140594519550288 [dir=none]
	140594519550288 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519561216 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519561504 -> 140594519561216
	140594681070672 [label="model.encoder.layers.5.self_attn.v_proj.bias
 (256)" fillcolor=lightblue]
	140594681070672 -> 140594519561504
	140594519561504 [label=AccumulateGrad]
	140594519561408 -> 140594519561216
	140594519561408 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594704775536 -> 140594519561408
	140594519560400 -> 140594519561216
	140594519560400 [label=TBackward0]
	140594519561696 -> 140594519560400
	140594681070592 [label="model.encoder.layers.5.self_attn.v_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594681070592 -> 140594519561696
	140594519561696 [label=AccumulateGrad]
	140594519490960 -> 140594704756256
	140594519490960 [label=TBackward0]
	140594519493648 -> 140594519490960
	140594681070272 [label="model.encoder.layers.5.self_attn.out_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594681070272 -> 140594519493648
	140594519493648 [label=AccumulateGrad]
	140594704775968 -> 140594704776160
	140594681070112 [label="model.encoder.layers.5.self_attn_layer_norm.weight
 (256)" fillcolor=lightblue]
	140594681070112 -> 140594704775968
	140594704775968 [label=AccumulateGrad]
	140594704776016 -> 140594704776160
	140594681070192 [label="model.encoder.layers.5.self_attn_layer_norm.bias
 (256)" fillcolor=lightblue]
	140594681070192 -> 140594704776016
	140594704776016 [label=AccumulateGrad]
	140594704776208 -> 140594704776544
	140594704776208 -> 140594519550128 [dir=none]
	140594519550128 [label="other
 (6, 782, 256)" fillcolor=orange]
	140594704776208 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704775104 -> 140594704776208
	140594704775104 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594704775152 -> 140594704775104
	140594704775152 -> 140594519550048 [dir=none]
	140594519550048 [label="mat1
 (4692, 2048)" fillcolor=orange]
	140594704775152 -> 140594519549568 [dir=none]
	140594519549568 [label="mat2
 (2048, 256)" fillcolor=orange]
	140594704775152 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :   (4692, 2048)
mat1_strides:      (2048, 1)
mat2        : [saved tensor]
mat2_sizes  :    (2048, 256)
mat2_strides:      (1, 2048)"]
	140594519493840 -> 140594704775152
	140594681069872 [label="model.encoder.layers.5.fc2.bias
 (256)" fillcolor=lightblue]
	140594681069872 -> 140594519493840
	140594519493840 [label=AccumulateGrad]
	140594519493360 -> 140594704775152
	140594519493360 [label="ViewBackward0
--------------------------
self_sizes: (6, 782, 2048)"]
	140594519493552 -> 140594519493360
	140594519493552 -> 140594519549888 [dir=none]
	140594519549888 [label="result
 (6, 782, 2048)" fillcolor=orange]
	140594519493552 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594519494368 -> 140594519493552
	140594519494368 [label="ViewBackward0
------------------------
self_sizes: (4692, 2048)"]
	140594519561024 -> 140594519494368
	140594519561024 -> 140594519550608 [dir=none]
	140594519550608 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594519561024 -> 140594519549808 [dir=none]
	140594519549808 [label="mat2
 (256, 2048)" fillcolor=orange]
	140594519561024 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :    (256, 2048)
mat2_strides:       (1, 256)"]
	140594519561456 -> 140594519561024
	140594681070032 [label="model.encoder.layers.5.fc1.bias
 (2048)" fillcolor=lightblue]
	140594681070032 -> 140594519561456
	140594519561456 [label=AccumulateGrad]
	140594519561648 -> 140594519561024
	140594519561648 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594704776160 -> 140594519561648
	140594519560496 -> 140594519561024
	140594519560496 [label=TBackward0]
	140594519561840 -> 140594519560496
	140594681069952 [label="model.encoder.layers.5.fc1.weight
 (2048, 256)" fillcolor=lightblue]
	140594681069952 -> 140594519561840
	140594519561840 [label=AccumulateGrad]
	140594519493408 -> 140594704775152
	140594519493408 [label=TBackward0]
	140594519494176 -> 140594519493408
	140594681069792 [label="model.encoder.layers.5.fc2.weight
 (256, 2048)" fillcolor=lightblue]
	140594681069792 -> 140594519494176
	140594519494176 [label=AccumulateGrad]
	140594704776592 -> 140594704776640
	140594681069632 [label="model.encoder.layers.5.final_layer_norm.weight
 (256)" fillcolor=lightblue]
	140594681069632 -> 140594704776592
	140594704776592 [label=AccumulateGrad]
	140594704776832 -> 140594704776640
	140594681069712 [label="model.encoder.layers.5.final_layer_norm.bias
 (256)" fillcolor=lightblue]
	140594681069712 -> 140594704776832
	140594704776832 [label=AccumulateGrad]
	140594704283680 -> 140594704281856
	140594704283680 [label=TBackward0]
	140594704776400 -> 140594704283680
	140594680941680 [label="model.decoder.layers.0.encoder_attn.k_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594680941680 -> 140594704776400
	140594704776400 [label=AccumulateGrad]
	140594704284688 -> 140594704284832
	140594704284688 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 782, 32)"]
	140594704284208 -> 140594704284688
	140594704284208 [label=CloneBackward0]
	140594704284640 -> 140594704284208
	140594704284640 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594704283104 -> 140594704284640
	140594704283104 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594704282000 -> 140594704283104
	140594704282000 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594704281904 -> 140594704282000
	140594704281904 -> 140594519551888 [dir=none]
	140594519551888 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594704281904 -> 140594519549728 [dir=none]
	140594519549728 [label="mat2
 (256, 256)" fillcolor=orange]
	140594704281904 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594704284592 -> 140594704281904
	140594680941440 [label="model.decoder.layers.0.encoder_attn.v_proj.bias
 (256)" fillcolor=lightblue]
	140594680941440 -> 140594704284592
	140594704284592 [label=AccumulateGrad]
	140594704776688 -> 140594704281904
	140594704776688 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594704776640 -> 140594704776688
	140594704777072 -> 140594704281904
	140594704777072 [label=TBackward0]
	140594704775776 -> 140594704777072
	140594680941520 [label="model.decoder.layers.0.encoder_attn.v_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594680941520 -> 140594704775776
	140594704775776 [label=AccumulateGrad]
	140594704389744 -> 140594704390608
	140594704389744 [label=TBackward0]
	140594704417024 -> 140594704389744
	140594680941200 [label="model.decoder.layers.0.encoder_attn.out_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594680941200 -> 140594704417024
	140594704417024 [label=AccumulateGrad]
	140594704391520 -> 140594704388736
	140594680941040 [label="model.decoder.layers.0.encoder_attn_layer_norm.weight
 (256)" fillcolor=lightblue]
	140594680941040 -> 140594704391520
	140594704391520 [label=AccumulateGrad]
	140594704388592 -> 140594704388736
	140594680940960 [label="model.decoder.layers.0.encoder_attn_layer_norm.bias
 (256)" fillcolor=lightblue]
	140594680940960 -> 140594704388592
	140594704388592 [label=AccumulateGrad]
	140594704388784 -> 140594704391088
	140594704388784 -> 140594519549968 [dir=none]
	140594519549968 [label="other
 (6, 100, 256)" fillcolor=orange]
	140594704388784 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704389840 -> 140594704388784
	140594704389840 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594704390704 -> 140594704389840
	140594704390704 -> 140594519549408 [dir=none]
	140594519549408 [label="mat1
 (600, 2048)" fillcolor=orange]
	140594704390704 -> 140594519549648 [dir=none]
	140594519549648 [label="mat2
 (2048, 256)" fillcolor=orange]
	140594704390704 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (600, 2048)
mat1_strides:      (2048, 1)
mat2        : [saved tensor]
mat2_sizes  :    (2048, 256)
mat2_strides:      (1, 2048)"]
	140594704448672 -> 140594704390704
	140594680940640 [label="model.decoder.layers.0.fc2.bias
 (256)" fillcolor=lightblue]
	140594680940640 -> 140594704448672
	140594704448672 [label=AccumulateGrad]
	140594704416928 -> 140594704390704
	140594704416928 [label="ViewBackward0
--------------------------
self_sizes: (6, 100, 2048)"]
	140594704285072 -> 140594704416928
	140594704285072 -> 140594519549248 [dir=none]
	140594519549248 [label="result
 (6, 100, 2048)" fillcolor=orange]
	140594704285072 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594704283488 -> 140594704285072
	140594704283488 [label="ViewBackward0
-----------------------
self_sizes: (600, 2048)"]
	140594704282096 -> 140594704283488
	140594704282096 -> 140594519548768 [dir=none]
	140594519548768 [label="mat1
 (600, 256)" fillcolor=orange]
	140594704282096 -> 140594519549168 [dir=none]
	140594519549168 [label="mat2
 (256, 2048)" fillcolor=orange]
	140594704282096 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :    (256, 2048)
mat2_strides:       (1, 256)"]
	140594519493744 -> 140594704282096
	140594680940800 [label="model.decoder.layers.0.fc1.bias
 (2048)" fillcolor=lightblue]
	140594680940800 -> 140594519493744
	140594519493744 [label=AccumulateGrad]
	140594519493504 -> 140594704282096
	140594519493504 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594704388736 -> 140594519493504
	140594704284400 -> 140594704282096
	140594704284400 [label=TBackward0]
	140594704776352 -> 140594704284400
	140594680940880 [label="model.decoder.layers.0.fc1.weight
 (2048, 256)" fillcolor=lightblue]
	140594680940880 -> 140594704776352
	140594704776352 [label=AccumulateGrad]
	140594704389168 -> 140594704390704
	140594704389168 [label=TBackward0]
	140594704282816 -> 140594704389168
	140594680940720 [label="model.decoder.layers.0.fc2.weight
 (256, 2048)" fillcolor=lightblue]
	140594680940720 -> 140594704282816
	140594704282816 [label=AccumulateGrad]
	140594704388832 -> 140594704388400
	140594680940560 [label="model.decoder.layers.0.final_layer_norm.weight
 (256)" fillcolor=lightblue]
	140594680940560 -> 140594704388832
	140594704388832 [label=AccumulateGrad]
	140594704388352 -> 140594704388400
	140594680940480 [label="model.decoder.layers.0.final_layer_norm.bias
 (256)" fillcolor=lightblue]
	140594680940480 -> 140594704388352
	140594704388352 [label=AccumulateGrad]
	140594704388880 -> 140594704388208
	140594704388880 -> 140594519549088 [dir=none]
	140594519549088 [label="other
 (6, 100, 256)" fillcolor=orange]
	140594704388880 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704389504 -> 140594704388880
	140594704389504 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594704391040 -> 140594704389504
	140594704391040 -> 140594519548928 [dir=none]
	140594519548928 [label="mat1
 (600, 256)" fillcolor=orange]
	140594704391040 -> 140594519550208 [dir=none]
	140594519550208 [label="mat2
 (256, 256)" fillcolor=orange]
	140594704391040 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594704775728 -> 140594704391040
	140594680939840 [label="model.decoder.layers.1.self_attn.out_proj.bias
 (256)" fillcolor=lightblue]
	140594680939840 -> 140594704775728
	140594704775728 [label=AccumulateGrad]
	140594704776880 -> 140594704391040
	140594704776880 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594704285264 -> 140594704776880
	140594704285264 [label="UnsafeViewBackward0
---------------------------
self_sizes: (6, 100, 8, 32)"]
	140594519561936 -> 140594704285264
	140594519561936 [label=CloneBackward0]
	140594519561744 -> 140594519561936
	140594519561744 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519562032 -> 140594519561744
	140594519562032 [label="ViewBackward0
-------------------------
self_sizes: (48, 100, 32)"]
	140594519562128 -> 140594519562032
	140594519562128 -> 140594682078128 [dir=none]
	140594682078128 [label="mat2
 (48, 100, 32)" fillcolor=orange]
	140594519562128 -> 140594682078288 [dir=none]
	140594682078288 [label="self
 (48, 100, 100)" fillcolor=orange]
	140594519562128 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594519562224 -> 140594519562128
	140594519562224 -> 140594519551408 [dir=none]
	140594519551408 [label="result
 (48, 100, 100)" fillcolor=orange]
	140594519562224 [label="SoftmaxBackward0
----------------------------
dim   : 18446744073709551615
result:       [saved tensor]"]
	140594519562368 -> 140594519562224
	140594519562368 -> 140594682077728 [dir=none]
	140594682077728 [label="mat2
 (48, 32, 100)" fillcolor=orange]
	140594519562368 -> 140594682078048 [dir=none]
	140594682078048 [label="self
 (48, 100, 32)" fillcolor=orange]
	140594519562368 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594519562464 -> 140594519562368
	140594519562464 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 100, 32)"]
	140594519562608 -> 140594519562464
	140594519562608 [label=CloneBackward0]
	140594519562704 -> 140594519562608
	140594519562704 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519562800 -> 140594519562704
	140594519562800 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519562896 -> 140594519562800
	140594519562896 -> 140594519548608 [dir=none]
	140594519548608 [label="other
 ()" fillcolor=orange]
	140594519562896 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519562992 -> 140594519562896
	140594519562992 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594519563088 -> 140594519562992
	140594519563088 -> 140594519548448 [dir=none]
	140594519548448 [label="mat1
 (600, 256)" fillcolor=orange]
	140594519563088 -> 140594519548848 [dir=none]
	140594519548848 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519563088 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519563184 -> 140594519563088
	140594680940000 [label="model.decoder.layers.1.self_attn.q_proj.bias
 (256)" fillcolor=lightblue]
	140594680940000 -> 140594519563184
	140594519563184 [label=AccumulateGrad]
	140594519563136 -> 140594519563088
	140594519563136 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519563280 -> 140594519563136
	140594519563280 [label="AddBackward0
------------
alpha: 1"]
	140594704388400 -> 140594519563280
	140594713911600 -> 140594519563280
	140594519562512 -> 140594519563088
	140594519562512 [label=TBackward0]
	140594519563424 -> 140594519562512
	140594680940080 [label="model.decoder.layers.1.self_attn.q_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594680940080 -> 140594519563424
	140594519563424 [label=AccumulateGrad]
	140594519562416 -> 140594519562368
	140594519562416 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519562752 -> 140594519562416
	140594519562752 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 100, 32)"]
	140594519562944 -> 140594519562752
	140594519562944 [label=CloneBackward0]
	140594519563232 -> 140594519562944
	140594519563232 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519563520 -> 140594519563232
	140594519563520 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519563328 -> 140594519563520
	140594519563328 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594519563616 -> 140594519563328
	140594519563616 -> 140594519549488 [dir=none]
	140594519549488 [label="mat1
 (600, 256)" fillcolor=orange]
	140594519563616 -> 140594519549008 [dir=none]
	140594519549008 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519563616 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519563712 -> 140594519563616
	140594680940320 [label="model.decoder.layers.1.self_attn.k_proj.bias
 (256)" fillcolor=lightblue]
	140594680940320 -> 140594519563712
	140594519563712 [label=AccumulateGrad]
	140594519563664 -> 140594519563616
	140594519563664 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519563280 -> 140594519563664
	140594519562560 -> 140594519563616
	140594519562560 [label=TBackward0]
	140594519563904 -> 140594519562560
	140594680940400 [label="model.decoder.layers.1.self_attn.k_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594680940400 -> 140594519563904
	140594519563904 [label=AccumulateGrad]
	140594519562176 -> 140594519562128
	140594519562176 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 100, 32)"]
	140594519562656 -> 140594519562176
	140594519562656 [label=CloneBackward0]
	140594519563040 -> 140594519562656
	140594519563040 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519563376 -> 140594519563040
	140594519563376 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519563760 -> 140594519563376
	140594519563760 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594519564000 -> 140594519563760
	140594519564000 -> 140594519548128 [dir=none]
	140594519548128 [label="mat1
 (600, 256)" fillcolor=orange]
	140594519564000 -> 140594519548048 [dir=none]
	140594519548048 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519564000 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519563808 -> 140594519564000
	140594680940160 [label="model.decoder.layers.1.self_attn.v_proj.bias
 (256)" fillcolor=lightblue]
	140594680940160 -> 140594519563808
	140594519563808 [label=AccumulateGrad]
	140594519563952 -> 140594519564000
	140594519563952 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594704388400 -> 140594519563952
	140594519562320 -> 140594519564000
	140594519562320 [label=TBackward0]
	140594519564192 -> 140594519562320
	140594680940240 [label="model.decoder.layers.1.self_attn.v_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594680940240 -> 140594519564192
	140594519564192 [label=AccumulateGrad]
	140594704284880 -> 140594704391040
	140594704284880 [label=TBackward0]
	140594519561888 -> 140594704284880
	140594680939920 [label="model.decoder.layers.1.self_attn.out_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594680939920 -> 140594519561888
	140594519561888 [label=AccumulateGrad]
	140594704392144 -> 140594704363088
	140594680939120 [label="model.decoder.layers.1.self_attn_layer_norm.weight
 (256)" fillcolor=lightblue]
	140594680939120 -> 140594704392144
	140594704392144 [label=AccumulateGrad]
	140594704388160 -> 140594704363088
	140594680939280 [label="model.decoder.layers.1.self_attn_layer_norm.bias
 (256)" fillcolor=lightblue]
	140594680939280 -> 140594704388160
	140594704388160 [label=AccumulateGrad]
	140594704363280 -> 140594704362704
	140594704363280 -> 140594519550448 [dir=none]
	140594519550448 [label="other
 (6, 100, 256)" fillcolor=orange]
	140594704363280 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704389120 -> 140594704363280
	140594704389120 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594704284016 -> 140594704389120
	140594704284016 -> 140594519550368 [dir=none]
	140594519550368 [label="mat1
 (600, 256)" fillcolor=orange]
	140594704284016 -> 140594519551168 [dir=none]
	140594519551168 [label="mat2
 (256, 256)" fillcolor=orange]
	140594704284016 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594704391424 -> 140594704284016
	140594704601232 [label="model.decoder.layers.1.encoder_attn.out_proj.bias
 (256)" fillcolor=lightblue]
	140594704601232 -> 140594704391424
	140594704391424 [label=AccumulateGrad]
	140594519562080 -> 140594704284016
	140594519562080 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519560688 -> 140594519562080
	140594519560688 [label="UnsafeViewBackward0
---------------------------
self_sizes: (6, 100, 8, 32)"]
	140594519563472 -> 140594519560688
	140594519563472 [label=CloneBackward0]
	140594519563856 -> 140594519563472
	140594519563856 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519564144 -> 140594519563856
	140594519564144 [label="ViewBackward0
-------------------------
self_sizes: (48, 100, 32)"]
	140594519564096 -> 140594519564144
	140594519564096 -> 140594682079088 [dir=none]
	140594682079088 [label="mat2
 (48, 782, 32)" fillcolor=orange]
	140594519564096 -> 140594682079248 [dir=none]
	140594682079248 [label="self
 (48, 100, 782)" fillcolor=orange]
	140594519564096 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594519562272 -> 140594519564096
	140594519562272 -> 140594519548288 [dir=none]
	140594519548288 [label="result
 (48, 100, 782)" fillcolor=orange]
	140594519562272 [label="SoftmaxBackward0
----------------------------
dim   : 18446744073709551615
result:       [saved tensor]"]
	140594519535872 -> 140594519562272
	140594519535872 [label="ViewBackward0
----------------------------
self_sizes: (6, 8, 100, 782)"]
	140594519535968 -> 140594519535872
	140594519535968 [label="AddBackward0
------------
alpha: 1"]
	140594519536064 -> 140594519535968
	140594519536064 [label="ViewBackward0
--------------------------
self_sizes: (48, 100, 782)"]
	140594519536160 -> 140594519536064
	140594519536160 -> 140594682078688 [dir=none]
	140594682078688 [label="mat2
 (48, 32, 782)" fillcolor=orange]
	140594519536160 -> 140594682079008 [dir=none]
	140594682079008 [label="self
 (48, 100, 32)" fillcolor=orange]
	140594519536160 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594519536256 -> 140594519536160
	140594519536256 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 100, 32)"]
	140594519536400 -> 140594519536256
	140594519536400 [label=CloneBackward0]
	140594519536496 -> 140594519536400
	140594519536496 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519536592 -> 140594519536496
	140594519536592 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519536688 -> 140594519536592
	140594519536688 -> 140594519547968 [dir=none]
	140594519547968 [label="other
 ()" fillcolor=orange]
	140594519536688 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519536784 -> 140594519536688
	140594519536784 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594519536880 -> 140594519536784
	140594519536880 -> 140594519548368 [dir=none]
	140594519548368 [label="mat1
 (600, 256)" fillcolor=orange]
	140594519536880 -> 140594519549328 [dir=none]
	140594519549328 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519536880 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519536976 -> 140594519536880
	140594704601472 [label="model.decoder.layers.1.encoder_attn.q_proj.bias
 (256)" fillcolor=lightblue]
	140594704601472 -> 140594519536976
	140594519536976 [label=AccumulateGrad]
	140594519536928 -> 140594519536880
	140594519536928 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519537072 -> 140594519536928
	140594519537072 [label="AddBackward0
------------
alpha: 1"]
	140594704363088 -> 140594519537072
	140594713911600 -> 140594519537072
	140594519536304 -> 140594519536880
	140594519536304 [label=TBackward0]
	140594519537216 -> 140594519536304
	140594704601312 [label="model.decoder.layers.1.encoder_attn.q_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594704601312 -> 140594519537216
	140594519537216 [label=AccumulateGrad]
	140594519536208 -> 140594519536160
	140594519536208 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519536544 -> 140594519536208
	140594519536544 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 782, 32)"]
	140594519536736 -> 140594519536544
	140594519536736 [label=CloneBackward0]
	140594519537024 -> 140594519536736
	140594519537024 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519537312 -> 140594519537024
	140594519537312 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519537120 -> 140594519537312
	140594519537120 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594519537408 -> 140594519537120
	140594519537408 -> 140594519548688 [dir=none]
	140594519548688 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594519537408 -> 140594519552144 [dir=none]
	140594519552144 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519537408 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519537504 -> 140594519537408
	140594680938560 [label="model.decoder.layers.1.encoder_attn.k_proj.bias
 (256)" fillcolor=lightblue]
	140594680938560 -> 140594519537504
	140594519537504 [label=AccumulateGrad]
	140594519537456 -> 140594519537408
	140594519537456 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519537600 -> 140594519537456
	140594519537600 [label="AddBackward0
------------
alpha: 1"]
	140594704776640 -> 140594519537600
	140594519536352 -> 140594519537408
	140594519536352 [label=TBackward0]
	140594519537744 -> 140594519536352
	140594680939040 [label="model.decoder.layers.1.encoder_attn.k_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594680939040 -> 140594519537744
	140594519537744 [label=AccumulateGrad]
	140594519535728 -> 140594519564096
	140594519535728 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 782, 32)"]
	140594519536016 -> 140594519535728
	140594519536016 [label=CloneBackward0]
	140594519535776 -> 140594519536016
	140594519535776 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519536640 -> 140594519535776
	140594519536640 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519537264 -> 140594519536640
	140594519537264 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594519537360 -> 140594519537264
	140594519537360 -> 140594519552064 [dir=none]
	140594519552064 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594519537360 -> 140594519552384 [dir=none]
	140594519552384 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519537360 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519537792 -> 140594519537360
	140595246313936 [label="model.decoder.layers.1.encoder_attn.v_proj.bias
 (256)" fillcolor=lightblue]
	140595246313936 -> 140594519537792
	140594519537792 [label=AccumulateGrad]
	140594519537552 -> 140594519537360
	140594519537552 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594704776640 -> 140594519537552
	140594519535824 -> 140594519537360
	140594519535824 [label=TBackward0]
	140594519537888 -> 140594519535824
	140594680938960 [label="model.decoder.layers.1.encoder_attn.v_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594680938960 -> 140594519537888
	140594519537888 [label=AccumulateGrad]
	140594519561600 -> 140594704284016
	140594519561600 [label=TBackward0]
	140594519563568 -> 140594519561600
	140594704601872 [label="model.decoder.layers.1.encoder_attn.out_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594704601872 -> 140594519563568
	140594519563568 [label=AccumulateGrad]
	140594704362656 -> 140594704362464
	140594704602192 [label="model.decoder.layers.1.encoder_attn_layer_norm.weight
 (256)" fillcolor=lightblue]
	140594704602192 -> 140594704362656
	140594704362656 [label=AccumulateGrad]
	140594704362416 -> 140594704362464
	140594704602032 [label="model.decoder.layers.1.encoder_attn_layer_norm.bias
 (256)" fillcolor=lightblue]
	140594704602032 -> 140594704362416
	140594704362416 [label=AccumulateGrad]
	140594704362896 -> 140594704361840
	140594704362896 -> 140594519552624 [dir=none]
	140594519552624 [label="other
 (6, 100, 256)" fillcolor=orange]
	140594704362896 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704363040 -> 140594704362896
	140594704363040 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594704388544 -> 140594704363040
	140594704388544 -> 140594519552784 [dir=none]
	140594519552784 [label="mat1
 (600, 2048)" fillcolor=orange]
	140594704388544 -> 140594519552464 [dir=none]
	140594519552464 [label="mat2
 (2048, 256)" fillcolor=orange]
	140594704388544 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (600, 2048)
mat1_strides:      (2048, 1)
mat2        : [saved tensor]
mat2_sizes  :    (2048, 256)
mat2_strides:      (1, 2048)"]
	140594519564240 -> 140594704388544
	140594520096992 [label="model.decoder.layers.1.fc2.bias
 (256)" fillcolor=lightblue]
	140594520096992 -> 140594519564240
	140594519564240 [label=AccumulateGrad]
	140594519562848 -> 140594704388544
	140594519562848 [label="ViewBackward0
--------------------------
self_sizes: (6, 100, 2048)"]
	140594519561792 -> 140594519562848
	140594519561792 -> 140594519552944 [dir=none]
	140594519552944 [label="result
 (6, 100, 2048)" fillcolor=orange]
	140594519561792 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594519536448 -> 140594519561792
	140594519536448 [label="ViewBackward0
-----------------------
self_sizes: (600, 2048)"]
	140594519537168 -> 140594519536448
	140594519537168 -> 140594519552704 [dir=none]
	140594519552704 [label="mat1
 (600, 256)" fillcolor=orange]
	140594519537168 -> 140594519553024 [dir=none]
	140594519553024 [label="mat2
 (256, 2048)" fillcolor=orange]
	140594519537168 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :    (256, 2048)
mat2_strides:       (1, 256)"]
	140594519537648 -> 140594519537168
	140594520096832 [label="model.decoder.layers.1.fc1.bias
 (2048)" fillcolor=lightblue]
	140594520096832 -> 140594519537648
	140594519537648 [label=AccumulateGrad]
	140594519537840 -> 140594519537168
	140594519537840 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594704362464 -> 140594519537840
	140594519535920 -> 140594519537168
	140594519535920 [label=TBackward0]
	140594519538032 -> 140594519535920
	140594704602112 [label="model.decoder.layers.1.fc1.weight
 (2048, 256)" fillcolor=lightblue]
	140594704602112 -> 140594519538032
	140594519538032 [label=AccumulateGrad]
	140594519561984 -> 140594704388544
	140594519561984 [label=TBackward0]
	140594519536832 -> 140594519561984
	140594520096912 [label="model.decoder.layers.1.fc2.weight
 (256, 2048)" fillcolor=lightblue]
	140594520096912 -> 140594519536832
	140594519536832 [label=AccumulateGrad]
	140594704362368 -> 140594704362176
	140594520097072 [label="model.decoder.layers.1.final_layer_norm.weight
 (256)" fillcolor=lightblue]
	140594520097072 -> 140594704362368
	140594704362368 [label=AccumulateGrad]
	140594704361600 -> 140594704362176
	140594520097152 [label="model.decoder.layers.1.final_layer_norm.bias
 (256)" fillcolor=lightblue]
	140594520097152 -> 140594704361600
	140594704361600 [label=AccumulateGrad]
	140594704361120 -> 140594704363232
	140594704361120 -> 140594519553104 [dir=none]
	140594519553104 [label="other
 (6, 100, 256)" fillcolor=orange]
	140594704361120 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704361648 -> 140594704361120
	140594704361648 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594519564048 -> 140594704361648
	140594519564048 -> 140594519553264 [dir=none]
	140594519553264 [label="mat1
 (600, 256)" fillcolor=orange]
	140594519564048 -> 140594519552304 [dir=none]
	140594519552304 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519564048 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594704391952 -> 140594519564048
	140594520097792 [label="model.decoder.layers.2.self_attn.out_proj.bias
 (256)" fillcolor=lightblue]
	140594520097792 -> 140594704391952
	140594704391952 [label=AccumulateGrad]
	140594519537696 -> 140594519564048
	140594519537696 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519535680 -> 140594519537696
	140594519535680 [label="UnsafeViewBackward0
---------------------------
self_sizes: (6, 100, 8, 32)"]
	140594519538176 -> 140594519535680
	140594519538176 [label=CloneBackward0]
	140594519538272 -> 140594519538176
	140594519538272 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519538368 -> 140594519538272
	140594519538368 [label="ViewBackward0
-------------------------
self_sizes: (48, 100, 32)"]
	140594519538464 -> 140594519538368
	140594519538464 -> 140594682080128 [dir=none]
	140594682080128 [label="mat2
 (48, 100, 32)" fillcolor=orange]
	140594519538464 -> 140594682080288 [dir=none]
	140594682080288 [label="self
 (48, 100, 100)" fillcolor=orange]
	140594519538464 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594519538560 -> 140594519538464
	140594519538560 -> 140594519552224 [dir=none]
	140594519552224 [label="result
 (48, 100, 100)" fillcolor=orange]
	140594519538560 [label="SoftmaxBackward0
----------------------------
dim   : 18446744073709551615
result:       [saved tensor]"]
	140594519538704 -> 140594519538560
	140594519538704 -> 140594682079728 [dir=none]
	140594682079728 [label="mat2
 (48, 32, 100)" fillcolor=orange]
	140594519538704 -> 140594682080048 [dir=none]
	140594682080048 [label="self
 (48, 100, 32)" fillcolor=orange]
	140594519538704 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594519538800 -> 140594519538704
	140594519538800 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 100, 32)"]
	140594519538944 -> 140594519538800
	140594519538944 [label=CloneBackward0]
	140594519539040 -> 140594519538944
	140594519539040 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519539136 -> 140594519539040
	140594519539136 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519539232 -> 140594519539136
	140594519539232 -> 140594519553424 [dir=none]
	140594519553424 [label="other
 ()" fillcolor=orange]
	140594519539232 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519539328 -> 140594519539232
	140594519539328 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594519539424 -> 140594519539328
	140594519539424 -> 140594519553584 [dir=none]
	140594519553584 [label="mat1
 (600, 256)" fillcolor=orange]
	140594519539424 -> 140594519553344 [dir=none]
	140594519553344 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519539424 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519539520 -> 140594519539424
	140594520097632 [label="model.decoder.layers.2.self_attn.q_proj.bias
 (256)" fillcolor=lightblue]
	140594520097632 -> 140594519539520
	140594519539520 [label=AccumulateGrad]
	140594519539472 -> 140594519539424
	140594519539472 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519539616 -> 140594519539472
	140594519539616 [label="AddBackward0
------------
alpha: 1"]
	140594704362176 -> 140594519539616
	140594713911600 -> 140594519539616
	140594519538848 -> 140594519539424
	140594519538848 [label=TBackward0]
	140594519539664 -> 140594519538848
	140594520097552 [label="model.decoder.layers.2.self_attn.q_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594520097552 -> 140594519539664
	140594519539664 [label=AccumulateGrad]
	140594519538752 -> 140594519538704
	140594519538752 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519539088 -> 140594519538752
	140594519539088 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 100, 32)"]
	140594519539280 -> 140594519539088
	140594519539280 [label=CloneBackward0]
	140594519539568 -> 140594519539280
	140594519539568 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519538896 -> 140594519539568
	140594519538896 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519351504 -> 140594519538896
	140594519351504 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594519351600 -> 140594519351504
	140594519351600 -> 140594519552544 [dir=none]
	140594519552544 [label="mat1
 (600, 256)" fillcolor=orange]
	140594519351600 -> 140594519553184 [dir=none]
	140594519553184 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519351600 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519351696 -> 140594519351600
	140594520097312 [label="model.decoder.layers.2.self_attn.k_proj.bias
 (256)" fillcolor=lightblue]
	140594520097312 -> 140594519351696
	140594519351696 [label=AccumulateGrad]
	140594519351648 -> 140594519351600
	140594519351648 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519539616 -> 140594519351648
	140594519351360 -> 140594519351600
	140594519351360 [label=TBackward0]
	140594519351888 -> 140594519351360
	140594520097232 [label="model.decoder.layers.2.self_attn.k_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594520097232 -> 140594519351888
	140594519351888 [label=AccumulateGrad]
	140594519538512 -> 140594519538464
	140594519538512 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 100, 32)"]
	140594519538992 -> 140594519538512
	140594519538992 [label=CloneBackward0]
	140594519539376 -> 140594519538992
	140594519539376 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519538656 -> 140594519539376
	140594519538656 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519351744 -> 140594519538656
	140594519351744 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594519351984 -> 140594519351744
	140594519351984 -> 140594519553744 [dir=none]
	140594519553744 [label="mat1
 (600, 256)" fillcolor=orange]
	140594519351984 -> 140594519553824 [dir=none]
	140594519553824 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519351984 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519351792 -> 140594519351984
	140594520097472 [label="model.decoder.layers.2.self_attn.v_proj.bias
 (256)" fillcolor=lightblue]
	140594520097472 -> 140594519351792
	140594519351792 [label=AccumulateGrad]
	140594519351936 -> 140594519351984
	140594519351936 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594704362176 -> 140594519351936
	140594519351408 -> 140594519351984
	140594519351408 [label=TBackward0]
	140594519352176 -> 140594519351408
	140594520097392 [label="model.decoder.layers.2.self_attn.v_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594520097392 -> 140594519352176
	140594519352176 [label=AccumulateGrad]
	140594519536112 -> 140594519564048
	140594519536112 [label=TBackward0]
	140594519538224 -> 140594519536112
	140594520097712 [label="model.decoder.layers.2.self_attn.out_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594520097712 -> 140594519538224
	140594519538224 [label=AccumulateGrad]
	140594704361504 -> 140594704361552
	140594520097872 [label="model.decoder.layers.2.self_attn_layer_norm.weight
 (256)" fillcolor=lightblue]
	140594520097872 -> 140594704361504
	140594704361504 [label=AccumulateGrad]
	140594704360784 -> 140594704361552
	140594520097952 [label="model.decoder.layers.2.self_attn_layer_norm.bias
 (256)" fillcolor=lightblue]
	140594520097952 -> 140594704360784
	140594704360784 [label=AccumulateGrad]
	140594704362224 -> 140594704361312
	140594704362224 -> 140594519554064 [dir=none]
	140594519554064 [label="other
 (6, 100, 256)" fillcolor=orange]
	140594704362224 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704361792 -> 140594704362224
	140594704361792 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594704389984 -> 140594704361792
	140594704389984 -> 140594519554144 [dir=none]
	140594519554144 [label="mat1
 (600, 256)" fillcolor=orange]
	140594704389984 -> 140594519553904 [dir=none]
	140594519553904 [label="mat2
 (256, 256)" fillcolor=orange]
	140594704389984 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519538416 -> 140594704389984
	140594520098592 [label="model.decoder.layers.2.encoder_attn.out_proj.bias
 (256)" fillcolor=lightblue]
	140594520098592 -> 140594519538416
	140594519538416 [label=AccumulateGrad]
	140594519537936 -> 140594704389984
	140594519537936 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519538128 -> 140594519537936
	140594519538128 [label="UnsafeViewBackward0
---------------------------
self_sizes: (6, 100, 8, 32)"]
	140594519539184 -> 140594519538128
	140594519539184 [label=CloneBackward0]
	140594519351840 -> 140594519539184
	140594519351840 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519352128 -> 140594519351840
	140594519352128 [label="ViewBackward0
-------------------------
self_sizes: (48, 100, 32)"]
	140594519352224 -> 140594519352128
	140594519352224 -> 140594682081088 [dir=none]
	140594682081088 [label="mat2
 (48, 782, 32)" fillcolor=orange]
	140594519352224 -> 140594682175552 [dir=none]
	140594682175552 [label="self
 (48, 100, 782)" fillcolor=orange]
	140594519352224 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594519352320 -> 140594519352224
	140594519352320 -> 140594519553504 [dir=none]
	140594519553504 [label="result
 (48, 100, 782)" fillcolor=orange]
	140594519352320 [label="SoftmaxBackward0
----------------------------
dim   : 18446744073709551615
result:       [saved tensor]"]
	140594519352464 -> 140594519352320
	140594519352464 [label="ViewBackward0
----------------------------
self_sizes: (6, 8, 100, 782)"]
	140594519352560 -> 140594519352464
	140594519352560 [label="AddBackward0
------------
alpha: 1"]
	140594519352656 -> 140594519352560
	140594519352656 [label="ViewBackward0
--------------------------
self_sizes: (48, 100, 782)"]
	140594519352752 -> 140594519352656
	140594519352752 -> 140594682080688 [dir=none]
	140594682080688 [label="mat2
 (48, 32, 782)" fillcolor=orange]
	140594519352752 -> 140594682081008 [dir=none]
	140594682081008 [label="self
 (48, 100, 32)" fillcolor=orange]
	140594519352752 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594519352848 -> 140594519352752
	140594519352848 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 100, 32)"]
	140594519352992 -> 140594519352848
	140594519352992 [label=CloneBackward0]
	140594519353088 -> 140594519352992
	140594519353088 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519353184 -> 140594519353088
	140594519353184 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519353280 -> 140594519353184
	140594519353280 -> 140594519554384 [dir=none]
	140594519554384 [label="other
 ()" fillcolor=orange]
	140594519353280 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519353376 -> 140594519353280
	140594519353376 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594519353472 -> 140594519353376
	140594519353472 -> 140594519554464 [dir=none]
	140594519554464 [label="mat1
 (600, 256)" fillcolor=orange]
	140594519353472 -> 140594519552864 [dir=none]
	140594519552864 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519353472 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519353568 -> 140594519353472
	140594520098432 [label="model.decoder.layers.2.encoder_attn.q_proj.bias
 (256)" fillcolor=lightblue]
	140594520098432 -> 140594519353568
	140594519353568 [label=AccumulateGrad]
	140594519353520 -> 140594519353472
	140594519353520 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519353664 -> 140594519353520
	140594519353664 [label="AddBackward0
------------
alpha: 1"]
	140594704361552 -> 140594519353664
	140594713911600 -> 140594519353664
	140594519352896 -> 140594519353472
	140594519352896 [label=TBackward0]
	140594519353808 -> 140594519352896
	140594520098352 [label="model.decoder.layers.2.encoder_attn.q_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594520098352 -> 140594519353808
	140594519353808 [label=AccumulateGrad]
	140594519352800 -> 140594519352752
	140594519352800 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519353136 -> 140594519352800
	140594519353136 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 782, 32)"]
	140594519353328 -> 140594519353136
	140594519353328 [label=CloneBackward0]
	140594519353616 -> 140594519353328
	140594519353616 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519353904 -> 140594519353616
	140594519353904 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519353712 -> 140594519353904
	140594519353712 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594519354000 -> 140594519353712
	140594519354000 -> 140594519553984 [dir=none]
	140594519553984 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594519354000 -> 140594519554304 [dir=none]
	140594519554304 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519354000 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519354096 -> 140594519354000
	140594520098112 [label="model.decoder.layers.2.encoder_attn.k_proj.bias
 (256)" fillcolor=lightblue]
	140594520098112 -> 140594519354096
	140594519354096 [label=AccumulateGrad]
	140594519354048 -> 140594519354000
	140594519354048 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519354192 -> 140594519354048
	140594519354192 [label="AddBackward0
------------
alpha: 1"]
	140594704776640 -> 140594519354192
	140594519352944 -> 140594519354000
	140594519352944 [label=TBackward0]
	140594519354336 -> 140594519352944
	140594520098032 [label="model.decoder.layers.2.encoder_attn.k_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594520098032 -> 140594519354336
	140594519354336 [label=AccumulateGrad]
	140594519352080 -> 140594519352224
	140594519352080 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 782, 32)"]
	140594519352608 -> 140594519352080
	140594519352608 [label=CloneBackward0]
	140594519352368 -> 140594519352608
	140594519352368 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519353232 -> 140594519352368
	140594519353232 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519353856 -> 140594519353232
	140594519353856 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594519353952 -> 140594519353856
	140594519353952 -> 140594519554624 [dir=none]
	140594519554624 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594519353952 -> 140594519554704 [dir=none]
	140594519554704 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519353952 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519354384 -> 140594519353952
	140594520098272 [label="model.decoder.layers.2.encoder_attn.v_proj.bias
 (256)" fillcolor=lightblue]
	140594520098272 -> 140594519354384
	140594519354384 [label=AccumulateGrad]
	140594519354144 -> 140594519353952
	140594519354144 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594704776640 -> 140594519354144
	140594519352416 -> 140594519353952
	140594519352416 [label=TBackward0]
	140594519354480 -> 140594519352416
	140594520098192 [label="model.decoder.layers.2.encoder_attn.v_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594520098192 -> 140594519354480
	140594519354480 [label=AccumulateGrad]
	140594519537984 -> 140594704389984
	140594519537984 [label=TBackward0]
	140594519538608 -> 140594519537984
	140594520098512 [label="model.decoder.layers.2.encoder_attn.out_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594520098512 -> 140594519538608
	140594519538608 [label=AccumulateGrad]
	140594704362512 -> 140594704360448
	140594520098672 [label="model.decoder.layers.2.encoder_attn_layer_norm.weight
 (256)" fillcolor=lightblue]
	140594520098672 -> 140594704362512
	140594704362512 [label=AccumulateGrad]
	140594704360304 -> 140594704360448
	140594520098752 [label="model.decoder.layers.2.encoder_attn_layer_norm.bias
 (256)" fillcolor=lightblue]
	140594520098752 -> 140594704360304
	140594704360304 [label=AccumulateGrad]
	140594704360640 -> 140594704359584
	140594704360640 -> 140594519554944 [dir=none]
	140594519554944 [label="other
 (6, 100, 256)" fillcolor=orange]
	140594704360640 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704360976 -> 140594704360640
	140594704360976 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594704361360 -> 140594704360976
	140594704361360 -> 140594519555024 [dir=none]
	140594519555024 [label="mat1
 (600, 2048)" fillcolor=orange]
	140594704361360 -> 140594519554784 [dir=none]
	140594519554784 [label="mat2
 (2048, 256)" fillcolor=orange]
	140594704361360 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (600, 2048)
mat1_strides:      (2048, 1)
mat2        : [saved tensor]
mat2_sizes  :    (2048, 256)
mat2_strides:      (1, 2048)"]
	140594519538080 -> 140594704361360
	140594520099072 [label="model.decoder.layers.2.fc2.bias
 (256)" fillcolor=lightblue]
	140594520099072 -> 140594519538080
	140594519538080 [label=AccumulateGrad]
	140594519538320 -> 140594704361360
	140594519538320 [label="ViewBackward0
--------------------------
self_sizes: (6, 100, 2048)"]
	140594519351552 -> 140594519538320
	140594519351552 -> 140594519555184 [dir=none]
	140594519555184 [label="result
 (6, 100, 2048)" fillcolor=orange]
	140594519351552 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594519353040 -> 140594519351552
	140594519353040 [label="ViewBackward0
-----------------------
self_sizes: (600, 2048)"]
	140594519353760 -> 140594519353040
	140594519353760 -> 140594519554544 [dir=none]
	140594519554544 [label="mat1
 (600, 256)" fillcolor=orange]
	140594519353760 -> 140594519555264 [dir=none]
	140594519555264 [label="mat2
 (256, 2048)" fillcolor=orange]
	140594519353760 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :    (256, 2048)
mat2_strides:       (1, 256)"]
	140594519354240 -> 140594519353760
	140594520098912 [label="model.decoder.layers.2.fc1.bias
 (2048)" fillcolor=lightblue]
	140594520098912 -> 140594519354240
	140594519354240 [label=AccumulateGrad]
	140594519354432 -> 140594519353760
	140594519354432 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594704360448 -> 140594519354432
	140594519352512 -> 140594519353760
	140594519352512 [label=TBackward0]
	140594519354624 -> 140594519352512
	140594520098832 [label="model.decoder.layers.2.fc1.weight
 (2048, 256)" fillcolor=lightblue]
	140594520098832 -> 140594519354624
	140594519354624 [label=AccumulateGrad]
	140594519352272 -> 140594704361360
	140594519352272 [label=TBackward0]
	140594519353424 -> 140594519352272
	140594520098992 [label="model.decoder.layers.2.fc2.weight
 (256, 2048)" fillcolor=lightblue]
	140594520098992 -> 140594519353424
	140594519353424 [label=AccumulateGrad]
	140594704359632 -> 140594704361984
	140594520099152 [label="model.decoder.layers.2.final_layer_norm.weight
 (256)" fillcolor=lightblue]
	140594520099152 -> 140594704359632
	140594704359632 [label=AccumulateGrad]
	140594704360112 -> 140594704361984
	140594520099232 [label="model.decoder.layers.2.final_layer_norm.bias
 (256)" fillcolor=lightblue]
	140594520099232 -> 140594704360112
	140594704360112 [label=AccumulateGrad]
	140594704360256 -> 140594704360064
	140594704360256 -> 140594519555344 [dir=none]
	140594519555344 [label="other
 (6, 100, 256)" fillcolor=orange]
	140594704360256 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704360688 -> 140594704360256
	140594704360688 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594704360736 -> 140594704360688
	140594704360736 -> 140594519555504 [dir=none]
	140594519555504 [label="mat1
 (600, 256)" fillcolor=orange]
	140594704360736 -> 140594519554224 [dir=none]
	140594519554224 [label="mat2
 (256, 256)" fillcolor=orange]
	140594704360736 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519354288 -> 140594704360736
	140594520099872 [label="model.decoder.layers.3.self_attn.out_proj.bias
 (256)" fillcolor=lightblue]
	140594520099872 -> 140594519354288
	140594519354288 [label=AccumulateGrad]
	140594519352704 -> 140594704360736
	140594519352704 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519351456 -> 140594519352704
	140594519351456 [label="UnsafeViewBackward0
---------------------------
self_sizes: (6, 100, 8, 32)"]
	140594519354768 -> 140594519351456
	140594519354768 [label=CloneBackward0]
	140594519354864 -> 140594519354768
	140594519354864 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519354960 -> 140594519354864
	140594519354960 [label="ViewBackward0
-------------------------
self_sizes: (48, 100, 32)"]
	140594519355056 -> 140594519354960
	140594519355056 -> 140594682176432 [dir=none]
	140594682176432 [label="mat2
 (48, 100, 32)" fillcolor=orange]
	140594519355056 -> 140594682176592 [dir=none]
	140594682176592 [label="self
 (48, 100, 100)" fillcolor=orange]
	140594519355056 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594519355152 -> 140594519355056
	140594519355152 -> 140594519553664 [dir=none]
	140594519553664 [label="result
 (48, 100, 100)" fillcolor=orange]
	140594519355152 [label="SoftmaxBackward0
----------------------------
dim   : 18446744073709551615
result:       [saved tensor]"]
	140594519355296 -> 140594519355152
	140594519355296 -> 140594682176032 [dir=none]
	140594682176032 [label="mat2
 (48, 32, 100)" fillcolor=orange]
	140594519355296 -> 140594682176352 [dir=none]
	140594682176352 [label="self
 (48, 100, 32)" fillcolor=orange]
	140594519355296 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594519355344 -> 140594519355296
	140594519355344 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 100, 32)"]
	140594519298256 -> 140594519355344
	140594519298256 [label=CloneBackward0]
	140594519298352 -> 140594519298256
	140594519298352 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519298448 -> 140594519298352
	140594519298448 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519298544 -> 140594519298448
	140594519298544 -> 140594519555664 [dir=none]
	140594519555664 [label="other
 ()" fillcolor=orange]
	140594519298544 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519298640 -> 140594519298544
	140594519298640 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594519298736 -> 140594519298640
	140594519298736 -> 140594519555824 [dir=none]
	140594519555824 [label="mat1
 (600, 256)" fillcolor=orange]
	140594519298736 -> 140594519555584 [dir=none]
	140594519555584 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519298736 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519298832 -> 140594519298736
	140594520099712 [label="model.decoder.layers.3.self_attn.q_proj.bias
 (256)" fillcolor=lightblue]
	140594520099712 -> 140594519298832
	140594519298832 [label=AccumulateGrad]
	140594519298784 -> 140594519298736
	140594519298784 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519298928 -> 140594519298784
	140594519298928 [label="AddBackward0
------------
alpha: 1"]
	140594704361984 -> 140594519298928
	140594713911600 -> 140594519298928
	140594519298160 -> 140594519298736
	140594519298160 [label=TBackward0]
	140594519299072 -> 140594519298160
	140594520099632 [label="model.decoder.layers.3.self_attn.q_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594520099632 -> 140594519299072
	140594519299072 [label=AccumulateGrad]
	140594519355200 -> 140594519355296
	140594519355200 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519298400 -> 140594519355200
	140594519298400 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 100, 32)"]
	140594519298592 -> 140594519298400
	140594519298592 [label=CloneBackward0]
	140594519298880 -> 140594519298592
	140594519298880 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519299168 -> 140594519298880
	140594519299168 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519298976 -> 140594519299168
	140594519298976 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594519299264 -> 140594519298976
	140594519299264 -> 140594519554864 [dir=none]
	140594519554864 [label="mat1
 (600, 256)" fillcolor=orange]
	140594519299264 -> 140594519555424 [dir=none]
	140594519555424 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519299264 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519299360 -> 140594519299264
	140594520099392 [label="model.decoder.layers.3.self_attn.k_proj.bias
 (256)" fillcolor=lightblue]
	140594520099392 -> 140594519299360
	140594519299360 [label=AccumulateGrad]
	140594519299312 -> 140594519299264
	140594519299312 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519298928 -> 140594519299312
	140594519298208 -> 140594519299264
	140594519298208 [label=TBackward0]
	140594519299552 -> 140594519298208
	140594520099312 [label="model.decoder.layers.3.self_attn.k_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594520099312 -> 140594519299552
	140594519299552 [label=AccumulateGrad]
	140594519355104 -> 140594519355056
	140594519355104 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 100, 32)"]
	140594519355248 -> 140594519355104
	140594519355248 [label=CloneBackward0]
	140594519298688 -> 140594519355248
	140594519298688 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519299024 -> 140594519298688
	140594519299024 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519299408 -> 140594519299024
	140594519299408 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594519299648 -> 140594519299408
	140594519299648 -> 140594519555984 [dir=none]
	140594519555984 [label="mat1
 (600, 256)" fillcolor=orange]
	140594519299648 -> 140594519555904 [dir=none]
	140594519555904 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519299648 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519299456 -> 140594519299648
	140594520099552 [label="model.decoder.layers.3.self_attn.v_proj.bias
 (256)" fillcolor=lightblue]
	140594520099552 -> 140594519299456
	140594519299456 [label=AccumulateGrad]
	140594519299600 -> 140594519299648
	140594519299600 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594704361984 -> 140594519299600
	140594519298112 -> 140594519299648
	140594519298112 [label=TBackward0]
	140594519299840 -> 140594519298112
	140594520099472 [label="model.decoder.layers.3.self_attn.v_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594520099472 -> 140594519299840
	140594519299840 [label=AccumulateGrad]
	140594519352032 -> 140594704360736
	140594519352032 [label=TBackward0]
	140594519354816 -> 140594519352032
	140594520099792 [label="model.decoder.layers.3.self_attn.out_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594520099792 -> 140594519354816
	140594519354816 [label=AccumulateGrad]
	140594704362848 -> 140594704338848
	140594520099952 [label="model.decoder.layers.3.self_attn_layer_norm.weight
 (256)" fillcolor=lightblue]
	140594520099952 -> 140594704362848
	140594704362848 [label=AccumulateGrad]
	140594704359872 -> 140594704338848
	140594520100032 [label="model.decoder.layers.3.self_attn_layer_norm.bias
 (256)" fillcolor=lightblue]
	140594520100032 -> 140594704359872
	140594704359872 [label=AccumulateGrad]
	140594704361168 -> 140594704338896
	140594704361168 -> 140594519555104 [dir=none]
	140594519555104 [label="other
 (6, 100, 256)" fillcolor=orange]
	140594704361168 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704360496 -> 140594704361168
	140594704360496 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594704362032 -> 140594704360496
	140594704362032 -> 140594519555744 [dir=none]
	140594519555744 [label="mat1
 (600, 256)" fillcolor=orange]
	140594704362032 -> 140594519244864 [dir=none]
	140594519244864 [label="mat2
 (256, 256)" fillcolor=orange]
	140594704362032 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519355008 -> 140594704362032
	140594520100672 [label="model.decoder.layers.3.encoder_attn.out_proj.bias
 (256)" fillcolor=lightblue]
	140594520100672 -> 140594519355008
	140594519355008 [label=AccumulateGrad]
	140594519354528 -> 140594704362032
	140594519354528 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519354720 -> 140594519354528
	140594519354720 [label="UnsafeViewBackward0
---------------------------
self_sizes: (6, 100, 8, 32)"]
	140594519299120 -> 140594519354720
	140594519299120 [label=CloneBackward0]
	140594519299504 -> 140594519299120
	140594519299504 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519299792 -> 140594519299504
	140594519299792 [label="ViewBackward0
-------------------------
self_sizes: (48, 100, 32)"]
	140594519299888 -> 140594519299792
	140594519299888 -> 140594682177392 [dir=none]
	140594682177392 [label="mat2
 (48, 782, 32)" fillcolor=orange]
	140594519299888 -> 140594682177552 [dir=none]
	140594682177552 [label="self
 (48, 100, 782)" fillcolor=orange]
	140594519299888 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594519299984 -> 140594519299888
	140594519299984 -> 140594519244944 [dir=none]
	140594519244944 [label="result
 (48, 100, 782)" fillcolor=orange]
	140594519299984 [label="SoftmaxBackward0
----------------------------
dim   : 18446744073709551615
result:       [saved tensor]"]
	140594519300128 -> 140594519299984
	140594519300128 [label="ViewBackward0
----------------------------
self_sizes: (6, 8, 100, 782)"]
	140594519300224 -> 140594519300128
	140594519300224 [label="AddBackward0
------------
alpha: 1"]
	140594519300320 -> 140594519300224
	140594519300320 [label="ViewBackward0
--------------------------
self_sizes: (48, 100, 782)"]
	140594519300416 -> 140594519300320
	140594519300416 -> 140594682176992 [dir=none]
	140594682176992 [label="mat2
 (48, 32, 782)" fillcolor=orange]
	140594519300416 -> 140594682177312 [dir=none]
	140594682177312 [label="self
 (48, 100, 32)" fillcolor=orange]
	140594519300416 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594519300512 -> 140594519300416
	140594519300512 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 100, 32)"]
	140594519300656 -> 140594519300512
	140594519300656 [label=CloneBackward0]
	140594519300752 -> 140594519300656
	140594519300752 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519300848 -> 140594519300752
	140594519300848 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519300944 -> 140594519300848
	140594519300944 -> 140594519245344 [dir=none]
	140594519245344 [label="other
 ()" fillcolor=orange]
	140594519300944 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519301040 -> 140594519300944
	140594519301040 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594519301136 -> 140594519301040
	140594519301136 -> 140594519245504 [dir=none]
	140594519245504 [label="mat1
 (600, 256)" fillcolor=orange]
	140594519301136 -> 140594519245184 [dir=none]
	140594519245184 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519301136 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519301232 -> 140594519301136
	140594520100512 [label="model.decoder.layers.3.encoder_attn.q_proj.bias
 (256)" fillcolor=lightblue]
	140594520100512 -> 140594519301232
	140594519301232 [label=AccumulateGrad]
	140594519301184 -> 140594519301136
	140594519301184 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519301328 -> 140594519301184
	140594519301328 [label="AddBackward0
------------
alpha: 1"]
	140594704338848 -> 140594519301328
	140594713911600 -> 140594519301328
	140594519300560 -> 140594519301136
	140594519300560 [label=TBackward0]
	140594519301472 -> 140594519300560
	140594520100432 [label="model.decoder.layers.3.encoder_attn.q_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594520100432 -> 140594519301472
	140594519301472 [label=AccumulateGrad]
	140594519300464 -> 140594519300416
	140594519300464 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519300800 -> 140594519300464
	140594519300800 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 782, 32)"]
	140594519300992 -> 140594519300800
	140594519300992 [label=CloneBackward0]
	140594519301280 -> 140594519300992
	140594519301280 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519301568 -> 140594519301280
	140594519301568 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519301376 -> 140594519301568
	140594519301376 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594519301664 -> 140594519301376
	140594519301664 -> 140594519245424 [dir=none]
	140594519245424 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594519301664 -> 140594519245264 [dir=none]
	140594519245264 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519301664 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519301760 -> 140594519301664
	140594520100192 [label="model.decoder.layers.3.encoder_attn.k_proj.bias
 (256)" fillcolor=lightblue]
	140594520100192 -> 140594519301760
	140594519301760 [label=AccumulateGrad]
	140594519301712 -> 140594519301664
	140594519301712 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519301856 -> 140594519301712
	140594519301856 [label="AddBackward0
------------
alpha: 1"]
	140594704776640 -> 140594519301856
	140594519300608 -> 140594519301664
	140594519300608 [label=TBackward0]
	140594519302000 -> 140594519300608
	140594520100112 [label="model.decoder.layers.3.encoder_attn.k_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594520100112 -> 140594519302000
	140594519302000 [label=AccumulateGrad]
	140594519299744 -> 140594519299888
	140594519299744 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 782, 32)"]
	140594519300272 -> 140594519299744
	140594519300272 [label=CloneBackward0]
	140594519300032 -> 140594519300272
	140594519300032 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519300896 -> 140594519300032
	140594519300896 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519301520 -> 140594519300896
	140594519301520 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594519301616 -> 140594519301520
	140594519301616 -> 140594519245664 [dir=none]
	140594519245664 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594519301616 -> 140594519245744 [dir=none]
	140594519245744 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519301616 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519302048 -> 140594519301616
	140594520100352 [label="model.decoder.layers.3.encoder_attn.v_proj.bias
 (256)" fillcolor=lightblue]
	140594520100352 -> 140594519302048
	140594519302048 [label=AccumulateGrad]
	140594519301808 -> 140594519301616
	140594519301808 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594704776640 -> 140594519301808
	140594519300080 -> 140594519301616
	140594519300080 [label=TBackward0]
	140594519301904 -> 140594519300080
	140594520100272 [label="model.decoder.layers.3.encoder_attn.v_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594520100272 -> 140594519301904
	140594519301904 [label=AccumulateGrad]
	140594519354576 -> 140594704362032
	140594519354576 [label=TBackward0]
	140594519354672 -> 140594519354576
	140594520100592 [label="model.decoder.layers.3.encoder_attn.out_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594520100592 -> 140594519354672
	140594519354672 [label=AccumulateGrad]
	140594704338656 -> 140594704338704
	140594520100752 [label="model.decoder.layers.3.encoder_attn_layer_norm.weight
 (256)" fillcolor=lightblue]
	140594520100752 -> 140594704338656
	140594704338656 [label=AccumulateGrad]
	140594704338032 -> 140594704338704
	140594519691328 [label="model.decoder.layers.3.encoder_attn_layer_norm.bias
 (256)" fillcolor=lightblue]
	140594519691328 -> 140594704338032
	140594704338032 [label=AccumulateGrad]
	140594704337984 -> 140594704337360
	140594704337984 -> 140594519245984 [dir=none]
	140594519245984 [label="other
 (6, 100, 256)" fillcolor=orange]
	140594704337984 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704338512 -> 140594704337984
	140594704338512 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594519354912 -> 140594704338512
	140594519354912 -> 140594519246064 [dir=none]
	140594519246064 [label="mat1
 (600, 2048)" fillcolor=orange]
	140594519354912 -> 140594519245824 [dir=none]
	140594519245824 [label="mat2
 (2048, 256)" fillcolor=orange]
	140594519354912 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (600, 2048)
mat1_strides:      (2048, 1)
mat2        : [saved tensor]
mat2_sizes  :    (2048, 256)
mat2_strides:      (1, 2048)"]
	140594704363328 -> 140594519354912
	140594519691648 [label="model.decoder.layers.3.fc2.bias
 (256)" fillcolor=lightblue]
	140594519691648 -> 140594704363328
	140594704363328 [label=AccumulateGrad]
	140594519299936 -> 140594519354912
	140594519299936 [label="ViewBackward0
--------------------------
self_sizes: (6, 100, 2048)"]
	140594519298496 -> 140594519299936
	140594519298496 -> 140594519246224 [dir=none]
	140594519246224 [label="result
 (6, 100, 2048)" fillcolor=orange]
	140594519298496 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594519300704 -> 140594519298496
	140594519300704 [label="ViewBackward0
-----------------------
self_sizes: (600, 2048)"]
	140594519301424 -> 140594519300704
	140594519301424 -> 140594519245584 [dir=none]
	140594519245584 [label="mat1
 (600, 256)" fillcolor=orange]
	140594519301424 -> 140594519246304 [dir=none]
	140594519246304 [label="mat2
 (256, 2048)" fillcolor=orange]
	140594519301424 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :    (256, 2048)
mat2_strides:       (1, 256)"]
	140594519301952 -> 140594519301424
	140594519691488 [label="model.decoder.layers.3.fc1.bias
 (2048)" fillcolor=lightblue]
	140594519691488 -> 140594519301952
	140594519301952 [label=AccumulateGrad]
	140594519302096 -> 140594519301424
	140594519302096 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594704338704 -> 140594519302096
	140594519300176 -> 140594519301424
	140594519300176 [label=TBackward0]
	140594519404752 -> 140594519300176
	140594519691408 [label="model.decoder.layers.3.fc1.weight
 (2048, 256)" fillcolor=lightblue]
	140594519691408 -> 140594519404752
	140594519404752 [label=AccumulateGrad]
	140594519299216 -> 140594519354912
	140594519299216 [label=TBackward0]
	140594519301088 -> 140594519299216
	140594519691568 [label="model.decoder.layers.3.fc2.weight
 (256, 2048)" fillcolor=lightblue]
	140594519691568 -> 140594519301088
	140594519301088 [label=AccumulateGrad]
	140594704337504 -> 140594704336688
	140594519691728 [label="model.decoder.layers.3.final_layer_norm.weight
 (256)" fillcolor=lightblue]
	140594519691728 -> 140594704337504
	140594704337504 [label=AccumulateGrad]
	140594704338224 -> 140594704336688
	140594519691808 [label="model.decoder.layers.3.final_layer_norm.bias
 (256)" fillcolor=lightblue]
	140594519691808 -> 140594704338224
	140594704338224 [label=AccumulateGrad]
	140594704336736 -> 140594704336640
	140594704336736 -> 140594519246384 [dir=none]
	140594519246384 [label="other
 (6, 100, 256)" fillcolor=orange]
	140594704336736 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704337648 -> 140594704336736
	140594704337648 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594704359776 -> 140594704337648
	140594704359776 -> 140594519246544 [dir=none]
	140594519246544 [label="mat1
 (600, 256)" fillcolor=orange]
	140594704359776 -> 140594519245104 [dir=none]
	140594519245104 [label="mat2
 (256, 256)" fillcolor=orange]
	140594704359776 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519298304 -> 140594704359776
	140594519692448 [label="model.decoder.layers.4.self_attn.out_proj.bias
 (256)" fillcolor=lightblue]
	140594519692448 -> 140594519298304
	140594519298304 [label=AccumulateGrad]
	140594519300368 -> 140594704359776
	140594519300368 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519404608 -> 140594519300368
	140594519404608 [label="UnsafeViewBackward0
---------------------------
self_sizes: (6, 100, 8, 32)"]
	140594519404896 -> 140594519404608
	140594519404896 [label=CloneBackward0]
	140594519404992 -> 140594519404896
	140594519404992 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519405088 -> 140594519404992
	140594519405088 [label="ViewBackward0
-------------------------
self_sizes: (48, 100, 32)"]
	140594519405184 -> 140594519405088
	140594519405184 -> 140594682178432 [dir=none]
	140594682178432 [label="mat2
 (48, 100, 32)" fillcolor=orange]
	140594519405184 -> 140594682178592 [dir=none]
	140594682178592 [label="self
 (48, 100, 100)" fillcolor=orange]
	140594519405184 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594519405280 -> 140594519405184
	140594519405280 -> 140594519245024 [dir=none]
	140594519245024 [label="result
 (48, 100, 100)" fillcolor=orange]
	140594519405280 [label="SoftmaxBackward0
----------------------------
dim   : 18446744073709551615
result:       [saved tensor]"]
	140594519405424 -> 140594519405280
	140594519405424 -> 140594682178032 [dir=none]
	140594682178032 [label="mat2
 (48, 32, 100)" fillcolor=orange]
	140594519405424 -> 140594682178352 [dir=none]
	140594682178352 [label="self
 (48, 100, 32)" fillcolor=orange]
	140594519405424 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594519405520 -> 140594519405424
	140594519405520 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 100, 32)"]
	140594519405664 -> 140594519405520
	140594519405664 [label=CloneBackward0]
	140594519405760 -> 140594519405664
	140594519405760 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519405856 -> 140594519405760
	140594519405856 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519405952 -> 140594519405856
	140594519405952 -> 140594519246704 [dir=none]
	140594519246704 [label="other
 ()" fillcolor=orange]
	140594519405952 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519406048 -> 140594519405952
	140594519406048 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594519406144 -> 140594519406048
	140594519406144 -> 140594519246864 [dir=none]
	140594519246864 [label="mat1
 (600, 256)" fillcolor=orange]
	140594519406144 -> 140594519246624 [dir=none]
	140594519246624 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519406144 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519406240 -> 140594519406144
	140594519692288 [label="model.decoder.layers.4.self_attn.q_proj.bias
 (256)" fillcolor=lightblue]
	140594519692288 -> 140594519406240
	140594519406240 [label=AccumulateGrad]
	140594519406192 -> 140594519406144
	140594519406192 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519406336 -> 140594519406192
	140594519406336 [label="AddBackward0
------------
alpha: 1"]
	140594704336688 -> 140594519406336
	140594713911600 -> 140594519406336
	140594519405568 -> 140594519406144
	140594519405568 [label=TBackward0]
	140594519406480 -> 140594519405568
	140594519692208 [label="model.decoder.layers.4.self_attn.q_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594519692208 -> 140594519406480
	140594519406480 [label=AccumulateGrad]
	140594519405472 -> 140594519405424
	140594519405472 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519405808 -> 140594519405472
	140594519405808 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 100, 32)"]
	140594519406000 -> 140594519405808
	140594519406000 [label=CloneBackward0]
	140594519406288 -> 140594519406000
	140594519406288 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519406576 -> 140594519406288
	140594519406576 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519406384 -> 140594519406576
	140594519406384 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594519406672 -> 140594519406384
	140594519406672 -> 140594519245904 [dir=none]
	140594519245904 [label="mat1
 (600, 256)" fillcolor=orange]
	140594519406672 -> 140594519246464 [dir=none]
	140594519246464 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519406672 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519406768 -> 140594519406672
	140594519691968 [label="model.decoder.layers.4.self_attn.k_proj.bias
 (256)" fillcolor=lightblue]
	140594519691968 -> 140594519406768
	140594519406768 [label=AccumulateGrad]
	140594519406720 -> 140594519406672
	140594519406720 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519406336 -> 140594519406720
	140594519405616 -> 140594519406672
	140594519405616 [label=TBackward0]
	140594519406960 -> 140594519405616
	140594519691888 [label="model.decoder.layers.4.self_attn.k_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594519691888 -> 140594519406960
	140594519406960 [label=AccumulateGrad]
	140594519405232 -> 140594519405184
	140594519405232 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 100, 32)"]
	140594519405712 -> 140594519405232
	140594519405712 [label=CloneBackward0]
	140594519406096 -> 140594519405712
	140594519406096 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519406432 -> 140594519406096
	140594519406432 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519406816 -> 140594519406432
	140594519406816 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594519407056 -> 140594519406816
	140594519407056 -> 140594519247024 [dir=none]
	140594519247024 [label="mat1
 (600, 256)" fillcolor=orange]
	140594519407056 -> 140594519247104 [dir=none]
	140594519247104 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519407056 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519406864 -> 140594519407056
	140594519692128 [label="model.decoder.layers.4.self_attn.v_proj.bias
 (256)" fillcolor=lightblue]
	140594519692128 -> 140594519406864
	140594519406864 [label=AccumulateGrad]
	140594519407008 -> 140594519407056
	140594519407008 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594704336688 -> 140594519407008
	140594519405376 -> 140594519407056
	140594519405376 [label=TBackward0]
	140594519407248 -> 140594519405376
	140594519692048 [label="model.decoder.layers.4.self_attn.v_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594519692048 -> 140594519407248
	140594519407248 [label=AccumulateGrad]
	140594519299696 -> 140594704359776
	140594519299696 [label=TBackward0]
	140594519404944 -> 140594519299696
	140594519692368 [label="model.decoder.layers.4.self_attn.out_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594519692368 -> 140594519404944
	140594519404944 [label=AccumulateGrad]
	140594704338416 -> 140594704335920
	140594519692528 [label="model.decoder.layers.4.self_attn_layer_norm.weight
 (256)" fillcolor=lightblue]
	140594519692528 -> 140594704338416
	140594704338416 [label=AccumulateGrad]
	140594704336064 -> 140594704335920
	140594519692608 [label="model.decoder.layers.4.self_attn_layer_norm.bias
 (256)" fillcolor=lightblue]
	140594519692608 -> 140594704336064
	140594704336064 [label=AccumulateGrad]
	140594704336304 -> 140594704335824
	140594704336304 -> 140594519247344 [dir=none]
	140594519247344 [label="other
 (6, 100, 256)" fillcolor=orange]
	140594704336304 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704337600 -> 140594704336304
	140594704337600 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594704363376 -> 140594704337600
	140594704363376 -> 140594519247424 [dir=none]
	140594519247424 [label="mat1
 (600, 256)" fillcolor=orange]
	140594704363376 -> 140594519247184 [dir=none]
	140594519247184 [label="mat2
 (256, 256)" fillcolor=orange]
	140594704363376 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519405136 -> 140594704363376
	140594519693248 [label="model.decoder.layers.4.encoder_attn.out_proj.bias
 (256)" fillcolor=lightblue]
	140594519693248 -> 140594519405136
	140594519405136 [label=AccumulateGrad]
	140594519404656 -> 140594704363376
	140594519404656 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519404848 -> 140594519404656
	140594519404848 [label="UnsafeViewBackward0
---------------------------
self_sizes: (6, 100, 8, 32)"]
	140594519406528 -> 140594519404848
	140594519406528 [label=CloneBackward0]
	140594519406912 -> 140594519406528
	140594519406912 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519407200 -> 140594519406912
	140594519407200 [label="ViewBackward0
-------------------------
self_sizes: (48, 100, 32)"]
	140594519407296 -> 140594519407200
	140594519407296 -> 140594682179392 [dir=none]
	140594682179392 [label="mat2
 (48, 782, 32)" fillcolor=orange]
	140594519407296 -> 140594682155072 [dir=none]
	140594682155072 [label="self
 (48, 100, 782)" fillcolor=orange]
	140594519407296 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594519407392 -> 140594519407296
	140594519407392 -> 140594519246784 [dir=none]
	140594519246784 [label="result
 (48, 100, 782)" fillcolor=orange]
	140594519407392 [label="SoftmaxBackward0
----------------------------
dim   : 18446744073709551615
result:       [saved tensor]"]
	140594519407536 -> 140594519407392
	140594519407536 [label="ViewBackward0
----------------------------
self_sizes: (6, 8, 100, 782)"]
	140594519407632 -> 140594519407536
	140594519407632 [label="AddBackward0
------------
alpha: 1"]
	140594519407728 -> 140594519407632
	140594519407728 [label="ViewBackward0
--------------------------
self_sizes: (48, 100, 782)"]
	140594519407824 -> 140594519407728
	140594519407824 -> 140594682178992 [dir=none]
	140594682178992 [label="mat2
 (48, 32, 782)" fillcolor=orange]
	140594519407824 -> 140594682179312 [dir=none]
	140594682179312 [label="self
 (48, 100, 32)" fillcolor=orange]
	140594519407824 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594519407920 -> 140594519407824
	140594519407920 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 100, 32)"]
	140594519408064 -> 140594519407920
	140594519408064 [label=CloneBackward0]
	140594519408160 -> 140594519408064
	140594519408160 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519408256 -> 140594519408160
	140594519408256 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519408352 -> 140594519408256
	140594519408352 -> 140594519247664 [dir=none]
	140594519247664 [label="other
 ()" fillcolor=orange]
	140594519408352 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519408448 -> 140594519408352
	140594519408448 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594519408544 -> 140594519408448
	140594519408544 -> 140594519247744 [dir=none]
	140594519247744 [label="mat1
 (600, 256)" fillcolor=orange]
	140594519408544 -> 140594519246144 [dir=none]
	140594519246144 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519408544 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519408592 -> 140594519408544
	140594519693088 [label="model.decoder.layers.4.encoder_attn.q_proj.bias
 (256)" fillcolor=lightblue]
	140594519693088 -> 140594519408592
	140594519408592 [label=AccumulateGrad]
	140594519407968 -> 140594519408544
	140594519407968 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519253152 -> 140594519407968
	140594519253152 [label="AddBackward0
------------
alpha: 1"]
	140594704335920 -> 140594519253152
	140594713911600 -> 140594519253152
	140594519253056 -> 140594519408544
	140594519253056 [label=TBackward0]
	140594519253296 -> 140594519253056
	140594519693008 [label="model.decoder.layers.4.encoder_attn.q_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594519693008 -> 140594519253296
	140594519253296 [label=AccumulateGrad]
	140594519407872 -> 140594519407824
	140594519407872 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519408208 -> 140594519407872
	140594519408208 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 782, 32)"]
	140594519408400 -> 140594519408208
	140594519408400 [label=CloneBackward0]
	140594519408496 -> 140594519408400
	140594519408496 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519253392 -> 140594519408496
	140594519253392 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519253200 -> 140594519253392
	140594519253200 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594519253488 -> 140594519253200
	140594519253488 -> 140594519247264 [dir=none]
	140594519247264 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594519253488 -> 140594519247584 [dir=none]
	140594519247584 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519253488 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519253584 -> 140594519253488
	140594519692768 [label="model.decoder.layers.4.encoder_attn.k_proj.bias
 (256)" fillcolor=lightblue]
	140594519692768 -> 140594519253584
	140594519253584 [label=AccumulateGrad]
	140594519253536 -> 140594519253488
	140594519253536 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519253680 -> 140594519253536
	140594519253680 [label="AddBackward0
------------
alpha: 1"]
	140594704776640 -> 140594519253680
	140594519253104 -> 140594519253488
	140594519253104 [label=TBackward0]
	140594519253824 -> 140594519253104
	140594519692688 [label="model.decoder.layers.4.encoder_attn.k_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594519692688 -> 140594519253824
	140594519253824 [label=AccumulateGrad]
	140594519407152 -> 140594519407296
	140594519407152 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 782, 32)"]
	140594519407680 -> 140594519407152
	140594519407680 [label=CloneBackward0]
	140594519407440 -> 140594519407680
	140594519407440 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519408304 -> 140594519407440
	140594519408304 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519408016 -> 140594519408304
	140594519408016 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594519253440 -> 140594519408016
	140594519253440 -> 140594519247904 [dir=none]
	140594519247904 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594519253440 -> 140594519247984 [dir=none]
	140594519247984 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519253440 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519253872 -> 140594519253440
	140594519692928 [label="model.decoder.layers.4.encoder_attn.v_proj.bias
 (256)" fillcolor=lightblue]
	140594519692928 -> 140594519253872
	140594519253872 [label=AccumulateGrad]
	140594519253632 -> 140594519253440
	140594519253632 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594704776640 -> 140594519253632
	140594519253344 -> 140594519253440
	140594519253344 [label=TBackward0]
	140594519253968 -> 140594519253344
	140594519692848 [label="model.decoder.layers.4.encoder_attn.v_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594519692848 -> 140594519253968
	140594519253968 [label=AccumulateGrad]
	140594519404704 -> 140594704363376
	140594519404704 [label=TBackward0]
	140594519406624 -> 140594519404704
	140594519693168 [label="model.decoder.layers.4.encoder_attn.out_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594519693168 -> 140594519406624
	140594519406624 [label=AccumulateGrad]
	140594704336496 -> 140594704335632
	140594519693328 [label="model.decoder.layers.4.encoder_attn_layer_norm.weight
 (256)" fillcolor=lightblue]
	140594519693328 -> 140594704336496
	140594704336496 [label=AccumulateGrad]
	140594704337840 -> 140594704335632
	140594519693408 [label="model.decoder.layers.4.encoder_attn_layer_norm.bias
 (256)" fillcolor=lightblue]
	140594519693408 -> 140594704337840
	140594704337840 [label=AccumulateGrad]
	140594704335776 -> 140594704335248
	140594704335776 -> 140594519248224 [dir=none]
	140594519248224 [label="other
 (6, 100, 256)" fillcolor=orange]
	140594704335776 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704336784 -> 140594704335776
	140594704336784 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594704337312 -> 140594704336784
	140594704337312 -> 140594519248304 [dir=none]
	140594519248304 [label="mat1
 (600, 2048)" fillcolor=orange]
	140594704337312 -> 140594519248064 [dir=none]
	140594519248064 [label="mat2
 (2048, 256)" fillcolor=orange]
	140594704337312 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (600, 2048)
mat1_strides:      (2048, 1)
mat2        : [saved tensor]
mat2_sizes  :    (2048, 256)
mat2_strides:      (1, 2048)"]
	140594519407344 -> 140594704337312
	140594519693728 [label="model.decoder.layers.4.fc2.bias
 (256)" fillcolor=lightblue]
	140594519693728 -> 140594519407344
	140594519407344 [label=AccumulateGrad]
	140594519405904 -> 140594704337312
	140594519405904 [label="ViewBackward0
--------------------------
self_sizes: (6, 100, 2048)"]
	140594519404800 -> 140594519405904
	140594519404800 -> 140594519248464 [dir=none]
	140594519248464 [label="result
 (6, 100, 2048)" fillcolor=orange]
	140594519404800 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594519408112 -> 140594519404800
	140594519408112 [label="ViewBackward0
-----------------------
self_sizes: (600, 2048)"]
	140594519407488 -> 140594519408112
	140594519407488 -> 140594519247824 [dir=none]
	140594519247824 [label="mat1
 (600, 256)" fillcolor=orange]
	140594519407488 -> 140594519248544 [dir=none]
	140594519248544 [label="mat2
 (256, 2048)" fillcolor=orange]
	140594519407488 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :    (256, 2048)
mat2_strides:       (1, 256)"]
	140594519253728 -> 140594519407488
	140594519693568 [label="model.decoder.layers.4.fc1.bias
 (2048)" fillcolor=lightblue]
	140594519693568 -> 140594519253728
	140594519253728 [label=AccumulateGrad]
	140594519253920 -> 140594519407488
	140594519253920 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594704335632 -> 140594519253920
	140594519253248 -> 140594519407488
	140594519253248 [label=TBackward0]
	140594519254112 -> 140594519253248
	140594519693488 [label="model.decoder.layers.4.fc1.weight
 (2048, 256)" fillcolor=lightblue]
	140594519693488 -> 140594519254112
	140594519254112 [label=AccumulateGrad]
	140594519405040 -> 140594704337312
	140594519405040 [label=TBackward0]
	140594519407584 -> 140594519405040
	140594519693648 [label="model.decoder.layers.4.fc2.weight
 (256, 2048)" fillcolor=lightblue]
	140594519693648 -> 140594519407584
	140594519407584 [label=AccumulateGrad]
	140594704335392 -> 140594704336976
	140594519693808 [label="model.decoder.layers.4.final_layer_norm.weight
 (256)" fillcolor=lightblue]
	140594519693808 -> 140594704335392
	140594704335392 [label=AccumulateGrad]
	140594704335584 -> 140594704336976
	140594519693888 [label="model.decoder.layers.4.final_layer_norm.bias
 (256)" fillcolor=lightblue]
	140594519693888 -> 140594704335584
	140594704335584 [label=AccumulateGrad]
	140594704337552 -> 140594704338464
	140594704337552 -> 140594519248624 [dir=none]
	140594519248624 [label="other
 (6, 100, 256)" fillcolor=orange]
	140594704337552 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704338176 -> 140594704337552
	140594704338176 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594704336448 -> 140594704338176
	140594704336448 -> 140594519248784 [dir=none]
	140594519248784 [label="mat1
 (600, 256)" fillcolor=orange]
	140594704336448 -> 140594519247504 [dir=none]
	140594519247504 [label="mat2
 (256, 256)" fillcolor=orange]
	140594704336448 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519405328 -> 140594704336448
	140594519694528 [label="model.decoder.layers.5.self_attn.out_proj.bias
 (256)" fillcolor=lightblue]
	140594519694528 -> 140594519405328
	140594519405328 [label=AccumulateGrad]
	140594519407776 -> 140594704336448
	140594519407776 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519254064 -> 140594519407776
	140594519254064 [label="UnsafeViewBackward0
---------------------------
self_sizes: (6, 100, 8, 32)"]
	140594519254256 -> 140594519254064
	140594519254256 [label=CloneBackward0]
	140594519254352 -> 140594519254256
	140594519254352 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519254448 -> 140594519254352
	140594519254448 [label="ViewBackward0
-------------------------
self_sizes: (48, 100, 32)"]
	140594519254544 -> 140594519254448
	140594519254544 -> 140594682155952 [dir=none]
	140594682155952 [label="mat2
 (48, 100, 32)" fillcolor=orange]
	140594519254544 -> 140594682156112 [dir=none]
	140594682156112 [label="self
 (48, 100, 100)" fillcolor=orange]
	140594519254544 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594519254640 -> 140594519254544
	140594519254640 -> 140594519248144 [dir=none]
	140594519248144 [label="result
 (48, 100, 100)" fillcolor=orange]
	140594519254640 [label="SoftmaxBackward0
----------------------------
dim   : 18446744073709551615
result:       [saved tensor]"]
	140594519254784 -> 140594519254640
	140594519254784 -> 140594682155552 [dir=none]
	140594682155552 [label="mat2
 (48, 32, 100)" fillcolor=orange]
	140594519254784 -> 140594682155872 [dir=none]
	140594682155872 [label="self
 (48, 100, 32)" fillcolor=orange]
	140594519254784 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594519254880 -> 140594519254784
	140594519254880 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 100, 32)"]
	140594519255024 -> 140594519254880
	140594519255024 [label=CloneBackward0]
	140594519255120 -> 140594519255024
	140594519255120 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519255216 -> 140594519255120
	140594519255216 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519255312 -> 140594519255216
	140594519255312 -> 140594519248704 [dir=none]
	140594519248704 [label="other
 ()" fillcolor=orange]
	140594519255312 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519255408 -> 140594519255312
	140594519255408 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594519255504 -> 140594519255408
	140594519255504 -> 140594519246944 [dir=none]
	140594519246944 [label="mat1
 (600, 256)" fillcolor=orange]
	140594519255504 -> 140594519248384 [dir=none]
	140594519248384 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519255504 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519255600 -> 140594519255504
	140594519694368 [label="model.decoder.layers.5.self_attn.q_proj.bias
 (256)" fillcolor=lightblue]
	140594519694368 -> 140594519255600
	140594519255600 [label=AccumulateGrad]
	140594519255552 -> 140594519255504
	140594519255552 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519255696 -> 140594519255552
	140594519255696 [label="AddBackward0
------------
alpha: 1"]
	140594704336976 -> 140594519255696
	140594713911600 -> 140594519255696
	140594519254928 -> 140594519255504
	140594519254928 [label=TBackward0]
	140594519255840 -> 140594519254928
	140594519694288 [label="model.decoder.layers.5.self_attn.q_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594519694288 -> 140594519255840
	140594519255840 [label=AccumulateGrad]
	140594519254832 -> 140594519254784
	140594519254832 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519255168 -> 140594519254832
	140594519255168 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 100, 32)"]
	140594519255360 -> 140594519255168
	140594519255360 [label=CloneBackward0]
	140594519255648 -> 140594519255360
	140594519255648 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519255936 -> 140594519255648
	140594519255936 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519255744 -> 140594519255936
	140594519255744 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594519256032 -> 140594519255744
	140594519256032 -> 140594519220448 [dir=none]
	140594519220448 [label="mat1
 (600, 256)" fillcolor=orange]
	140594519256032 -> 140594519220288 [dir=none]
	140594519220288 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519256032 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519256128 -> 140594519256032
	140594519694048 [label="model.decoder.layers.5.self_attn.k_proj.bias
 (256)" fillcolor=lightblue]
	140594519694048 -> 140594519256128
	140594519256128 [label=AccumulateGrad]
	140594519256080 -> 140594519256032
	140594519256080 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519255696 -> 140594519256080
	140594519254976 -> 140594519256032
	140594519254976 [label=TBackward0]
	140594519256320 -> 140594519254976
	140594519693968 [label="model.decoder.layers.5.self_attn.k_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594519693968 -> 140594519256320
	140594519256320 [label=AccumulateGrad]
	140594519254592 -> 140594519254544
	140594519254592 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 100, 32)"]
	140594519255072 -> 140594519254592
	140594519255072 [label=CloneBackward0]
	140594519255456 -> 140594519255072
	140594519255456 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519255792 -> 140594519255456
	140594519255792 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519256176 -> 140594519255792
	140594519256176 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594519256416 -> 140594519256176
	140594519256416 -> 140594519220368 [dir=none]
	140594519220368 [label="mat1
 (600, 256)" fillcolor=orange]
	140594519256416 -> 140594519220688 [dir=none]
	140594519220688 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519256416 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519256224 -> 140594519256416
	140594519694208 [label="model.decoder.layers.5.self_attn.v_proj.bias
 (256)" fillcolor=lightblue]
	140594519694208 -> 140594519256224
	140594519256224 [label=AccumulateGrad]
	140594519256368 -> 140594519256416
	140594519256368 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594704336976 -> 140594519256368
	140594519254736 -> 140594519256416
	140594519254736 [label=TBackward0]
	140594519256608 -> 140594519254736
	140594519694128 [label="model.decoder.layers.5.self_attn.v_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594519694128 -> 140594519256608
	140594519256608 [label=AccumulateGrad]
	140594519407104 -> 140594704336448
	140594519407104 [label=TBackward0]
	140594519254304 -> 140594519407104
	140594519694448 [label="model.decoder.layers.5.self_attn.out_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594519694448 -> 140594519254304
	140594519254304 [label=AccumulateGrad]
	140594704335872 -> 140594704335200
	140594519694608 [label="model.decoder.layers.5.self_attn_layer_norm.weight
 (256)" fillcolor=lightblue]
	140594519694608 -> 140594704335872
	140594704335872 [label=AccumulateGrad]
	140594704335056 -> 140594704335200
	140594519694688 [label="model.decoder.layers.5.self_attn_layer_norm.bias
 (256)" fillcolor=lightblue]
	140594519694688 -> 140594704335056
	140594704335056 [label=AccumulateGrad]
	140594704334960 -> 140594704309744
	140594704334960 -> 140594519220928 [dir=none]
	140594519220928 [label="other
 (6, 100, 256)" fillcolor=orange]
	140594704334960 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704336256 -> 140594704334960
	140594704336256 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594704337792 -> 140594704336256
	140594704337792 -> 140594519221088 [dir=none]
	140594519221088 [label="mat1
 (600, 256)" fillcolor=orange]
	140594704337792 -> 140594519220768 [dir=none]
	140594519220768 [label="mat2
 (256, 256)" fillcolor=orange]
	140594704337792 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519254496 -> 140594704337792
	140594519814208 [label="model.decoder.layers.5.encoder_attn.out_proj.bias
 (256)" fillcolor=lightblue]
	140594519814208 -> 140594519254496
	140594519254496 [label=AccumulateGrad]
	140594519254016 -> 140594704337792
	140594519254016 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519254208 -> 140594519254016
	140594519254208 [label="UnsafeViewBackward0
---------------------------
self_sizes: (6, 100, 8, 32)"]
	140594519255888 -> 140594519254208
	140594519255888 [label=CloneBackward0]
	140594519256272 -> 140594519255888
	140594519256272 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519256560 -> 140594519256272
	140594519256560 [label="ViewBackward0
-------------------------
self_sizes: (48, 100, 32)"]
	140594519256656 -> 140594519256560
	140594519256656 -> 140594682156912 [dir=none]
	140594682156912 [label="mat2
 (48, 782, 32)" fillcolor=orange]
	140594519256656 -> 140594682157072 [dir=none]
	140594682157072 [label="self
 (48, 100, 782)" fillcolor=orange]
	140594519256656 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594519256752 -> 140594519256656
	140594519256752 -> 140594519220528 [dir=none]
	140594519220528 [label="result
 (48, 100, 782)" fillcolor=orange]
	140594519256752 [label="SoftmaxBackward0
----------------------------
dim   : 18446744073709551615
result:       [saved tensor]"]
	140594519256896 -> 140594519256752
	140594519256896 [label="ViewBackward0
----------------------------
self_sizes: (6, 8, 100, 782)"]
	140594519256992 -> 140594519256896
	140594519256992 [label="AddBackward0
------------
alpha: 1"]
	140594519257040 -> 140594519256992
	140594519257040 [label="ViewBackward0
--------------------------
self_sizes: (48, 100, 782)"]
	140594519175328 -> 140594519257040
	140594519175328 -> 140594682156512 [dir=none]
	140594682156512 [label="mat2
 (48, 32, 782)" fillcolor=orange]
	140594519175328 -> 140594682156832 [dir=none]
	140594682156832 [label="self
 (48, 100, 32)" fillcolor=orange]
	140594519175328 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140594519175424 -> 140594519175328
	140594519175424 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 100, 32)"]
	140594519175568 -> 140594519175424
	140594519175568 [label=CloneBackward0]
	140594519175664 -> 140594519175568
	140594519175664 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519175760 -> 140594519175664
	140594519175760 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519175856 -> 140594519175760
	140594519175856 -> 140594519221328 [dir=none]
	140594519221328 [label="other
 ()" fillcolor=orange]
	140594519175856 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594519175952 -> 140594519175856
	140594519175952 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594519176048 -> 140594519175952
	140594519176048 -> 140594519221408 [dir=none]
	140594519221408 [label="mat1
 (600, 256)" fillcolor=orange]
	140594519176048 -> 140594519220608 [dir=none]
	140594519220608 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519176048 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519176144 -> 140594519176048
	140594519695168 [label="model.decoder.layers.5.encoder_attn.q_proj.bias
 (256)" fillcolor=lightblue]
	140594519695168 -> 140594519176144
	140594519176144 [label=AccumulateGrad]
	140594519176096 -> 140594519176048
	140594519176096 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594519176240 -> 140594519176096
	140594519176240 [label="AddBackward0
------------
alpha: 1"]
	140594704335200 -> 140594519176240
	140594713911600 -> 140594519176240
	140594519175472 -> 140594519176048
	140594519175472 [label=TBackward0]
	140594519176384 -> 140594519175472
	140594519695088 [label="model.decoder.layers.5.encoder_attn.q_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594519695088 -> 140594519176384
	140594519176384 [label=AccumulateGrad]
	140594519175376 -> 140594519175328
	140594519175376 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519175712 -> 140594519175376
	140594519175712 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 782, 32)"]
	140594519175904 -> 140594519175712
	140594519175904 [label=CloneBackward0]
	140594519176192 -> 140594519175904
	140594519176192 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519176480 -> 140594519176192
	140594519176480 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519176288 -> 140594519176480
	140594519176288 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594519176576 -> 140594519176288
	140594519176576 -> 140594519220848 [dir=none]
	140594519220848 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594519176576 -> 140594519221248 [dir=none]
	140594519221248 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519176576 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519176672 -> 140594519176576
	140594519694848 [label="model.decoder.layers.5.encoder_attn.k_proj.bias
 (256)" fillcolor=lightblue]
	140594519694848 -> 140594519176672
	140594519176672 [label=AccumulateGrad]
	140594519176624 -> 140594519176576
	140594519176624 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519176768 -> 140594519176624
	140594519176768 [label="AddBackward0
------------
alpha: 1"]
	140594704776640 -> 140594519176768
	140594519175520 -> 140594519176576
	140594519175520 [label=TBackward0]
	140594519176912 -> 140594519175520
	140594519694768 [label="model.decoder.layers.5.encoder_attn.k_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594519694768 -> 140594519176912
	140594519176912 [label=AccumulateGrad]
	140594519256512 -> 140594519256656
	140594519256512 [label="ViewBackward0
---------------------------
self_sizes: (6, 8, 782, 32)"]
	140594519256800 -> 140594519256512
	140594519256800 [label=CloneBackward0]
	140594519256848 -> 140594519256800
	140594519256848 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	140594519175808 -> 140594519256848
	140594519175808 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594519176432 -> 140594519175808
	140594519176432 [label="ViewBackward0
-----------------------
self_sizes: (4692, 256)"]
	140594519176528 -> 140594519176432
	140594519176528 -> 140594519221568 [dir=none]
	140594519221568 [label="mat1
 (4692, 256)" fillcolor=orange]
	140594519176528 -> 140594519221648 [dir=none]
	140594519221648 [label="mat2
 (256, 256)" fillcolor=orange]
	140594519176528 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (4692, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :     (256, 256)
mat2_strides:       (1, 256)"]
	140594519176960 -> 140594519176528
	140594519695008 [label="model.decoder.layers.5.encoder_attn.v_proj.bias
 (256)" fillcolor=lightblue]
	140594519695008 -> 140594519176960
	140594519176960 [label=AccumulateGrad]
	140594519176720 -> 140594519176528
	140594519176720 [label="ViewBackward0
-------------------------
self_sizes: (6, 782, 256)"]
	140594704776640 -> 140594519176720
	140594519175280 -> 140594519176528
	140594519175280 [label=TBackward0]
	140594519177056 -> 140594519175280
	140594519694928 [label="model.decoder.layers.5.encoder_attn.v_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594519694928 -> 140594519177056
	140594519177056 [label=AccumulateGrad]
	140594519253776 -> 140594704337792
	140594519253776 [label=TBackward0]
	140594519255984 -> 140594519253776
	140594519695248 [label="model.decoder.layers.5.encoder_attn.out_proj.weight
 (256, 256)" fillcolor=lightblue]
	140594519695248 -> 140594519255984
	140594519255984 [label=AccumulateGrad]
	140594704309888 -> 140594704309456
	140594519814288 [label="model.decoder.layers.5.encoder_attn_layer_norm.weight
 (256)" fillcolor=lightblue]
	140594519814288 -> 140594704309888
	140594704309888 [label=AccumulateGrad]
	140594704309696 -> 140594704309456
	140594519814368 [label="model.decoder.layers.5.encoder_attn_layer_norm.bias
 (256)" fillcolor=lightblue]
	140594519814368 -> 140594704309696
	140594704309696 [label=AccumulateGrad]
	140594704310080 -> 140594704309936
	140594704310080 -> 140594519221888 [dir=none]
	140594519221888 [label="other
 (6, 100, 256)" fillcolor=orange]
	140594704310080 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140594704336112 -> 140594704310080
	140594704336112 [label="ViewBackward0
----------------------
self_sizes: (600, 256)"]
	140594704336928 -> 140594704336112
	140594704336928 -> 140594519221968 [dir=none]
	140594519221968 [label="mat1
 (600, 2048)" fillcolor=orange]
	140594704336928 -> 140594519221728 [dir=none]
	140594519221728 [label="mat2
 (2048, 256)" fillcolor=orange]
	140594704336928 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (600, 2048)
mat1_strides:      (2048, 1)
mat2        : [saved tensor]
mat2_sizes  :    (2048, 256)
mat2_strides:      (1, 2048)"]
	140594519256704 -> 140594704336928
	140594519814688 [label="model.decoder.layers.5.fc2.bias
 (256)" fillcolor=lightblue]
	140594519814688 -> 140594519256704
	140594519256704 [label=AccumulateGrad]
	140594519255264 -> 140594704336928
	140594519255264 [label="ViewBackward0
--------------------------
self_sizes: (6, 100, 2048)"]
	140594519254160 -> 140594519255264
	140594519254160 -> 140594519222128 [dir=none]
	140594519222128 [label="result
 (6, 100, 2048)" fillcolor=orange]
	140594519254160 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140594519256944 -> 140594519254160
	140594519256944 [label="ViewBackward0
-----------------------
self_sizes: (600, 2048)"]
	140594519176336 -> 140594519256944
	140594519176336 -> 140594519221488 [dir=none]
	140594519221488 [label="mat1
 (600, 256)" fillcolor=orange]
	140594519176336 -> 140594519222208 [dir=none]
	140594519222208 [label="mat2
 (256, 2048)" fillcolor=orange]
	140594519176336 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (600, 256)
mat1_strides:       (256, 1)
mat2        : [saved tensor]
mat2_sizes  :    (256, 2048)
mat2_strides:       (1, 256)"]
	140594519176816 -> 140594519176336
	140594519814528 [label="model.decoder.layers.5.fc1.bias
 (2048)" fillcolor=lightblue]
	140594519814528 -> 140594519176816
	140594519176816 [label=AccumulateGrad]
	140594519177008 -> 140594519176336
	140594519177008 [label="ViewBackward0
-------------------------
self_sizes: (6, 100, 256)"]
	140594704309456 -> 140594519177008
	140594519175232 -> 140594519176336
	140594519175232 [label=TBackward0]
	140594519177200 -> 140594519175232
	140594519814448 [label="model.decoder.layers.5.fc1.weight
 (2048, 256)" fillcolor=lightblue]
	140594519814448 -> 140594519177200
	140594519177200 [label=AccumulateGrad]
	140594519254400 -> 140594704336928
	140594519254400 [label=TBackward0]
	140594519254688 -> 140594519254400
	140594519814608 [label="model.decoder.layers.5.fc2.weight
 (256, 2048)" fillcolor=lightblue]
	140594519814608 -> 140594519254688
	140594519254688 [label=AccumulateGrad]
	140594704308832 -> 140594704308352
	140594519814768 [label="model.decoder.layers.5.final_layer_norm.weight
 (256)" fillcolor=lightblue]
	140594519814768 -> 140594704308832
	140594704308832 [label=AccumulateGrad]
	140594704308592 -> 140594704308352
	140594519814848 [label="model.decoder.layers.5.final_layer_norm.bias
 (256)" fillcolor=lightblue]
	140594519814848 -> 140594704308592
	140594704308592 [label=AccumulateGrad]
	140594704308544 -> 140594704306288
	140594519814928 [label="model.decoder.layernorm.weight
 (256)" fillcolor=lightblue]
	140594519814928 -> 140594704308544
	140594704308544 [label=AccumulateGrad]
	140594704308208 -> 140594704306288
	140594519815008 [label="model.decoder.layernorm.bias
 (256)" fillcolor=lightblue]
	140594519815008 -> 140594704308208
	140594704308208 [label=AccumulateGrad]
	140594704306672 -> 140594704307296
	140594704306672 [label=TBackward0]
	140594704308880 -> 140594704306672
	140594519815088 [label="class_labels_classifier.weight
 (92, 256)" fillcolor=lightblue]
	140594519815088 -> 140594704308880
	140594704308880 [label=AccumulateGrad]
	140594704309024 -> 140594681347984
	140594519222288 [label="
 (600, 92)" fillcolor=darkolivegreen3]
	140594704307296 -> 140594519222288
	140594519222288 -> 140594681347984 [style=dotted]
}
